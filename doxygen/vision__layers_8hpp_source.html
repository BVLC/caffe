<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9.1"/>
<title>Caffe: include/caffe/vision_layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_4b7f3da7c7b4301d805dae0326fb91b7.html">caffe</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">vision_layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef CAFFE_VISION_LAYERS_HPP_</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define CAFFE_VISION_LAYERS_HPP_</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;caffe/blob.hpp&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;caffe/common.hpp&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;caffe/common_layers.hpp&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;caffe/data_layers.hpp&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;caffe/layer.hpp&quot;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &quot;caffe/loss_layers.hpp&quot;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &quot;caffe/neuron_layers.hpp&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &quot;caffe/proto/caffe.pb.h&quot;</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecaffe.html">caffe</a> {</div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00024"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html">   24</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a35c6389878e77ab0a4a479e5441563cc">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#ac330e2fb166bca496edd277b0495f6eb">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div>
<div class="line"><a name="l00033"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#a14a2760d3eafcfce766222f80e126fbe">   33</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a14a2760d3eafcfce766222f80e126fbe">MinBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00034"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#accd0683191124da91a3667acc57e5ecd">   34</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#accd0683191124da91a3667acc57e5ecd">MinTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00035"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#add4567680b9466cbae5804da6a76e2ee">   35</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#add4567680b9466cbae5804da6a76e2ee">EqualNumBottomTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="keyword">true</span>; }</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;  <span class="comment">// Helper functions that abstract away the column buffer and gemm arguments.</span></div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;  <span class="comment">// The last argument in forward_cpu_gemm is so that we can skip the im2col if</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;  <span class="comment">// we just called weight_cpu_gemm with the same input.</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;  <span class="keywordtype">void</span> forward_cpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;      Dtype* output, <span class="keywordtype">bool</span> skip_im2col = <span class="keyword">false</span>);</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;  <span class="keywordtype">void</span> forward_cpu_bias(Dtype* output, <span class="keyword">const</span> Dtype* bias);</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;  <span class="keywordtype">void</span> backward_cpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;      Dtype* output);</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;  <span class="keywordtype">void</span> weight_cpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* output, Dtype*</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;      weights);</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;  <span class="keywordtype">void</span> backward_cpu_bias(Dtype* bias, <span class="keyword">const</span> Dtype* input);</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="preprocessor">#ifndef CPU_ONLY</span></div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;  <span class="keywordtype">void</span> forward_gpu_gemm(<span class="keyword">const</span> Dtype* col_input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;      Dtype* output, <span class="keywordtype">bool</span> skip_im2col = <span class="keyword">false</span>);</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;  <span class="keywordtype">void</span> forward_gpu_bias(Dtype* output, <span class="keyword">const</span> Dtype* bias);</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;  <span class="keywordtype">void</span> backward_gpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;      Dtype* col_output);</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  <span class="keywordtype">void</span> weight_gpu_gemm(<span class="keyword">const</span> Dtype* col_input, <span class="keyword">const</span> Dtype* output, Dtype*</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;      weights);</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;  <span class="keywordtype">void</span> backward_gpu_bias(Dtype* bias, <span class="keyword">const</span> Dtype* input);</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div>
<div class="line"><a name="l00062"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#a6324d4ab918a7b09399aa85a8a03737d">   62</a></span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a6324d4ab918a7b09399aa85a8a03737d">input_shape</a>(<span class="keywordtype">int</span> i) {</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    <span class="keywordflow">return</span> (*bottom_shape_)[channel_axis_ + i];</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;  }</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;  <span class="comment">// reverse_dimensions should return true iff we are implementing deconv, so</span></div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;  <span class="comment">// that conv helpers know which dimensions are which.</span></div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">bool</span> reverse_dimensions() = 0;</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;  <span class="comment">// Compute height_out_ and width_out_ from other parameters.</span></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> compute_output_shape() = 0;</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;</div>
<div class="line"><a name="l00072"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#a0a2f112eec8a7cbd13888185d4fb36b0">   72</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a0a2f112eec8a7cbd13888185d4fb36b0">kernel_shape_</a>;</div>
<div class="line"><a name="l00074"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#af638d3d8e67c33443cb11cb000368e73">   74</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#af638d3d8e67c33443cb11cb000368e73">stride_</a>;</div>
<div class="line"><a name="l00076"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#a897ead2823e9031863e2151e71229e35">   76</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a897ead2823e9031863e2151e71229e35">pad_</a>;</div>
<div class="line"><a name="l00078"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#a63756d6ef00f6491939e539094c21397">   78</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a63756d6ef00f6491939e539094c21397">conv_input_shape_</a>;</div>
<div class="line"><a name="l00080"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#a9dd3f4ea6e17fe155efe537c120a3de4">   80</a></span>&#160;  vector&lt;int&gt; <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a9dd3f4ea6e17fe155efe537c120a3de4">col_buffer_shape_</a>;</div>
<div class="line"><a name="l00082"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#af0892b61454ba086c4c74b78d910bf31">   82</a></span>&#160;  vector&lt;int&gt; <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#af0892b61454ba086c4c74b78d910bf31">output_shape_</a>;</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;  <span class="keyword">const</span> vector&lt;int&gt;* bottom_shape_;</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;  <span class="keywordtype">int</span> num_spatial_axes_;</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;  <span class="keywordtype">int</span> bottom_dim_;</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;  <span class="keywordtype">int</span> top_dim_;</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;  <span class="keywordtype">int</span> channel_axis_;</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;  <span class="keywordtype">int</span> num_;</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;  <span class="keywordtype">int</span> group_;</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;  <span class="keywordtype">int</span> out_spatial_dim_;</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;  <span class="keywordtype">int</span> weight_offset_;</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;  <span class="keywordtype">int</span> num_output_;</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;  <span class="keywordtype">bool</span> bias_term_;</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;  <span class="keywordtype">bool</span> is_1x1_;</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;  <span class="keywordtype">bool</span> force_nd_im2col_;</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160; <span class="keyword">private</span>:</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  <span class="comment">// wrap im2col/col2im so we don&#39;t have to remember the (long) argument lists</span></div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_im2col_cpu(<span class="keyword">const</span> Dtype* data, Dtype* col_buff) {</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    <span class="keywordflow">if</span> (!force_nd_im2col_ &amp;&amp; num_spatial_axes_ == 2) {</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;      im2col_cpu(data, conv_in_channels_,</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;          conv_input_shape_.cpu_data()[1], conv_input_shape_.cpu_data()[2],</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;          kernel_shape_.cpu_data()[0], kernel_shape_.cpu_data()[1],</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;          pad_.cpu_data()[0], pad_.cpu_data()[1],</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;          stride_.cpu_data()[0], stride_.cpu_data()[1], col_buff);</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;      im2col_nd_cpu(data, num_spatial_axes_, conv_input_shape_.cpu_data(),</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;          col_buffer_shape_.data(), kernel_shape_.cpu_data(),</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;          pad_.cpu_data(), stride_.cpu_data(), col_buff);</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;    }</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;  }</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_col2im_cpu(<span class="keyword">const</span> Dtype* col_buff, Dtype* data) {</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="keywordflow">if</span> (!force_nd_im2col_ &amp;&amp; num_spatial_axes_ == 2) {</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;      col2im_cpu(col_buff, conv_in_channels_,</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;          conv_input_shape_.cpu_data()[1], conv_input_shape_.cpu_data()[2],</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;          kernel_shape_.cpu_data()[0], kernel_shape_.cpu_data()[1],</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;          pad_.cpu_data()[0], pad_.cpu_data()[1],</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;          stride_.cpu_data()[0], stride_.cpu_data()[1], data);</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;      col2im_nd_cpu(col_buff, num_spatial_axes_, conv_input_shape_.cpu_data(),</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;          col_buffer_shape_.data(), kernel_shape_.cpu_data(),</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;          pad_.cpu_data(), stride_.cpu_data(), data);</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;    }</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;  }</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;<span class="preprocessor">#ifndef CPU_ONLY</span></div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_im2col_gpu(<span class="keyword">const</span> Dtype* data, Dtype* col_buff) {</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;    <span class="keywordflow">if</span> (!force_nd_im2col_ &amp;&amp; num_spatial_axes_ == 2) {</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;      im2col_gpu(data, conv_in_channels_,</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;          conv_input_shape_.cpu_data()[1], conv_input_shape_.cpu_data()[2],</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;          kernel_shape_.cpu_data()[0], kernel_shape_.cpu_data()[1],</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;          pad_.cpu_data()[0], pad_.cpu_data()[1],</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;          stride_.cpu_data()[0], stride_.cpu_data()[1], col_buff);</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;      im2col_nd_gpu(data, num_spatial_axes_, num_kernels_im2col_,</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;          conv_input_shape_.gpu_data(), col_buffer_.gpu_shape(),</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;          kernel_shape_.gpu_data(), pad_.gpu_data(),</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;          stride_.gpu_data(), col_buff);</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    }</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;  }</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_col2im_gpu(<span class="keyword">const</span> Dtype* col_buff, Dtype* data) {</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;    <span class="keywordflow">if</span> (!force_nd_im2col_ &amp;&amp; num_spatial_axes_ == 2) {</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;      col2im_gpu(col_buff, conv_in_channels_,</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;          conv_input_shape_.cpu_data()[1], conv_input_shape_.cpu_data()[2],</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;          kernel_shape_.cpu_data()[0], kernel_shape_.cpu_data()[1],</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;          pad_.cpu_data()[0], pad_.cpu_data()[1],</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;          stride_.cpu_data()[0], stride_.cpu_data()[1], data);</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;      col2im_nd_gpu(col_buff, num_spatial_axes_, num_kernels_col2im_,</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;          conv_input_shape_.gpu_data(), col_buffer_.gpu_shape(),</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;          kernel_shape_.gpu_data(), pad_.gpu_data(), stride_.gpu_data(),</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;          data);</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    }</div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;  }</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;  <span class="keywordtype">int</span> num_kernels_im2col_;</div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;  <span class="keywordtype">int</span> num_kernels_col2im_;</div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;  <span class="keywordtype">int</span> conv_out_channels_;</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;  <span class="keywordtype">int</span> conv_in_channels_;</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;  <span class="keywordtype">int</span> conv_out_spatial_dim_;</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;  <span class="keywordtype">int</span> kernel_dim_;</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;  <span class="keywordtype">int</span> col_offset_;</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;  <span class="keywordtype">int</span> output_offset_;</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;  Blob&lt;Dtype&gt; col_buffer_;</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;  Blob&lt;Dtype&gt; bias_multiplier_;</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;};</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;</div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00189"></a><span class="lineno"><a class="line" href="classcaffe_1_1ConvolutionLayer.html">  189</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ConvolutionLayer.html">ConvolutionLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00219"></a><span class="lineno"><a class="line" href="classcaffe_1_1ConvolutionLayer.html#ad27360afd7729001b9e4f1d8c8401866">  219</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#ad27360afd7729001b9e4f1d8c8401866">ConvolutionLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;      : <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;</div>
<div class="line"><a name="l00222"></a><span class="lineno"><a class="line" href="classcaffe_1_1ConvolutionLayer.html#afdcf33e7ec63ca5e476ffdc1da1f1fa0">  222</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1ConvolutionLayer.html#afdcf33e7ec63ca5e476ffdc1da1f1fa0">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Convolution&quot;</span>; }</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#a8505044adc26d89aae3055022898c9ea">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#ace239a41953c9207efd1a9966570825c">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#ac1591049f064bd88ccdc785a948ed4b2">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#a4de7682afbd816037aba5da3ec66a9bb">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> reverse_dimensions() { <span class="keywordflow">return</span> <span class="keyword">false</span>; }</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> compute_output_shape();</div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;};</div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00252"></a><span class="lineno"><a class="line" href="classcaffe_1_1DeconvolutionLayer.html">  252</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1DeconvolutionLayer.html">DeconvolutionLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html">DeconvolutionLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;      : <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;</div>
<div class="line"><a name="l00257"></a><span class="lineno"><a class="line" href="classcaffe_1_1DeconvolutionLayer.html#a7498a14d8b7afa0bc85abe1dbd719135">  257</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a7498a14d8b7afa0bc85abe1dbd719135">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Deconvolution&quot;</span>; }</div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;</div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a3716cda5f7d7e81f7d19cf4313d2bfc5">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a49c3360133291f7e6593db36ec392d07">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a081ed64d7b91d42f9f441f849db2a58d">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a2b4a2203001e8b5a5839955879551048">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> reverse_dimensions() { <span class="keywordflow">return</span> <span class="keyword">true</span>; }</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> compute_output_shape();</div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;};</div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;</div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;<span class="comment">/*</span></div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;<span class="comment"> * @brief cuDNN implementation of ConvolutionLayer.</span></div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;<span class="comment"> *        Fallback to ConvolutionLayer for CPU mode.</span></div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;<span class="comment"> *</span></div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;<span class="comment"> * cuDNN accelerates convolution through forward kernels for filtering and bias</span></div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;<span class="comment"> * plus backward kernels for the gradient w.r.t. the filters, biases, and</span></div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;<span class="comment"> * inputs. Caffe + cuDNN further speeds up the computation through forward</span></div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;<span class="comment"> * parallelism across groups and backward parallelism across gradients.</span></div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;<span class="comment"> *</span></div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;<span class="comment"> * The CUDNN engine does not have memory overhead for matrix buffers. For many</span></div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;<span class="comment"> * input and filter regimes the CUDNN engine is faster than the CAFFE engine,</span></div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;<span class="comment"> * but for fully-convolutional models and large inputs the CAFFE engine can be</span></div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;<span class="comment"> * faster as long as it fits in memory.</span></div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;<span class="comment">*/</span></div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;<span class="keyword">class </span>CuDNNConvolutionLayer : <span class="keyword">public</span> ConvolutionLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;  <span class="keyword">explicit</span> CuDNNConvolutionLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;      : ConvolutionLayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;  <span class="keyword">virtual</span> ~CuDNNConvolutionLayer();</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;  cudnnHandle_t* handle_;</div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;  cudaStream_t*  stream_;</div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;  <span class="comment">// algorithms for forward and backwards convolutions</span></div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;  cudnnConvolutionFwdAlgo_t *fwd_algo_;</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;  cudnnConvolutionBwdFilterAlgo_t *bwd_filter_algo_;</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;  cudnnConvolutionBwdDataAlgo_t *bwd_data_algo_;</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;</div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;  vector&lt;cudnnTensorDescriptor_t&gt; bottom_descs_, top_descs_;</div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;  cudnnTensorDescriptor_t    bias_desc_;</div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;  cudnnFilterDescriptor_t      filter_desc_;</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;  vector&lt;cudnnConvolutionDescriptor_t&gt; conv_descs_;</div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;  <span class="keywordtype">int</span> bottom_offset_, top_offset_, bias_offset_;</div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;</div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;  <span class="keywordtype">size_t</span> *workspace_fwd_sizes_;</div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;  <span class="keywordtype">size_t</span> *workspace_bwd_data_sizes_;</div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;  <span class="keywordtype">size_t</span> *workspace_bwd_filter_sizes_;</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;  <span class="keywordtype">size_t</span> workspaceSizeInBytes;  <span class="comment">// size of underlying storage</span></div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;  <span class="keywordtype">void</span> *workspaceData;  <span class="comment">// underlying storage</span></div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;  <span class="keywordtype">void</span> **workspace;  <span class="comment">// aliases into workspaceData</span></div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;};</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00336"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html">  336</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1Im2colLayer.html">Im2colLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1Im2colLayer.html">Im2colLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a73d7e780b38406dc3d840649cadf8f8a">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a79735ab9fb43a53e4ca02e33a0b3f181">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;</div>
<div class="line"><a name="l00345"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#aac44aaa893e6fb774c1953b523180cea">  345</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1Im2colLayer.html#aac44aaa893e6fb774c1953b523180cea">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Im2col&quot;</span>; }</div>
<div class="line"><a name="l00346"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#aba3720be3f1f71f9e44fbfba90ae3ac0">  346</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#aba3720be3f1f71f9e44fbfba90ae3ac0">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00347"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#aa4aa1cfc956fa1ab3656ad2adf911f32">  347</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#aa4aa1cfc956fa1ab3656ad2adf911f32">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;</div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#ad8c319e6628c7c523c2c6a991f9c631a">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a1481790fce4361eefab8d78bbdd6f0ec">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a3b2dc21acbbe2e174cc83554469c29f5">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a5340f5b2e176beeb6c74428f05e06c7c">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;</div>
<div class="line"><a name="l00360"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#a188e9ea1225c7f373f4d50e2a78dcec7">  360</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> <a class="code" href="classcaffe_1_1Im2colLayer.html#a188e9ea1225c7f373f4d50e2a78dcec7">kernel_shape_</a>;</div>
<div class="line"><a name="l00362"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#afb9baa8216b65a8124d4d1d2b719da0f">  362</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> <a class="code" href="classcaffe_1_1Im2colLayer.html#afb9baa8216b65a8124d4d1d2b719da0f">stride_</a>;</div>
<div class="line"><a name="l00364"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#a55c335fac2a25ba438a8bf94497c53ec">  364</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> <a class="code" href="classcaffe_1_1Im2colLayer.html#a55c335fac2a25ba438a8bf94497c53ec">pad_</a>;</div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;  <span class="keywordtype">int</span> num_spatial_axes_;</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;  <span class="keywordtype">int</span> bottom_dim_;</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;  <span class="keywordtype">int</span> top_dim_;</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;  <span class="keywordtype">int</span> channel_axis_;</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;  <span class="keywordtype">int</span> num_;</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;</div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;  <span class="keywordtype">bool</span> force_nd_im2col_;</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;};</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;</div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;<span class="comment">// Forward declare PoolingLayer and SplitLayer for use in LRNLayer.</span></div>
<div class="line"><a name="l00378"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html">  378</a></span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt; <span class="keyword">class </span><a class="code" href="classcaffe_1_1PoolingLayer.html">PoolingLayer</a>;</div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt; <span class="keyword">class </span><a class="code" href="classcaffe_1_1SplitLayer.html">SplitLayer</a>;</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00387"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html">  387</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1LRNLayer.html">LRNLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1LRNLayer.html">LRNLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a7ab94b55392ad0500115d4a4d64b0a7c">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#ae7ca62b2339f0691dadde24fd8acb481">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;</div>
<div class="line"><a name="l00396"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html#a28dbd28c7542ae178973f0cb7b73cf8a">  396</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1LRNLayer.html#a28dbd28c7542ae178973f0cb7b73cf8a">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;LRN&quot;</span>; }</div>
<div class="line"><a name="l00397"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html#aabbbcdeb646c188ac2137b003aa1c682">  397</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LRNLayer.html#aabbbcdeb646c188ac2137b003aa1c682">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00398"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html#aab9056708727154a01866d17756c07cc">  398</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LRNLayer.html#aab9056708727154a01866d17756c07cc">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#ad3ae42eb16a0f55745211a44c806e316">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a7d8e7e7e1daf4ae1205e0bfe9fb9ac51">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a71ff30a634527e2bf89c067d3c325979">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a1ba7e8a8af945fba73da4a0c307fc4a0">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;</div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelForward_cpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelForward_gpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> WithinChannelForward(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelBackward_cpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelBackward_gpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> WithinChannelBackward(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;</div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;  <span class="keywordtype">int</span> size_;</div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;  <span class="keywordtype">int</span> pre_pad_;</div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;  Dtype alpha_;</div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;  Dtype beta_;</div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;  Dtype k_;</div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;  <span class="keywordtype">int</span> num_;</div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;  <span class="keywordtype">int</span> height_;</div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;  <span class="keywordtype">int</span> width_;</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;</div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;  <span class="comment">// Fields used for normalization ACROSS_CHANNELS</span></div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;  <span class="comment">// scale_ stores the intermediate summing results</span></div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> scale_;</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;</div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;  <span class="comment">// Fields used for normalization WITHIN_CHANNEL</span></div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;  shared_ptr&lt;SplitLayer&lt;Dtype&gt; &gt; split_layer_;</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; split_top_vec_;</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;  shared_ptr&lt;PowerLayer&lt;Dtype&gt; &gt; square_layer_;</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> square_input_;</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> square_output_;</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; square_bottom_vec_;</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; square_top_vec_;</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;  shared_ptr&lt;PoolingLayer&lt;Dtype&gt; &gt; pool_layer_;</div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> pool_output_;</div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; pool_top_vec_;</div>
<div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;  shared_ptr&lt;PowerLayer&lt;Dtype&gt; &gt; power_layer_;</div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> power_output_;</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; power_top_vec_;</div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;  shared_ptr&lt;EltwiseLayer&lt;Dtype&gt; &gt; product_layer_;</div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> product_input_;</div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; product_bottom_vec_;</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;};</div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;</div>
<div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;</div>
<div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;<span class="keyword">class </span>CuDNNLRNLayer : <span class="keyword">public</span> LRNLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;  <span class="keyword">explicit</span> CuDNNLRNLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;      : LRNLayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;  <span class="keyword">virtual</span> ~CuDNNLRNLayer();</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;  cudnnLRNDescriptor_t norm_desc_;</div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;  cudnnTensorDescriptor_t bottom_desc_, top_desc_;</div>
<div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;  <span class="keywordtype">int</span> size_;</div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;  Dtype alpha_, beta_, k_;</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;};</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;<span class="keyword">class </span>CuDNNLCNLayer : <span class="keyword">public</span> LRNLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;  <span class="keyword">explicit</span> CuDNNLCNLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;      : LRNLayer&lt;Dtype&gt;(param), handles_setup_(false), tempDataSize(0),</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;        tempData1(NULL), tempData2(NULL) {}</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;  <span class="keyword">virtual</span> ~CuDNNLCNLayer();</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;  cudnnLRNDescriptor_t norm_desc_;</div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;  cudnnTensorDescriptor_t bottom_desc_, top_desc_;</div>
<div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;</div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;  <span class="keywordtype">int</span> size_, pre_pad_;</div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;  Dtype alpha_, beta_, k_;</div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;</div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;  <span class="keywordtype">size_t</span> tempDataSize;</div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;  <span class="keywordtype">void</span> *tempData1, *tempData2;</div>
<div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;};</div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;</div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;<span class="keyword">class </span>PoolingLayer : <span class="keyword">public</span> Layer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;  <span class="keyword">explicit</span> PoolingLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">Layer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a5e1a46c850fcd18934309824208b31ff">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a79a285029778124aca1c803d6cfec55f">Reshape</a>(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;</div>
<div class="line"><a name="l00531"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#a0b4899ba1d3fe6f041dd5cc88a380c44">  531</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1PoolingLayer.html#a0b4899ba1d3fe6f041dd5cc88a380c44">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Pooling&quot;</span>; }</div>
<div class="line"><a name="l00532"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#a6fc8f79729e17639d3b97781791e352d">  532</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a6fc8f79729e17639d3b97781791e352d">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00533"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#abc72dca274a4ab42f7a12de4d1e8f8eb">  533</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#abc72dca274a4ab42f7a12de4d1e8f8eb">MinTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;  <span class="comment">// MAX POOL layers can output an extra top blob for the mask;</span></div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;  <span class="comment">// others can only output the pooled inputs.</span></div>
<div class="line"><a name="l00536"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#a2a79eac8d3e85873c1fede0f1e8f0a45">  536</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a2a79eac8d3e85873c1fede0f1e8f0a45">MaxTopBlobs</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;    <span class="keywordflow">return</span> (this-&gt;<a class="code" href="classcaffe_1_1Layer.html#a7ed12bb2df25c887e41d7ea9557fc701">layer_param_</a>.pooling_param().pool() ==</div>
<div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;            PoolingParameter_PoolMethod_MAX) ? 2 : 1;</div>
<div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;  }</div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;</div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#ac84e5fb89223f6cc2577cea2c55cd388">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a027fcd5f61e6386819e8d02815f72e4a">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a8d3cf138cdbd059a0bab72361f0860b5">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#ad13b67ea00c891ce922604ab66eeeb0d">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;</div>
<div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;  <span class="keywordtype">int</span> kernel_h_, kernel_w_;</div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;  <span class="keywordtype">int</span> stride_h_, stride_w_;</div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;  <span class="keywordtype">int</span> pad_h_, pad_w_;</div>
<div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;  <span class="keywordtype">int</span> height_, width_;</div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;  <span class="keywordtype">int</span> pooled_height_, pooled_width_;</div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;  <span class="keywordtype">bool</span> global_pooling_;</div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> rand_idx_;</div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> max_idx_;</div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;};</div>
<div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;</div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;<span class="comment">/*</span></div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;<span class="comment"> * @brief cuDNN implementation of PoolingLayer.</span></div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;<span class="comment"> *        Fallback to PoolingLayer for CPU mode.</span></div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;<span class="comment">*/</span></div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;<span class="keyword">class </span>CuDNNPoolingLayer : <span class="keyword">public</span> PoolingLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;  <span class="keyword">explicit</span> CuDNNPoolingLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;      : PoolingLayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;  <span class="keyword">virtual</span> ~CuDNNPoolingLayer();</div>
<div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;  <span class="comment">// Currently, cuDNN does not support the extra top blob.</span></div>
<div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> MinTopBlobs()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> ExactNumTopBlobs()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;</div>
<div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;</div>
<div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;  cudnnTensorDescriptor_t bottom_desc_, top_desc_;</div>
<div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;  cudnnPoolingDescriptor_t  pooling_desc_;</div>
<div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;  cudnnPoolingMode_t        mode_;</div>
<div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;};</div>
<div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00602"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html">  602</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SPPLayer.html">SPPLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SPPLayer.html">SPPLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#acf2c8649f50afd4a31b32cefb06de09a">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#a9f54a92de230cde55b0dd4e996b9975e">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;</div>
<div class="line"><a name="l00611"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a71054cf06805c96615332b70fdb45a8b">  611</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1SPPLayer.html#a71054cf06805c96615332b70fdb45a8b">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;SPP&quot;</span>; }</div>
<div class="line"><a name="l00612"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#ab6912cfa8daa151407d024d5113e10b0">  612</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SPPLayer.html#ab6912cfa8daa151407d024d5113e10b0">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00613"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a698395fdd26563b18ea0fac07d4e8026">  613</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SPPLayer.html#a698395fdd26563b18ea0fac07d4e8026">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;</div>
<div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#a47c6a647030121c813845c657744547c">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#abf8677b68b68fb7c3c85f347d2bacc5d">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;  <span class="comment">// calculates the kernel and stride dimensions for the pooling layer,</span></div>
<div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;  <span class="comment">// returns a correctly configured LayerParameter for a PoolingLayer</span></div>
<div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;  <span class="keyword">virtual</span> LayerParameter GetPoolingParam(<span class="keyword">const</span> <span class="keywordtype">int</span> pyramid_level,</div>
<div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;      <span class="keyword">const</span> <span class="keywordtype">int</span> bottom_h, <span class="keyword">const</span> <span class="keywordtype">int</span> bottom_w, <span class="keyword">const</span> SPPParameter spp_param);</div>
<div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;</div>
<div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;  <span class="keywordtype">int</span> pyramid_height_;</div>
<div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;  <span class="keywordtype">int</span> bottom_h_, bottom_w_;</div>
<div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;  <span class="keywordtype">int</span> num_;</div>
<div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;  <span class="keywordtype">int</span> kernel_h_, kernel_w_;</div>
<div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;  <span class="keywordtype">int</span> pad_h_, pad_w_;</div>
<div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;  <span class="keywordtype">bool</span> reshaped_first_time_;</div>
<div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;</div>
<div class="line"><a name="l00634"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a9312cb2eb190ce25d9269d9319cf5e4b">  634</a></span>&#160;  shared_ptr&lt;SplitLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a9312cb2eb190ce25d9269d9319cf5e4b">split_layer_</a>;</div>
<div class="line"><a name="l00636"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#aa4c2a009d84367e72b98b3b8542e3a0f">  636</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#aa4c2a009d84367e72b98b3b8542e3a0f">split_top_vec_</a>;</div>
<div class="line"><a name="l00638"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a2c9e8e5e918431ccc43e8578419357c9">  638</a></span>&#160;  vector&lt;vector&lt;Blob&lt;Dtype&gt;*&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a2c9e8e5e918431ccc43e8578419357c9">pooling_bottom_vecs_</a>;</div>
<div class="line"><a name="l00640"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a4cde4ff418007bcbdd34f91c6abbea1f">  640</a></span>&#160;  vector&lt;shared_ptr&lt;PoolingLayer&lt;Dtype&gt; &gt; &gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a4cde4ff418007bcbdd34f91c6abbea1f">pooling_layers_</a>;</div>
<div class="line"><a name="l00642"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a4bddcb27cbc0e9e2d153d134d5f9d760">  642</a></span>&#160;  vector&lt;vector&lt;Blob&lt;Dtype&gt;*&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a4bddcb27cbc0e9e2d153d134d5f9d760">pooling_top_vecs_</a>;</div>
<div class="line"><a name="l00644"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#aed09b8f30c285651c726ac7ca186f93f">  644</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#aed09b8f30c285651c726ac7ca186f93f">pooling_outputs_</a>;</div>
<div class="line"><a name="l00646"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a765c32194d96177869e2b9028b1ff0d4">  646</a></span>&#160;  vector&lt;FlattenLayer&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a765c32194d96177869e2b9028b1ff0d4">flatten_layers_</a>;</div>
<div class="line"><a name="l00648"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a7460ba8ed098335de91cd8cab363d365">  648</a></span>&#160;  vector&lt;vector&lt;Blob&lt;Dtype&gt;*&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a7460ba8ed098335de91cd8cab363d365">flatten_top_vecs_</a>;</div>
<div class="line"><a name="l00650"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#afd42f96c91f26fe32427865a16796503">  650</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#afd42f96c91f26fe32427865a16796503">flatten_outputs_</a>;</div>
<div class="line"><a name="l00652"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a2874ca5b0c4d8f7d970c5a30768d2bc0">  652</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a2874ca5b0c4d8f7d970c5a30768d2bc0">concat_bottom_vec_</a>;</div>
<div class="line"><a name="l00654"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a02a9d50a48983fa0c6e42cafa85c1eb8">  654</a></span>&#160;  shared_ptr&lt;ConcatLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a02a9d50a48983fa0c6e42cafa85c1eb8">concat_layer_</a>;</div>
<div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;};</div>
<div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;</div>
<div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;}  <span class="comment">// namespace caffe</span></div>
<div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;</div>
<div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;<span class="preprocessor">#endif  // CAFFE_VISION_LAYERS_HPP_</span></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a0a2f112eec8a7cbd13888185d4fb36b0"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a0a2f112eec8a7cbd13888185d4fb36b0">caffe::BaseConvolutionLayer::kernel_shape_</a></div><div class="ttdeci">Blob&lt; int &gt; kernel_shape_</div><div class="ttdoc">The spatial dimensions of a filter kernel. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:72</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a7ab94b55392ad0500115d4a4d64b0a7c"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a7ab94b55392ad0500115d4a4d64b0a7c">caffe::LRNLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html">caffe::Im2colLayer</a></div><div class="ttdoc">A helper for image operations that rearranges image regions into column vectors. Used by ConvolutionL...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:336</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_ad13b67ea00c891ce922604ab66eeeb0d"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#ad13b67ea00c891ce922604ab66eeeb0d">caffe::PoolingLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_aab9056708727154a01866d17756c07cc"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#aab9056708727154a01866d17756c07cc">caffe::LRNLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:398</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html"><div class="ttname"><a href="classcaffe_1_1Layer.html">caffe::Layer</a></div><div class="ttdoc">An interface for the units of computation which can be composed into a Net. </div><div class="ttdef"><b>Definition:</b> layer.hpp:33</div></div>
<div class="ttc" id="namespacecaffe_html"><div class="ttname"><a href="namespacecaffe.html">caffe</a></div><div class="ttdoc">A layer factory that allows one to register layers. During runtime, registered layers could be called...</div><div class="ttdef"><b>Definition:</b> blob.hpp:15</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_afdcf33e7ec63ca5e476ffdc1da1f1fa0"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#afdcf33e7ec63ca5e476ffdc1da1f1fa0">caffe::ConvolutionLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:222</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a027fcd5f61e6386819e8d02815f72e4a"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a027fcd5f61e6386819e8d02815f72e4a">caffe::PoolingLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a7d8e7e7e1daf4ae1205e0bfe9fb9ac51"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a7d8e7e7e1daf4ae1205e0bfe9fb9ac51">caffe::LRNLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_add4567680b9466cbae5804da6a76e2ee"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#add4567680b9466cbae5804da6a76e2ee">caffe::BaseConvolutionLayer::EqualNumBottomTopBlobs</a></div><div class="ttdeci">virtual bool EqualNumBottomTopBlobs() const </div><div class="ttdoc">Returns true if the layer requires an equal number of bottom and top blobs. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:35</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a79735ab9fb43a53e4ca02e33a0b3f181"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a79735ab9fb43a53e4ca02e33a0b3f181">caffe::Im2colLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:95</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a6fc8f79729e17639d3b97781791e352d"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a6fc8f79729e17639d3b97781791e352d">caffe::PoolingLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:532</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a4cde4ff418007bcbdd34f91c6abbea1f"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a4cde4ff418007bcbdd34f91c6abbea1f">caffe::SPPLayer::pooling_layers_</a></div><div class="ttdeci">vector&lt; shared_ptr&lt; PoolingLayer&lt; Dtype &gt; &gt; &gt; pooling_layers_</div><div class="ttdoc">the internal Pooling layers of different kernel sizes </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:640</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a2a79eac8d3e85873c1fede0f1e8f0a45"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a2a79eac8d3e85873c1fede0f1e8f0a45">caffe::PoolingLayer::MaxTopBlobs</a></div><div class="ttdeci">virtual int MaxTopBlobs() const </div><div class="ttdoc">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:536</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_ac1591049f064bd88ccdc785a948ed4b2"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#ac1591049f064bd88ccdc785a948ed4b2">caffe::ConvolutionLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> conv_layer.cpp:45</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_acf2c8649f50afd4a31b32cefb06de09a"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#acf2c8649f50afd4a31b32cefb06de09a">caffe::SPPLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:65</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a7460ba8ed098335de91cd8cab363d365"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a7460ba8ed098335de91cd8cab363d365">caffe::SPPLayer::flatten_top_vecs_</a></div><div class="ttdeci">vector&lt; vector&lt; Blob&lt; Dtype &gt; * &gt; * &gt; flatten_top_vecs_</div><div class="ttdoc">top vector holders used in call to the underlying FlattenLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:648</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a4bddcb27cbc0e9e2d153d134d5f9d760"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a4bddcb27cbc0e9e2d153d134d5f9d760">caffe::SPPLayer::pooling_top_vecs_</a></div><div class="ttdeci">vector&lt; vector&lt; Blob&lt; Dtype &gt; * &gt; * &gt; pooling_top_vecs_</div><div class="ttdoc">top vector holders used in call to the underlying PoolingLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:642</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_aabbbcdeb646c188ac2137b003aa1c682"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#aabbbcdeb646c188ac2137b003aa1c682">caffe::LRNLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:397</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_aa4c2a009d84367e72b98b3b8542e3a0f"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#aa4c2a009d84367e72b98b3b8542e3a0f">caffe::SPPLayer::split_top_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; split_top_vec_</div><div class="ttdoc">top vector holder used in call to the underlying SplitLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:636</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a3716cda5f7d7e81f7d19cf4313d2bfc5"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a3716cda5f7d7e81f7d19cf4313d2bfc5">caffe::DeconvolutionLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> deconv_layer.cpp:27</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_ab6912cfa8daa151407d024d5113e10b0"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#ab6912cfa8daa151407d024d5113e10b0">caffe::SPPLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:612</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a6324d4ab918a7b09399aa85a8a03737d"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a6324d4ab918a7b09399aa85a8a03737d">caffe::BaseConvolutionLayer::input_shape</a></div><div class="ttdeci">int input_shape(int i)</div><div class="ttdoc">The spatial dimensions of the input. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:62</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a14a2760d3eafcfce766222f80e126fbe"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a14a2760d3eafcfce766222f80e126fbe">caffe::BaseConvolutionLayer::MinBottomBlobs</a></div><div class="ttdeci">virtual int MinBottomBlobs() const </div><div class="ttdoc">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is requi...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:33</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html">caffe::SPPLayer</a></div><div class="ttdoc">Does spatial pyramid pooling on the input image by taking the max, average, etc. within regions so th...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:602</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a1481790fce4361eefab8d78bbdd6f0ec"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a1481790fce4361eefab8d78bbdd6f0ec">caffe::Im2colLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a0b4899ba1d3fe6f041dd5cc88a380c44"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a0b4899ba1d3fe6f041dd5cc88a380c44">caffe::PoolingLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:531</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a5340f5b2e176beeb6c74428f05e06c7c"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a5340f5b2e176beeb6c74428f05e06c7c">caffe::Im2colLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_aac44aaa893e6fb774c1953b523180cea"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#aac44aaa893e6fb774c1953b523180cea">caffe::Im2colLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:345</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a47c6a647030121c813845c657744547c"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a47c6a647030121c813845c657744547c">caffe::SPPLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:188</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a55c335fac2a25ba438a8bf94497c53ec"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a55c335fac2a25ba438a8bf94497c53ec">caffe::Im2colLayer::pad_</a></div><div class="ttdeci">Blob&lt; int &gt; pad_</div><div class="ttdoc">The spatial dimensions of the padding. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:364</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a7498a14d8b7afa0bc85abe1dbd719135"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a7498a14d8b7afa0bc85abe1dbd719135">caffe::DeconvolutionLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:257</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a71054cf06805c96615332b70fdb45a8b"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a71054cf06805c96615332b70fdb45a8b">caffe::SPPLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:611</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_ac330e2fb166bca496edd277b0495f6eb"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#ac330e2fb166bca496edd277b0495f6eb">caffe::BaseConvolutionLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> base_conv_layer.cpp:173</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_abc72dca274a4ab42f7a12de4d1e8f8eb"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#abc72dca274a4ab42f7a12de4d1e8f8eb">caffe::PoolingLayer::MinTopBlobs</a></div><div class="ttdeci">virtual int MinTopBlobs() const </div><div class="ttdoc">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:533</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_a4de7682afbd816037aba5da3ec66a9bb"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#a4de7682afbd816037aba5da3ec66a9bb">caffe::ConvolutionLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html">caffe::BaseConvolutionLayer</a></div><div class="ttdoc">Abstract base class that factors out the BLAS code common to ConvolutionLayer and DeconvolutionLayer...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:24</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a71ff30a634527e2bf89c067d3c325979"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a71ff30a634527e2bf89c067d3c325979">caffe::LRNLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:166</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a73d7e780b38406dc3d840649cadf8f8a"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a73d7e780b38406dc3d840649cadf8f8a">caffe::Im2colLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a2c9e8e5e918431ccc43e8578419357c9"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a2c9e8e5e918431ccc43e8578419357c9">caffe::SPPLayer::pooling_bottom_vecs_</a></div><div class="ttdeci">vector&lt; vector&lt; Blob&lt; Dtype &gt; * &gt; * &gt; pooling_bottom_vecs_</div><div class="ttdoc">bottom vector holder used in call to the underlying PoolingLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:638</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a2874ca5b0c4d8f7d970c5a30768d2bc0"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a2874ca5b0c4d8f7d970c5a30768d2bc0">caffe::SPPLayer::concat_bottom_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; concat_bottom_vec_</div><div class="ttdoc">bottom vector holder used in call to the underlying ConcatLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:652</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a79a285029778124aca1c803d6cfec55f"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a79a285029778124aca1c803d6cfec55f">caffe::PoolingLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:82</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a35c6389878e77ab0a4a479e5441563cc"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a35c6389878e77ab0a4a479e5441563cc">caffe::BaseConvolutionLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> base_conv_layer.cpp:13</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_a8505044adc26d89aae3055022898c9ea"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#a8505044adc26d89aae3055022898c9ea">caffe::ConvolutionLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> conv_layer.cpp:27</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a897ead2823e9031863e2151e71229e35"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a897ead2823e9031863e2151e71229e35">caffe::BaseConvolutionLayer::pad_</a></div><div class="ttdeci">Blob&lt; int &gt; pad_</div><div class="ttdoc">The spatial dimensions of the padding. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:76</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_ace239a41953c9207efd1a9966570825c"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#ace239a41953c9207efd1a9966570825c">caffe::ConvolutionLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a765c32194d96177869e2b9028b1ff0d4"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a765c32194d96177869e2b9028b1ff0d4">caffe::SPPLayer::flatten_layers_</a></div><div class="ttdeci">vector&lt; FlattenLayer&lt; Dtype &gt; * &gt; flatten_layers_</div><div class="ttdoc">the internal Flatten layers that the Pooling layers feed into </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:646</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a5e1a46c850fcd18934309824208b31ff"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a5e1a46c850fcd18934309824208b31ff">caffe::PoolingLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:17</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a698395fdd26563b18ea0fac07d4e8026"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a698395fdd26563b18ea0fac07d4e8026">caffe::SPPLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:613</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_ae7ca62b2339f0691dadde24fd8acb481"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#ae7ca62b2339f0691dadde24fd8acb481">caffe::LRNLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:70</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a3b2dc21acbbe2e174cc83554469c29f5"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a3b2dc21acbbe2e174cc83554469c29f5">caffe::Im2colLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:146</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html_a7b4e4ccea08c7b8b15acc6829d5735f6"><div class="ttname"><a href="classcaffe_1_1Layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">caffe::Layer::Layer</a></div><div class="ttdeci">Layer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> layer.hpp:40</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_afd42f96c91f26fe32427865a16796503"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#afd42f96c91f26fe32427865a16796503">caffe::SPPLayer::flatten_outputs_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; flatten_outputs_</div><div class="ttdoc">flatten_outputs stores the outputs of the FlattenLayers </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:650</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a28dbd28c7542ae178973f0cb7b73cf8a"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a28dbd28c7542ae178973f0cb7b73cf8a">caffe::LRNLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:396</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a9dd3f4ea6e17fe155efe537c120a3de4"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a9dd3f4ea6e17fe155efe537c120a3de4">caffe::BaseConvolutionLayer::col_buffer_shape_</a></div><div class="ttdeci">vector&lt; int &gt; col_buffer_shape_</div><div class="ttdoc">The spatial dimensions of the col_buffer. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:80</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a9f54a92de230cde55b0dd4e996b9975e"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a9f54a92de230cde55b0dd4e996b9975e">caffe::SPPLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:146</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_aba3720be3f1f71f9e44fbfba90ae3ac0"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#aba3720be3f1f71f9e44fbfba90ae3ac0">caffe::Im2colLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:346</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a1ba7e8a8af945fba73da4a0c307fc4a0"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a1ba7e8a8af945fba73da4a0c307fc4a0">caffe::LRNLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_ad27360afd7729001b9e4f1d8c8401866"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#ad27360afd7729001b9e4f1d8c8401866">caffe::ConvolutionLayer::ConvolutionLayer</a></div><div class="ttdeci">ConvolutionLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:219</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html">caffe::DeconvolutionLayer</a></div><div class="ttdoc">Convolve the input with a bank of learned filters, and (optionally) add biases, treating filters and ...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:252</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a188e9ea1225c7f373f4d50e2a78dcec7"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a188e9ea1225c7f373f4d50e2a78dcec7">caffe::Im2colLayer::kernel_shape_</a></div><div class="ttdeci">Blob&lt; int &gt; kernel_shape_</div><div class="ttdoc">The spatial dimensions of a filter kernel. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:360</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html_a7ed12bb2df25c887e41d7ea9557fc701"><div class="ttname"><a href="classcaffe_1_1Layer.html#a7ed12bb2df25c887e41d7ea9557fc701">caffe::Layer::layer_param_</a></div><div class="ttdeci">LayerParameter layer_param_</div><div class="ttdef"><b>Definition:</b> layer.hpp:322</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html">caffe::PoolingLayer</a></div><div class="ttdoc">Pools the input image by taking the max, average, etc. within regions. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:378</div></div>
<div class="ttc" id="classcaffe_1_1SplitLayer_html"><div class="ttname"><a href="classcaffe_1_1SplitLayer.html">caffe::SplitLayer</a></div><div class="ttdoc">Creates a "split" path in the network by copying the bottom Blob into multiple top Blobs to be used b...</div><div class="ttdef"><b>Definition:</b> common_layers.hpp:663</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a49c3360133291f7e6593db36ec392d07"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a49c3360133291f7e6593db36ec392d07">caffe::DeconvolutionLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a2b4a2203001e8b5a5839955879551048"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a2b4a2203001e8b5a5839955879551048">caffe::DeconvolutionLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a02a9d50a48983fa0c6e42cafa85c1eb8"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a02a9d50a48983fa0c6e42cafa85c1eb8">caffe::SPPLayer::concat_layer_</a></div><div class="ttdeci">shared_ptr&lt; ConcatLayer&lt; Dtype &gt; &gt; concat_layer_</div><div class="ttdoc">the internal Concat layers that the Flatten layers feed into </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:654</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_af0892b61454ba086c4c74b78d910bf31"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#af0892b61454ba086c4c74b78d910bf31">caffe::BaseConvolutionLayer::output_shape_</a></div><div class="ttdeci">vector&lt; int &gt; output_shape_</div><div class="ttdoc">The spatial dimensions of the output. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:82</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_abf8677b68b68fb7c3c85f347d2bacc5d"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#abf8677b68b68fb7c3c85f347d2bacc5d">caffe::SPPLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:205</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_ad8c319e6628c7c523c2c6a991f9c631a"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#ad8c319e6628c7c523c2c6a991f9c631a">caffe::Im2colLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:117</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a9312cb2eb190ce25d9269d9319cf5e4b"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a9312cb2eb190ce25d9269d9319cf5e4b">caffe::SPPLayer::split_layer_</a></div><div class="ttdeci">shared_ptr&lt; SplitLayer&lt; Dtype &gt; &gt; split_layer_</div><div class="ttdoc">the internal Split layer that feeds the pooling layers </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:634</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html">caffe::ConvolutionLayer</a></div><div class="ttdoc">Convolves the input image with a bank of learned filters, and (optionally) adds biases. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:189</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a63756d6ef00f6491939e539094c21397"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a63756d6ef00f6491939e539094c21397">caffe::BaseConvolutionLayer::conv_input_shape_</a></div><div class="ttdeci">Blob&lt; int &gt; conv_input_shape_</div><div class="ttdoc">The spatial dimensions of the convolution input. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:78</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a081ed64d7b91d42f9f441f849db2a58d"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a081ed64d7b91d42f9f441f849db2a58d">caffe::DeconvolutionLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> deconv_layer.cpp:45</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a8d3cf138cdbd059a0bab72361f0860b5"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a8d3cf138cdbd059a0bab72361f0860b5">caffe::PoolingLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:233</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_ac84e5fb89223f6cc2577cea2c55cd388"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#ac84e5fb89223f6cc2577cea2c55cd388">caffe::PoolingLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:131</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_aa4aa1cfc956fa1ab3656ad2adf911f32"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#aa4aa1cfc956fa1ab3656ad2adf911f32">caffe::Im2colLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:347</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html">caffe::LRNLayer</a></div><div class="ttdoc">Normalize the input in a local region across or within feature maps. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:387</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_aed09b8f30c285651c726ac7ca186f93f"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#aed09b8f30c285651c726ac7ca186f93f">caffe::SPPLayer::pooling_outputs_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; pooling_outputs_</div><div class="ttdoc">pooling_outputs stores the outputs of the PoolingLayers </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:644</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_afb9baa8216b65a8124d4d1d2b719da0f"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#afb9baa8216b65a8124d4d1d2b719da0f">caffe::Im2colLayer::stride_</a></div><div class="ttdeci">Blob&lt; int &gt; stride_</div><div class="ttdoc">The spatial dimensions of the stride. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:362</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_af638d3d8e67c33443cb11cb000368e73"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#af638d3d8e67c33443cb11cb000368e73">caffe::BaseConvolutionLayer::stride_</a></div><div class="ttdeci">Blob&lt; int &gt; stride_</div><div class="ttdoc">The spatial dimensions of the stride. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:74</div></div>
<div class="ttc" id="classcaffe_1_1Blob_html"><div class="ttname"><a href="classcaffe_1_1Blob.html">caffe::Blob</a></div><div class="ttdoc">A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...</div><div class="ttdef"><b>Definition:</b> blob.hpp:25</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_accd0683191124da91a3667acc57e5ecd"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#accd0683191124da91a3667acc57e5ecd">caffe::BaseConvolutionLayer::MinTopBlobs</a></div><div class="ttdeci">virtual int MinTopBlobs() const </div><div class="ttdoc">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:34</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_ad3ae42eb16a0f55745211a44c806e316"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#ad3ae42eb16a0f55745211a44c806e316">caffe::LRNLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:94</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Oct 19 2015 15:25:08 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.9.1
</small></address>
</body>
</html>
