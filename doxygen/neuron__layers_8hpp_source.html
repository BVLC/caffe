<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>Caffe: include/caffe/neuron_layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_4b7f3da7c7b4301d805dae0326fb91b7.html">caffe</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">neuron_layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef CAFFE_NEURON_LAYERS_HPP_</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define CAFFE_NEURON_LAYERS_HPP_</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;caffe/blob.hpp&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;caffe/common.hpp&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;caffe/layer.hpp&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;caffe/proto/caffe.pb.h&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#define HDF5_DATA_DATASET_NAME &quot;data&quot;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#define HDF5_DATA_LABEL_NAME &quot;label&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecaffe.html">caffe</a> {</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00025"></a><span class="lineno"><a class="line" href="classcaffe_1_1NeuronLayer.html">   25</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;     : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1NeuronLayer.html#ae4d8d67cbdb21a2953d6dd36e4ec0572">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div>
<div class="line"><a name="l00032"></a><span class="lineno"><a class="line" href="classcaffe_1_1NeuronLayer.html#affbf79616942fe3679c99fb9d0ac84ad">   32</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1NeuronLayer.html#affbf79616942fe3679c99fb9d0ac84ad">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_NONE;</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;  }</div>
<div class="line"><a name="l00035"></a><span class="lineno"><a class="line" href="classcaffe_1_1NeuronLayer.html#a83678ec7f661054d36d83fa062b639b2">   35</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1NeuronLayer.html#a83678ec7f661054d36d83fa062b639b2">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00036"></a><span class="lineno"><a class="line" href="classcaffe_1_1NeuronLayer.html#a25dfa84e8b46705aa7a822e734b4f04f">   36</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1NeuronLayer.html#a25dfa84e8b46705aa7a822e734b4f04f">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;};</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html">   50</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1AbsValLayer.html">AbsValLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1AbsValLayer.html">AbsValLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a2a32937ff04041fb76672e1e5bb3e0aa">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;</div>
<div class="line"><a name="l00057"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html#ab556af9217c109c8dae9c8b4a462b4a5">   57</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1AbsValLayer.html#ab556af9217c109c8dae9c8b4a462b4a5">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_ABSVAL;</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;  }</div>
<div class="line"><a name="l00060"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html#a0e797616508e76aa9c2ce19a1b08dff0">   60</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a0e797616508e76aa9c2ce19a1b08dff0">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00061"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html#abddadbf826dc2ffaf22738804a484208">   61</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#abddadbf826dc2ffaf22738804a484208">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#ac379aad4369569903a8581dddc712584">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a196b6fa187cb2af02a5f56da149a8f54">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a4f00dd9e7c9460528565b35250867e40">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a2a472af34e7c5626ae4ba11840e908f6">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;};</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00111"></a><span class="lineno"><a class="line" href="classcaffe_1_1BNLLLayer.html">  111</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1BNLLLayer.html">BNLLLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1BNLLLayer.html">BNLLLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;</div>
<div class="line"><a name="l00116"></a><span class="lineno"><a class="line" href="classcaffe_1_1BNLLLayer.html#ac1f442cb3e3b39012a796972f95ae7c0">  116</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1BNLLLayer.html#ac1f442cb3e3b39012a796972f95ae7c0">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_BNLL;</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;  }</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#ab822f247ff7446dbb3bc8f0a20e99c15">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#a4d6b5fe6318885631092d9e42eeb013b">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#ab27e120ce0802b52ec32b78ce72107c2">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#a896db9d857e57940fddeb265da05d77d">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;};</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;</div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00161"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html">  161</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1DropoutLayer.html">DropoutLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a24cbddd4699b102a9555d3b8013c16d0">  169</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a24cbddd4699b102a9555d3b8013c16d0">DropoutLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a995adb2cbc22a5765e5a54344f5ea223">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a58af13f6e1c1f36fdb1b980e21f527d6">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;</div>
<div class="line"><a name="l00176"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a1f295c758a7b7deae92c3358528c8391">  176</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1DropoutLayer.html#a1f295c758a7b7deae92c3358528c8391">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_DROPOUT;</div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;  }</div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a2f17dd95bf4ed23bbbf7e4855c17b0ff">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a3d3645a8d78677024ba4657a5887ca16">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#ad903b09dd5f4a32eac8dfbdda2fded9d">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#afdc43d169cec7088819f3d333cbc7319">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;</div>
<div class="line"><a name="l00207"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a7a2c28420611a960a964e56acdbe2b47">  207</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;unsigned int&gt;</a> <a class="code" href="classcaffe_1_1DropoutLayer.html#a7a2c28420611a960a964e56acdbe2b47">rand_vec_</a>;</div>
<div class="line"><a name="l00209"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a8e9d88e6128a97101c27ce8a11158ca6">  209</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1DropoutLayer.html#a8e9d88e6128a97101c27ce8a11158ca6">threshold_</a>;</div>
<div class="line"><a name="l00211"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#ac8702c053de0fea389f5a0ded8cdc544">  211</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1DropoutLayer.html#ac8702c053de0fea389f5a0ded8cdc544">scale_</a>;</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;  <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uint_thres_;</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;};</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00221"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html">  221</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1PowerLayer.html">PowerLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00230"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#ab008c03c36436e1a0dac0fe1faa53c6d">  230</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1PowerLayer.html#ab008c03c36436e1a0dac0fe1faa53c6d">PowerLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#ad34527c12dbeee81099a969746525ede">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;</div>
<div class="line"><a name="l00235"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a1f72b855d7e9e990aeb69f27fc2926ce">  235</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1PowerLayer.html#a1f72b855d7e9e990aeb69f27fc2926ce">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_POWER;</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;  }</div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;</div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#ae0236ceba4e3c23a328b02df1be7ca6e">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#a1bdc10348d6264689b280eec48f8c064">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#a189f9f1baf6386f8c8d1d2c69b233cf2">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#a80282fcacdd180114e5a38e022293612">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;</div>
<div class="line"><a name="l00281"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a882ce133988e4dd72a10d87fec4c04c3">  281</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#a882ce133988e4dd72a10d87fec4c04c3">power_</a>;</div>
<div class="line"><a name="l00283"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a6684b2c6c2b2047d58c9d2809b86c39c">  283</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#a6684b2c6c2b2047d58c9d2809b86c39c">scale_</a>;</div>
<div class="line"><a name="l00285"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a3a3143c4d6735d12cb5a41b1cb623bc9">  285</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#a3a3143c4d6735d12cb5a41b1cb623bc9">shift_</a>;</div>
<div class="line"><a name="l00287"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#aa83169eaa1b573137aa6ed2b526879f0">  287</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#aa83169eaa1b573137aa6ed2b526879f0">diff_scale_</a>;</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;};</div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;</div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00295"></a><span class="lineno"><a class="line" href="classcaffe_1_1ReLULayer.html">  295</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ReLULayer.html">ReLULayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00303"></a><span class="lineno"><a class="line" href="classcaffe_1_1ReLULayer.html#aa6770fbbfd5e6f564c2ca19de7f7e712">  303</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ReLULayer.html#aa6770fbbfd5e6f564c2ca19de7f7e712">ReLULayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;</div>
<div class="line"><a name="l00306"></a><span class="lineno"><a class="line" href="classcaffe_1_1ReLULayer.html#a95c9dbcf1f149b78207da19266f88c9d">  306</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1ReLULayer.html#a95c9dbcf1f149b78207da19266f88c9d">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_RELU;</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;  }</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#ae9cfdc21df9d6479b0a35e55d32b75b9">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#a34412743e3034101ef744d91d78033ba">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#aad17699e86aa76fc5e6bd1fd3f16bf5c">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#aa91958d99784becb904ec71b4471e37f">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;};</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;</div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;<span class="keyword">class </span>CuDNNReLULayer : <span class="keyword">public</span> ReLULayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;  <span class="keyword">explicit</span> CuDNNReLULayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;      : ReLULayer&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;  <span class="keyword">virtual</span> ~CuDNNReLULayer();</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;Blob&lt;Dtype&gt;*&gt;* bottom);</div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;</div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;  cudnnTensor4dDescriptor_t bottom_desc_;</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;  cudnnTensor4dDescriptor_t top_desc_;</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;};</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00397"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidLayer.html">  397</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SigmoidLayer.html">SigmoidLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html">SigmoidLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;</div>
<div class="line"><a name="l00402"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidLayer.html#a14eca30ad9de8227022a21fe2f3fbc0e">  402</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1SigmoidLayer.html#a14eca30ad9de8227022a21fe2f3fbc0e">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_SIGMOID;</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;  }</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#aab48dac8b32e6390e3bfe3ac6e0331a0">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#a06bb3da74ac1060144dae0bb52d54e97">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#aa8b75c0f9f2534984fe2f66a4155da5f">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#ae21ad0a2e2566059ecdf79fd6a5ab918">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;};</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;</div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;<span class="keyword">class </span>CuDNNSigmoidLayer : <span class="keyword">public</span> SigmoidLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;  <span class="keyword">explicit</span> CuDNNSigmoidLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;      : SigmoidLayer&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;  <span class="keyword">virtual</span> ~CuDNNSigmoidLayer();</div>
<div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;</div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;Blob&lt;Dtype&gt;*&gt;* bottom);</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;</div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;  cudnnTensor4dDescriptor_t bottom_desc_;</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;  cudnnTensor4dDescriptor_t top_desc_;</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;};</div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00481"></a><span class="lineno"><a class="line" href="classcaffe_1_1TanHLayer.html">  481</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1TanHLayer.html">TanHLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1TanHLayer.html">TanHLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;</div>
<div class="line"><a name="l00486"></a><span class="lineno"><a class="line" href="classcaffe_1_1TanHLayer.html#acc472a059386ada567909934e89d4f5b">  486</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1TanHLayer.html#acc472a059386ada567909934e89d4f5b">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_TANH;</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;  }</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#a1850d9255f31ae140b6c6fd95bb3207d">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#a748aca2293035bcee7d60d786f5b1370">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;</div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#ac6aaca23ab6026720481c02b33da77e7">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#adf577c64cfa6d4d045428da005b77149">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;};</div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;</div>
<div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;</div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;<span class="keyword">class </span>CuDNNTanHLayer : <span class="keyword">public</span> TanHLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;  <span class="keyword">explicit</span> CuDNNTanHLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;      : TanHLayer&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;  <span class="keyword">virtual</span> ~CuDNNTanHLayer();</div>
<div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;</div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;      vector&lt;Blob&lt;Dtype&gt;*&gt;* top);</div>
<div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;Blob&lt;Dtype&gt;*&gt;* bottom);</div>
<div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;</div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;  cudnnTensor4dDescriptor_t bottom_desc_;</div>
<div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;  cudnnTensor4dDescriptor_t top_desc_;</div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;};</div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;</div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00563"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html">  563</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ThresholdLayer.html">ThresholdLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00571"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html#a18883bf3cb9c29828acd59b8216ba1de">  571</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#a18883bf3cb9c29828acd59b8216ba1de">ThresholdLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#ac7fa6d72dda38d3506de453bd716db62">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;</div>
<div class="line"><a name="l00576"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html#a93c0457c89fb42b145010632246e0415">  576</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1ThresholdLayer.html#a93c0457c89fb42b145010632246e0415">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_THRESHOLD;</div>
<div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;  }</div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;</div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#ac19ad5d2c231651d17479a2ccfada9c6">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#a56d69bd232349a8f52876151fa40b5c6">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00600"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html#afc8ede2b382bb659c07db24dbe60f6ba">  600</a></span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#afc8ede2b382bb659c07db24dbe60f6ba">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom) {</div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;    NOT_IMPLEMENTED;</div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;  }</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;  Dtype threshold_;</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;};</div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;}  <span class="comment">// namespace caffe</span></div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;<span class="preprocessor">#endif  // CAFFE_NEURON_LAYERS_HPP_</span></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html">caffe::ThresholdLayer</a></div><div class="ttdoc">Tests whether the input exceeds a threshold: outputs 1 for inputs above threshold; 0 otherwise...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:563</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a995adb2cbc22a5765e5a54344f5ea223"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a995adb2cbc22a5765e5a54344f5ea223">caffe::DropoutLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_abddadbf826dc2ffaf22738804a484208"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#abddadbf826dc2ffaf22738804a484208">caffe::AbsValLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:61</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a7a2c28420611a960a964e56acdbe2b47"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a7a2c28420611a960a964e56acdbe2b47">caffe::DropoutLayer::rand_vec_</a></div><div class="ttdeci">Blob&lt; unsigned int &gt; rand_vec_</div><div class="ttdoc">when divided by UINT_MAX, the randomly generated values  </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:207</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_a18883bf3cb9c29828acd59b8216ba1de"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#a18883bf3cb9c29828acd59b8216ba1de">caffe::ThresholdLayer::ThresholdLayer</a></div><div class="ttdeci">ThresholdLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:571</div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html_a83678ec7f661054d36d83fa062b639b2"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html#a83678ec7f661054d36d83fa062b639b2">caffe::NeuronLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:35</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a1f72b855d7e9e990aeb69f27fc2926ce"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a1f72b855d7e9e990aeb69f27fc2926ce">caffe::PowerLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:235</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_a4d6b5fe6318885631092d9e42eeb013b"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#a4d6b5fe6318885631092d9e42eeb013b">caffe::BNLLLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1Layer_html"><div class="ttname"><a href="classcaffe_1_1Layer.html">caffe::Layer</a></div><div class="ttdoc">An interface for the units of computation which can be composed into a Net. </div><div class="ttdef"><b>Definition:</b> layer.hpp:26</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_ac8702c053de0fea389f5a0ded8cdc544"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#ac8702c053de0fea389f5a0ded8cdc544">caffe::DropoutLayer::scale_</a></div><div class="ttdeci">Dtype scale_</div><div class="ttdoc">the scale for undropped inputs at train time  </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:211</div></div>
<div class="ttc" id="namespacecaffe_html"><div class="ttname"><a href="namespacecaffe.html">caffe</a></div><div class="ttdef"><b>Definition:</b> blob.hpp:9</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html">caffe::SigmoidLayer</a></div><div class="ttdoc">Sigmoid function non-linearity , a classic choice in neural networks. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:397</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a189f9f1baf6386f8c8d1d2c69b233cf2"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a189f9f1baf6386f8c8d1d2c69b233cf2">caffe::PowerLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the power inputs. </div><div class="ttdef"><b>Definition:</b> power_layer.cpp:46</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_afdc43d169cec7088819f3d333cbc7319"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#afdc43d169cec7088819f3d333cbc7319">caffe::DropoutLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_a1850d9255f31ae140b6c6fd95bb3207d"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#a1850d9255f31ae140b6c6fd95bb3207d">caffe::TanHLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> tanh_layer.cpp:13</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_aa8b75c0f9f2534984fe2f66a4155da5f"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#aa8b75c0f9f2534984fe2f66a4155da5f">caffe::SigmoidLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the sigmoid inputs. </div><div class="ttdef"><b>Definition:</b> sigmoid_layer.cpp:27</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html">caffe::AbsValLayer</a></div><div class="ttdoc">Computes . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:50</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_ab822f247ff7446dbb3bc8f0a20e99c15"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#ab822f247ff7446dbb3bc8f0a20e99c15">caffe::BNLLLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes  if ;  otherwise. </div><div class="ttdef"><b>Definition:</b> bnll_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a2a32937ff04041fb76672e1e5bb3e0aa"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a2a32937ff04041fb76672e1e5bb3e0aa">caffe::AbsValLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> absval_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a882ce133988e4dd72a10d87fec4c04c3"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a882ce133988e4dd72a10d87fec4c04c3">caffe::PowerLayer::power_</a></div><div class="ttdeci">Dtype power_</div><div class="ttdoc"> from layer_param_.power_param() </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:281</div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html_affbf79616942fe3679c99fb9d0ac84ad"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html#affbf79616942fe3679c99fb9d0ac84ad">caffe::NeuronLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:32</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_aa83169eaa1b573137aa6ed2b526879f0"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#aa83169eaa1b573137aa6ed2b526879f0">caffe::PowerLayer::diff_scale_</a></div><div class="ttdeci">Dtype diff_scale_</div><div class="ttdoc">Result of . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:287</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_ad34527c12dbeee81099a969746525ede"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#ad34527c12dbeee81099a969746525ede">caffe::PowerLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> power_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_ac7fa6d72dda38d3506de453bd716db62"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#ac7fa6d72dda38d3506de453bd716db62">caffe::ThresholdLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> threshold_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a24cbddd4699b102a9555d3b8013c16d0"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a24cbddd4699b102a9555d3b8013c16d0">caffe::DropoutLayer::DropoutLayer</a></div><div class="ttdeci">DropoutLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:169</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_ae0236ceba4e3c23a328b02df1be7ca6e"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#ae0236ceba4e3c23a328b02df1be7ca6e">caffe::PowerLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> power_layer.cpp:22</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_adf577c64cfa6d4d045428da005b77149"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#adf577c64cfa6d4d045428da005b77149">caffe::TanHLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html">caffe::ReLULayer</a></div><div class="ttdoc">Rectified Linear Unit non-linearity . The simple max is fast to compute, and the function does not sa...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:295</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_ab27e120ce0802b52ec32b78ce72107c2"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#ab27e120ce0802b52ec32b78ce72107c2">caffe::BNLLLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the BNLL inputs. </div><div class="ttdef"><b>Definition:</b> bnll_layer.cpp:25</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html">caffe::PowerLayer</a></div><div class="ttdoc">Computes , as specified by the scale , shift , and power . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:221</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_aa6770fbbfd5e6f564c2ca19de7f7e712"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#aa6770fbbfd5e6f564c2ca19de7f7e712">caffe::ReLULayer::ReLULayer</a></div><div class="ttdeci">ReLULayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:303</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_a06bb3da74ac1060144dae0bb52d54e97"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#a06bb3da74ac1060144dae0bb52d54e97">caffe::SigmoidLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_a34412743e3034101ef744d91d78033ba"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#a34412743e3034101ef744d91d78033ba">caffe::ReLULayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a1bdc10348d6264689b280eec48f8c064"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a1bdc10348d6264689b280eec48f8c064">caffe::PowerLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_ab556af9217c109c8dae9c8b4a462b4a5"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#ab556af9217c109c8dae9c8b4a462b4a5">caffe::AbsValLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:57</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_ac1f442cb3e3b39012a796972f95ae7c0"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#ac1f442cb3e3b39012a796972f95ae7c0">caffe::BNLLLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:116</div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html_a25dfa84e8b46705aa7a822e734b4f04f"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html#a25dfa84e8b46705aa7a822e734b4f04f">caffe::NeuronLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:36</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_a93c0457c89fb42b145010632246e0415"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#a93c0457c89fb42b145010632246e0415">caffe::ThresholdLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:576</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_a896db9d857e57940fddeb265da05d77d"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#a896db9d857e57940fddeb265da05d77d">caffe::BNLLLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a3a3143c4d6735d12cb5a41b1cb623bc9"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a3a3143c4d6735d12cb5a41b1cb623bc9">caffe::PowerLayer::shift_</a></div><div class="ttdeci">Dtype shift_</div><div class="ttdoc"> from layer_param_.power_param() </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:285</div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html_ae4d8d67cbdb21a2953d6dd36e4ec0572"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html#ae4d8d67cbdb21a2953d6dd36e4ec0572">caffe::NeuronLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> neuron_layer.cpp:9</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_ac379aad4369569903a8581dddc712584"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#ac379aad4369569903a8581dddc712584">caffe::AbsValLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes . </div><div class="ttdef"><b>Definition:</b> absval_layer.cpp:18</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_a56d69bd232349a8f52876151fa40b5c6"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#a56d69bd232349a8f52876151fa40b5c6">caffe::ThresholdLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html">caffe::BNLLLayer</a></div><div class="ttdoc">Computes  if ;  otherwise. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:111</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_ae21ad0a2e2566059ecdf79fd6a5ab918"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#ae21ad0a2e2566059ecdf79fd6a5ab918">caffe::SigmoidLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_aa91958d99784becb904ec71b4471e37f"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#aa91958d99784becb904ec71b4471e37f">caffe::ReLULayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_ae9cfdc21df9d6479b0a35e55d32b75b9"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#ae9cfdc21df9d6479b0a35e55d32b75b9">caffe::ReLULayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> relu_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a3d3645a8d78677024ba4657a5887ca16"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a3d3645a8d78677024ba4657a5887ca16">caffe::DropoutLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html">caffe::NeuronLayer</a></div><div class="ttdoc">An interface for layers that take one blob as input ( ) and produce one equally-sized blob as output ...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:25</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a6684b2c6c2b2047d58c9d2809b86c39c"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a6684b2c6c2b2047d58c9d2809b86c39c">caffe::PowerLayer::scale_</a></div><div class="ttdeci">Dtype scale_</div><div class="ttdoc"> from layer_param_.power_param() </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:283</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a80282fcacdd180114e5a38e022293612"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a80282fcacdd180114e5a38e022293612">caffe::PowerLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_a748aca2293035bcee7d60d786f5b1370"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#a748aca2293035bcee7d60d786f5b1370">caffe::TanHLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a1f295c758a7b7deae92c3358528c8391"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a1f295c758a7b7deae92c3358528c8391">caffe::DropoutLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:176</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_ab008c03c36436e1a0dac0fe1faa53c6d"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#ab008c03c36436e1a0dac0fe1faa53c6d">caffe::PowerLayer::PowerLayer</a></div><div class="ttdeci">PowerLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:230</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_ad903b09dd5f4a32eac8dfbdda2fded9d"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#ad903b09dd5f4a32eac8dfbdda2fded9d">caffe::DropoutLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:52</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_aad17699e86aa76fc5e6bd1fd3f16bf5c"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#aad17699e86aa76fc5e6bd1fd3f16bf5c">caffe::ReLULayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the ReLU inputs. </div><div class="ttdef"><b>Definition:</b> relu_layer.cpp:23</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_ac6aaca23ab6026720481c02b33da77e7"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#ac6aaca23ab6026720481c02b33da77e7">caffe::TanHLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the sigmoid inputs. </div><div class="ttdef"><b>Definition:</b> tanh_layer.cpp:26</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a2a472af34e7c5626ae4ba11840e908f6"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a2a472af34e7c5626ae4ba11840e908f6">caffe::AbsValLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a2f17dd95bf4ed23bbbf7e4855c17b0ff"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a2f17dd95bf4ed23bbbf7e4855c17b0ff">caffe::DropoutLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:34</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_acc472a059386ada567909934e89d4f5b"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#acc472a059386ada567909934e89d4f5b">caffe::TanHLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:486</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_afc8ede2b382bb659c07db24dbe60f6ba"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#afc8ede2b382bb659c07db24dbe60f6ba">caffe::ThresholdLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Not implemented (non-differentiable function) </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:600</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_a14eca30ad9de8227022a21fe2f3fbc0e"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#a14eca30ad9de8227022a21fe2f3fbc0e">caffe::SigmoidLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:402</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a4f00dd9e7c9460528565b35250867e40"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a4f00dd9e7c9460528565b35250867e40">caffe::AbsValLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the absolute value inputs. </div><div class="ttdef"><b>Definition:</b> absval_layer.cpp:26</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_a95c9dbcf1f149b78207da19266f88c9d"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#a95c9dbcf1f149b78207da19266f88c9d">caffe::ReLULayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:306</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a0e797616508e76aa9c2ce19a1b08dff0"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a0e797616508e76aa9c2ce19a1b08dff0">caffe::AbsValLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:60</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html">caffe::DropoutLayer</a></div><div class="ttdoc">During training only, sets a random portion of  to 0, adjusting the rest of the vector magnitude acco...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:161</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a58af13f6e1c1f36fdb1b980e21f527d6"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a58af13f6e1c1f36fdb1b980e21f527d6">caffe::DropoutLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:25</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_aab48dac8b32e6390e3bfe3ac6e0331a0"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#aab48dac8b32e6390e3bfe3ac6e0331a0">caffe::SigmoidLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> sigmoid_layer.cpp:16</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a8e9d88e6128a97101c27ce8a11158ca6"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a8e9d88e6128a97101c27ce8a11158ca6">caffe::DropoutLayer::threshold_</a></div><div class="ttdeci">Dtype threshold_</div><div class="ttdoc">the probability  of dropping any input </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:209</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_ac19ad5d2c231651d17479a2ccfada9c6"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#ac19ad5d2c231651d17479a2ccfada9c6">caffe::ThresholdLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> threshold_layer.cpp:17</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a196b6fa187cb2af02a5f56da149a8f54"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a196b6fa187cb2af02a5f56da149a8f54">caffe::AbsValLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html">caffe::TanHLayer</a></div><div class="ttdoc">TanH hyperbolic tangent non-linearity , popular in auto-encoders. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:481</div></div>
<div class="ttc" id="classcaffe_1_1Blob_html"><div class="ttname"><a href="classcaffe_1_1Blob.html">caffe::Blob</a></div><div class="ttdoc">A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...</div><div class="ttdef"><b>Definition:</b> blob.hpp:19</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Oct 20 2014 13:53:54 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.8
</small></address>
</body>
</html>
