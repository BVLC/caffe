<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9.1"/>
<title>Caffe: include/caffe/neuron_layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_4b7f3da7c7b4301d805dae0326fb91b7.html">caffe</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">neuron_layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef CAFFE_NEURON_LAYERS_HPP_</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define CAFFE_NEURON_LAYERS_HPP_</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;caffe/blob.hpp&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;caffe/common.hpp&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;caffe/layer.hpp&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;caffe/proto/caffe.pb.h&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#define HDF5_DATA_DATASET_NAME &quot;data&quot;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#define HDF5_DATA_LABEL_NAME &quot;label&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecaffe.html">caffe</a> {</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00025"></a><span class="lineno"><a class="line" href="classcaffe_1_1NeuronLayer.html">   25</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;     : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1NeuronLayer.html#a810f5f75b95ba7fdcb9d3e0e33e98a7e">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div>
<div class="line"><a name="l00032"></a><span class="lineno"><a class="line" href="classcaffe_1_1NeuronLayer.html#a83678ec7f661054d36d83fa062b639b2">   32</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1NeuronLayer.html#a83678ec7f661054d36d83fa062b639b2">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00033"></a><span class="lineno"><a class="line" href="classcaffe_1_1NeuronLayer.html#a25dfa84e8b46705aa7a822e734b4f04f">   33</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1NeuronLayer.html#a25dfa84e8b46705aa7a822e734b4f04f">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;};</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00047"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html">   47</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1AbsValLayer.html">AbsValLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1AbsValLayer.html">AbsValLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#acfb0677a17e9d3b4920ff62d3b0d800a">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div>
<div class="line"><a name="l00054"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html#a35f8a7f7ae11e115f5bd5dac67abf555">   54</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1AbsValLayer.html#a35f8a7f7ae11e115f5bd5dac67abf555">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;AbsVal&quot;</span>; }</div>
<div class="line"><a name="l00055"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html#a0e797616508e76aa9c2ce19a1b08dff0">   55</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a0e797616508e76aa9c2ce19a1b08dff0">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00056"></a><span class="lineno"><a class="line" href="classcaffe_1_1AbsValLayer.html#abddadbf826dc2ffaf22738804a484208">   56</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#abddadbf826dc2ffaf22738804a484208">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a6f9bc11e2459c982b44482305390dfc7">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#abe4da39f8844524e745a92d9766adccc">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a1d81dee85d0f354986e0f6f984974599">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AbsValLayer.html#a9dfa072afd31d0261763074be0a797ec">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;};</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00106"></a><span class="lineno"><a class="line" href="classcaffe_1_1BNLLLayer.html">  106</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1BNLLLayer.html">BNLLLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1BNLLLayer.html">BNLLLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;</div>
<div class="line"><a name="l00111"></a><span class="lineno"><a class="line" href="classcaffe_1_1BNLLLayer.html#a1847167dcb7582eea70e9a5e0d99754a">  111</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1BNLLLayer.html#a1847167dcb7582eea70e9a5e0d99754a">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;BNLL&quot;</span>; }</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#a6a3458c972d30459aaa46bae3d331ceb">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#ab21bef6df27bee7d7579d02c18d8dfb0">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#ab76de68096d3ad4a1ac57ea3dc96f4d1">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BNLLLayer.html#ae85a771b875a4acf2c8b72e51f2da1eb">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;};</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00154"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html">  154</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1DropoutLayer.html">DropoutLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a24cbddd4699b102a9555d3b8013c16d0">  162</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a24cbddd4699b102a9555d3b8013c16d0">DropoutLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a82bcd23115526808c79c807686945145">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a3d5bce578b44ba2a89c1d4f7205ed842">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;</div>
<div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a73b1eba29e00cea48e1faaf9818b5dba">  169</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1DropoutLayer.html#a73b1eba29e00cea48e1faaf9818b5dba">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Dropout&quot;</span>; }</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a0216a90061f76314ad9cbcff9a30de8c">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#ac5aa2af956f5860729cc168c71eaee06">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a867367c03a4ddada547c6f5d663cdc73">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DropoutLayer.html#a94686dbe949aee8316e905cc1d0dde2e">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;</div>
<div class="line"><a name="l00198"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a7a2c28420611a960a964e56acdbe2b47">  198</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;unsigned int&gt;</a> <a class="code" href="classcaffe_1_1DropoutLayer.html#a7a2c28420611a960a964e56acdbe2b47">rand_vec_</a>;</div>
<div class="line"><a name="l00200"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#a8e9d88e6128a97101c27ce8a11158ca6">  200</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1DropoutLayer.html#a8e9d88e6128a97101c27ce8a11158ca6">threshold_</a>;</div>
<div class="line"><a name="l00202"></a><span class="lineno"><a class="line" href="classcaffe_1_1DropoutLayer.html#ac8702c053de0fea389f5a0ded8cdc544">  202</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1DropoutLayer.html#ac8702c053de0fea389f5a0ded8cdc544">scale_</a>;</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;  <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> uint_thres_;</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;};</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00212"></a><span class="lineno"><a class="line" href="classcaffe_1_1ExpLayer.html">  212</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ExpLayer.html">ExpLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00222"></a><span class="lineno"><a class="line" href="classcaffe_1_1ExpLayer.html#a87a0fae261ad3d2c8947f463686a6de0">  222</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ExpLayer.html#a87a0fae261ad3d2c8947f463686a6de0">ExpLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ExpLayer.html#a5f88102bf4922032eeab431154a76710">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;</div>
<div class="line"><a name="l00227"></a><span class="lineno"><a class="line" href="classcaffe_1_1ExpLayer.html#a9fce31193341c4f70a65a8670121ab51">  227</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1ExpLayer.html#a9fce31193341c4f70a65a8670121ab51">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Exp&quot;</span>; }</div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;</div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ExpLayer.html#a56e2e4d6b5bc7eb5d7242f216bd70961">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ExpLayer.html#a3d6df27bfdb0aac45f5a7682e0ad7e3f">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ExpLayer.html#a691eeee0b9b2cbd1742e1fde7ba4d941">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ExpLayer.html#a2a1b0a09970aa4998f9f409609ed3712">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;</div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;  Dtype inner_scale_, outer_scale_;</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;};</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00276"></a><span class="lineno"><a class="line" href="classcaffe_1_1LogLayer.html">  276</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1LogLayer.html">LogLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00286"></a><span class="lineno"><a class="line" href="classcaffe_1_1LogLayer.html#aa6f92a0b12140d70a44a2bcb71bab552">  286</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1LogLayer.html#aa6f92a0b12140d70a44a2bcb71bab552">LogLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LogLayer.html#ab3f8854a38095f499e44ad8edf15b97b">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;</div>
<div class="line"><a name="l00291"></a><span class="lineno"><a class="line" href="classcaffe_1_1LogLayer.html#a35fe9f30bc494fb930aa0c7a19dadace">  291</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1LogLayer.html#a35fe9f30bc494fb930aa0c7a19dadace">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Log&quot;</span>; }</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LogLayer.html#a928ac703824992b46eb33210e049fdb6">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LogLayer.html#a6f9540e08387ce74287a6ee7abca8b1c">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LogLayer.html#adde7e59f9b065e518e6f254c408eb3ef">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LogLayer.html#ac4399854936b71196392d7736c162081">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;</div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;  Dtype base_scale_;</div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;  Dtype input_scale_, input_shift_;</div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;  Dtype backward_num_scale_;</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;};</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00342"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html">  342</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1PowerLayer.html">PowerLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00351"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#ab008c03c36436e1a0dac0fe1faa53c6d">  351</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1PowerLayer.html#ab008c03c36436e1a0dac0fe1faa53c6d">PowerLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#aa8f097be5b0f8d7dd104e88dc2a2e544">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;</div>
<div class="line"><a name="l00356"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a51ef88d67194814fe0f78dc1927f07a6">  356</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1PowerLayer.html#a51ef88d67194814fe0f78dc1927f07a6">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Power&quot;</span>; }</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#a35131891dc10f9092ec6dcd115fdb71b">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#ae942bd168cb49fb02b4d60a4aa2a0e64">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#a1eebf9d5152fc5926a051c9c97eba27e">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PowerLayer.html#a4471782e2f899cf2eaa5e47df2ea850e">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;</div>
<div class="line"><a name="l00400"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a882ce133988e4dd72a10d87fec4c04c3">  400</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#a882ce133988e4dd72a10d87fec4c04c3">power_</a>;</div>
<div class="line"><a name="l00402"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a6684b2c6c2b2047d58c9d2809b86c39c">  402</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#a6684b2c6c2b2047d58c9d2809b86c39c">scale_</a>;</div>
<div class="line"><a name="l00404"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#a3a3143c4d6735d12cb5a41b1cb623bc9">  404</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#a3a3143c4d6735d12cb5a41b1cb623bc9">shift_</a>;</div>
<div class="line"><a name="l00406"></a><span class="lineno"><a class="line" href="classcaffe_1_1PowerLayer.html#aa83169eaa1b573137aa6ed2b526879f0">  406</a></span>&#160;  Dtype <a class="code" href="classcaffe_1_1PowerLayer.html#aa83169eaa1b573137aa6ed2b526879f0">diff_scale_</a>;</div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;};</div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;</div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00414"></a><span class="lineno"><a class="line" href="classcaffe_1_1ReLULayer.html">  414</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ReLULayer.html">ReLULayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00422"></a><span class="lineno"><a class="line" href="classcaffe_1_1ReLULayer.html#aa6770fbbfd5e6f564c2ca19de7f7e712">  422</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ReLULayer.html#aa6770fbbfd5e6f564c2ca19de7f7e712">ReLULayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;</div>
<div class="line"><a name="l00425"></a><span class="lineno"><a class="line" href="classcaffe_1_1ReLULayer.html#a80f429ddb1942f7c5e3d6530c69f9308">  425</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1ReLULayer.html#a80f429ddb1942f7c5e3d6530c69f9308">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;ReLU&quot;</span>; }</div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;</div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#aab91a81886843afbe167881b16432947">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#addcdd688e5f137181dc9f28c01252d75">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#a2a8eacfffacb2d71583d6f837c19db8b">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ReLULayer.html#ade10fe5dc516efca618ecfd0d9562679">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;};</div>
<div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;</div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;<span class="keyword">class </span>CuDNNReLULayer : <span class="keyword">public</span> ReLULayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;  <span class="keyword">explicit</span> CuDNNReLULayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;      : ReLULayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;  <span class="keyword">virtual</span> ~CuDNNReLULayer();</div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;</div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;</div>
<div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;  cudnnTensorDescriptor_t bottom_desc_;</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;  cudnnTensorDescriptor_t top_desc_;</div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;};</div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;</div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00515"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidLayer.html">  515</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SigmoidLayer.html">SigmoidLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html">SigmoidLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;</div>
<div class="line"><a name="l00520"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidLayer.html#a3d9b66404ad6d8b65bb0bba662cb1189">  520</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1SigmoidLayer.html#a3d9b66404ad6d8b65bb0bba662cb1189">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Sigmoid&quot;</span>; }</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#a36dc176a1f3769219adc7f2de8147f19">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#abaabf3202ba640865500f751f2386c20">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;</div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#afde12451a26311e04a108fb21f79f134">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html#a52ed0e3039b4babf1d559e6c4a809d37">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;};</div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;</div>
<div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;</div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;<span class="keyword">class </span>CuDNNSigmoidLayer : <span class="keyword">public</span> SigmoidLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;  <span class="keyword">explicit</span> CuDNNSigmoidLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;      : SigmoidLayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;  <span class="keyword">virtual</span> ~CuDNNSigmoidLayer();</div>
<div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;</div>
<div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;</div>
<div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;  cudnnTensorDescriptor_t bottom_desc_;</div>
<div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;  cudnnTensorDescriptor_t top_desc_;</div>
<div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;};</div>
<div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;</div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00598"></a><span class="lineno"><a class="line" href="classcaffe_1_1TanHLayer.html">  598</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1TanHLayer.html">TanHLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1TanHLayer.html">TanHLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;</div>
<div class="line"><a name="l00603"></a><span class="lineno"><a class="line" href="classcaffe_1_1TanHLayer.html#a562648aab7ee89a9d7059d8894b9b223">  603</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1TanHLayer.html#a562648aab7ee89a9d7059d8894b9b223">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;TanH&quot;</span>; }</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#ab6a45bd7a84b1b725544082a7bdb583c">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#a469b993d4f5a45f888d16b27f091eb02">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;</div>
<div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#a74cf935710a47152e3596b54e68e6e68">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1TanHLayer.html#a0d0baef23ef5f3ccfeef950832ecad0e">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;};</div>
<div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;</div>
<div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;</div>
<div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;<span class="keyword">class </span>CuDNNTanHLayer : <span class="keyword">public</span> TanHLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;  <span class="keyword">explicit</span> CuDNNTanHLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;      : TanHLayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;  <span class="keyword">virtual</span> ~CuDNNTanHLayer();</div>
<div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;</div>
<div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;</div>
<div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;  cudnnTensorDescriptor_t bottom_desc_;</div>
<div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;  cudnnTensorDescriptor_t top_desc_;</div>
<div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;};</div>
<div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;</div>
<div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00679"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html">  679</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ThresholdLayer.html">ThresholdLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00687"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html#a18883bf3cb9c29828acd59b8216ba1de">  687</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#a18883bf3cb9c29828acd59b8216ba1de">ThresholdLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#a9568049d6c53efcd64829742e4847bc9">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;</div>
<div class="line"><a name="l00692"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html#a76736a76d69ef537f252d36adeadf476">  692</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1ThresholdLayer.html#a76736a76d69ef537f252d36adeadf476">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Threshold&quot;</span>; }</div>
<div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;</div>
<div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#a57d3757107bc9b21379dc56b4f96643e">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#ae364101c13558996e4923bbb249504c7">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00714"></a><span class="lineno"><a class="line" href="classcaffe_1_1ThresholdLayer.html#aa0da8e40847b007faa4e84cc1047e38b">  714</a></span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ThresholdLayer.html#aa0da8e40847b007faa4e84cc1047e38b">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom) {</div>
<div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;    NOT_IMPLEMENTED;</div>
<div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;  }</div>
<div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;</div>
<div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;  Dtype threshold_;</div>
<div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;};</div>
<div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;</div>
<div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00731"></a><span class="lineno"><a class="line" href="classcaffe_1_1PReLULayer.html">  731</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1PReLULayer.html">PReLULayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00741"></a><span class="lineno"><a class="line" href="classcaffe_1_1PReLULayer.html#a9d164a537a2f77b4143d2491f4809732">  741</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1PReLULayer.html#a9d164a537a2f77b4143d2491f4809732">PReLULayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;      : <a class="code" href="classcaffe_1_1NeuronLayer.html">NeuronLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;</div>
<div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PReLULayer.html#ad80124134d59ef7eff37601c953f09ef">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;</div>
<div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PReLULayer.html#a49e457fde8b31a97978718345d0ff53a">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;</div>
<div class="line"><a name="l00750"></a><span class="lineno"><a class="line" href="classcaffe_1_1PReLULayer.html#a5ef92d5ceec05bae89ea4c72fabe6dc5">  750</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1PReLULayer.html#a5ef92d5ceec05bae89ea4c72fabe6dc5">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;PReLU&quot;</span>; }</div>
<div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;</div>
<div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PReLULayer.html#a67128902b4ef419ccfb23db2d49b9ace">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PReLULayer.html#af0807c358c94f9947dc42876eca413ce">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;</div>
<div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PReLULayer.html#a29a2da9c4d5efdb81e26663d17ca7ce9">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00798"></a><span class="lineno">  798</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PReLULayer.html#a16ab90570492b7e74faae68a0ee986bb">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;</div>
<div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;  <span class="keywordtype">bool</span> channel_shared_;</div>
<div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> multiplier_;  <span class="comment">// dot multiplier for backward computation of params</span></div>
<div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> backward_buff_;  <span class="comment">// temporary buffer for backward computation</span></div>
<div class="line"><a name="l00804"></a><span class="lineno">  804</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> bottom_memory_;  <span class="comment">// memory for in-place computation</span></div>
<div class="line"><a name="l00805"></a><span class="lineno">  805</span>&#160;};</div>
<div class="line"><a name="l00806"></a><span class="lineno">  806</span>&#160;</div>
<div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;}  <span class="comment">// namespace caffe</span></div>
<div class="line"><a name="l00808"></a><span class="lineno">  808</span>&#160;</div>
<div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;<span class="preprocessor">#endif  // CAFFE_NEURON_LAYERS_HPP_</span></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html">caffe::ThresholdLayer</a></div><div class="ttdoc">Tests whether the input exceeds a threshold: outputs 1 for inputs above threshold; 0 otherwise...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:679</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_abddadbf826dc2ffaf22738804a484208"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#abddadbf826dc2ffaf22738804a484208">caffe::AbsValLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:56</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a7a2c28420611a960a964e56acdbe2b47"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a7a2c28420611a960a964e56acdbe2b47">caffe::DropoutLayer::rand_vec_</a></div><div class="ttdeci">Blob&lt; unsigned int &gt; rand_vec_</div><div class="ttdoc">when divided by UINT_MAX, the randomly generated values  </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:198</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_a36dc176a1f3769219adc7f2de8147f19"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#a36dc176a1f3769219adc7f2de8147f19">caffe::SigmoidLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> sigmoid_layer.cpp:16</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_a18883bf3cb9c29828acd59b8216ba1de"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#a18883bf3cb9c29828acd59b8216ba1de">caffe::ThresholdLayer::ThresholdLayer</a></div><div class="ttdeci">ThresholdLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:687</div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html_a83678ec7f661054d36d83fa062b639b2"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html#a83678ec7f661054d36d83fa062b639b2">caffe::NeuronLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:32</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_a0d0baef23ef5f3ccfeef950832ecad0e"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#a0d0baef23ef5f3ccfeef950832ecad0e">caffe::TanHLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html"><div class="ttname"><a href="classcaffe_1_1Layer.html">caffe::Layer</a></div><div class="ttdoc">An interface for the units of computation which can be composed into a Net. </div><div class="ttdef"><b>Definition:</b> layer.hpp:27</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_ac8702c053de0fea389f5a0ded8cdc544"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#ac8702c053de0fea389f5a0ded8cdc544">caffe::DropoutLayer::scale_</a></div><div class="ttdeci">Dtype scale_</div><div class="ttdoc">the scale for undropped inputs at train time  </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:202</div></div>
<div class="ttc" id="namespacecaffe_html"><div class="ttname"><a href="namespacecaffe.html">caffe</a></div><div class="ttdoc">A layer factory that allows one to register layers. During runtime, registered layers could be called...</div><div class="ttdef"><b>Definition:</b> blob.hpp:15</div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html_a56e2e4d6b5bc7eb5d7242f216bd70961"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html#a56e2e4d6b5bc7eb5d7242f216bd70961">caffe::ExpLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> exp_layer.cpp:32</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_a3d9b66404ad6d8b65bb0bba662cb1189"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#a3d9b66404ad6d8b65bb0bba662cb1189">caffe::SigmoidLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:520</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html">caffe::SigmoidLayer</a></div><div class="ttdoc">Sigmoid function non-linearity , a classic choice in neural networks. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:515</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_ac5aa2af956f5860729cc168c71eaee06"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#ac5aa2af956f5860729cc168c71eaee06">caffe::DropoutLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_a57d3757107bc9b21379dc56b4f96643e"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#a57d3757107bc9b21379dc56b4f96643e">caffe::ThresholdLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> threshold_layer.cpp:17</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_ab76de68096d3ad4a1ac57ea3dc96f4d1"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#ab76de68096d3ad4a1ac57ea3dc96f4d1">caffe::BNLLLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the BNLL inputs. </div><div class="ttdef"><b>Definition:</b> bnll_layer.cpp:25</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_aa8f097be5b0f8d7dd104e88dc2a2e544"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#aa8f097be5b0f8d7dd104e88dc2a2e544">caffe::PowerLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> power_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html_a6f9540e08387ce74287a6ee7abca8b1c"><div class="ttname"><a href="classcaffe_1_1LogLayer.html#a6f9540e08387ce74287a6ee7abca8b1c">caffe::LogLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_ae942bd168cb49fb02b4d60a4aa2a0e64"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#ae942bd168cb49fb02b4d60a4aa2a0e64">caffe::PowerLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html_a810f5f75b95ba7fdcb9d3e0e33e98a7e"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html#a810f5f75b95ba7fdcb9d3e0e33e98a7e">caffe::NeuronLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> neuron_layer.cpp:9</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_ab6a45bd7a84b1b725544082a7bdb583c"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#ab6a45bd7a84b1b725544082a7bdb583c">caffe::TanHLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> tanh_layer.cpp:13</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a1d81dee85d0f354986e0f6f984974599"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a1d81dee85d0f354986e0f6f984974599">caffe::AbsValLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the absolute value inputs. </div><div class="ttdef"><b>Definition:</b> absval_layer.cpp:26</div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html_a2a1b0a09970aa4998f9f409609ed3712"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html#a2a1b0a09970aa4998f9f409609ed3712">caffe::ExpLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a4471782e2f899cf2eaa5e47df2ea850e"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a4471782e2f899cf2eaa5e47df2ea850e">caffe::PowerLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html">caffe::AbsValLayer</a></div><div class="ttdoc">Computes . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:47</div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html">caffe::ExpLayer</a></div><div class="ttdoc">Computes , as specified by the scale , shift , and base . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:212</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_a562648aab7ee89a9d7059d8894b9b223"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#a562648aab7ee89a9d7059d8894b9b223">caffe::TanHLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:603</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a882ce133988e4dd72a10d87fec4c04c3"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a882ce133988e4dd72a10d87fec4c04c3">caffe::PowerLayer::power_</a></div><div class="ttdeci">Dtype power_</div><div class="ttdoc"> from layer_param_.power_param() </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:400</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_aa83169eaa1b573137aa6ed2b526879f0"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#aa83169eaa1b573137aa6ed2b526879f0">caffe::PowerLayer::diff_scale_</a></div><div class="ttdeci">Dtype diff_scale_</div><div class="ttdoc">Result of . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:406</div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html_a35fe9f30bc494fb930aa0c7a19dadace"><div class="ttname"><a href="classcaffe_1_1LogLayer.html#a35fe9f30bc494fb930aa0c7a19dadace">caffe::LogLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:291</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a51ef88d67194814fe0f78dc1927f07a6"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a51ef88d67194814fe0f78dc1927f07a6">caffe::PowerLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:356</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a24cbddd4699b102a9555d3b8013c16d0"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a24cbddd4699b102a9555d3b8013c16d0">caffe::DropoutLayer::DropoutLayer</a></div><div class="ttdeci">DropoutLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:162</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_ae364101c13558996e4923bbb249504c7"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#ae364101c13558996e4923bbb249504c7">caffe::ThresholdLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html_ab3f8854a38095f499e44ad8edf15b97b"><div class="ttname"><a href="classcaffe_1_1LogLayer.html#ab3f8854a38095f499e44ad8edf15b97b">caffe::LogLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> log_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_a49e457fde8b31a97978718345d0ff53a"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#a49e457fde8b31a97978718345d0ff53a">caffe::PReLULayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> prelu_layer.cpp:54</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html">caffe::ReLULayer</a></div><div class="ttdoc">Rectified Linear Unit non-linearity . The simple max is fast to compute, and the function does not sa...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:414</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_aa0da8e40847b007faa4e84cc1047e38b"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#aa0da8e40847b007faa4e84cc1047e38b">caffe::ThresholdLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Not implemented (non-differentiable function) </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:714</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_a52ed0e3039b4babf1d559e6c4a809d37"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#a52ed0e3039b4babf1d559e6c4a809d37">caffe::SigmoidLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html">caffe::PowerLayer</a></div><div class="ttdoc">Computes , as specified by the scale , shift , and power . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:342</div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html_a3d6df27bfdb0aac45f5a7682e0ad7e3f"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html#a3d6df27bfdb0aac45f5a7682e0ad7e3f">caffe::ExpLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_aa6770fbbfd5e6f564c2ca19de7f7e712"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#aa6770fbbfd5e6f564c2ca19de7f7e712">caffe::ReLULayer::ReLULayer</a></div><div class="ttdeci">ReLULayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:422</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a82bcd23115526808c79c807686945145"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a82bcd23115526808c79c807686945145">caffe::DropoutLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_afde12451a26311e04a108fb21f79f134"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#afde12451a26311e04a108fb21f79f134">caffe::SigmoidLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the sigmoid inputs. </div><div class="ttdef"><b>Definition:</b> sigmoid_layer.cpp:27</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a94686dbe949aee8316e905cc1d0dde2e"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a94686dbe949aee8316e905cc1d0dde2e">caffe::DropoutLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_ad80124134d59ef7eff37601c953f09ef"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#ad80124134d59ef7eff37601c953f09ef">caffe::PReLULayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> prelu_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html_a25dfa84e8b46705aa7a822e734b4f04f"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html#a25dfa84e8b46705aa7a822e734b4f04f">caffe::NeuronLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:33</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_a5ef92d5ceec05bae89ea4c72fabe6dc5"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#a5ef92d5ceec05bae89ea4c72fabe6dc5">caffe::PReLULayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:750</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_a2a8eacfffacb2d71583d6f837c19db8b"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#a2a8eacfffacb2d71583d6f837c19db8b">caffe::ReLULayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the ReLU inputs. </div><div class="ttdef"><b>Definition:</b> relu_layer.cpp:23</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a3a3143c4d6735d12cb5a41b1cb623bc9"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a3a3143c4d6735d12cb5a41b1cb623bc9">caffe::PowerLayer::shift_</a></div><div class="ttdeci">Dtype shift_</div><div class="ttdoc"> from layer_param_.power_param() </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:404</div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html_ac4399854936b71196392d7736c162081"><div class="ttname"><a href="classcaffe_1_1LogLayer.html#ac4399854936b71196392d7736c162081">caffe::LogLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a1eebf9d5152fc5926a051c9c97eba27e"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a1eebf9d5152fc5926a051c9c97eba27e">caffe::PowerLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the power inputs. </div><div class="ttdef"><b>Definition:</b> power_layer.cpp:46</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html">caffe::BNLLLayer</a></div><div class="ttdoc">Computes  if ;  otherwise. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:106</div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html"><div class="ttname"><a href="classcaffe_1_1LogLayer.html">caffe::LogLayer</a></div><div class="ttdoc">Computes , as specified by the scale , shift , and base . </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:276</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a0216a90061f76314ad9cbcff9a30de8c"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a0216a90061f76314ad9cbcff9a30de8c">caffe::DropoutLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:34</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html_abaabf3202ba640865500f751f2386c20"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html#abaabf3202ba640865500f751f2386c20">caffe::SigmoidLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_a80f429ddb1942f7c5e3d6530c69f9308"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#a80f429ddb1942f7c5e3d6530c69f9308">caffe::ReLULayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:425</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a73b1eba29e00cea48e1faaf9818b5dba"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a73b1eba29e00cea48e1faaf9818b5dba">caffe::DropoutLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:169</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_a29a2da9c4d5efdb81e26663d17ca7ce9"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#a29a2da9c4d5efdb81e26663d17ca7ce9">caffe::PReLULayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the PReLU inputs. </div><div class="ttdef"><b>Definition:</b> prelu_layer.cpp:91</div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html_a691eeee0b9b2cbd1742e1fde7ba4d941"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html#a691eeee0b9b2cbd1742e1fde7ba4d941">caffe::ExpLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the exp inputs. </div><div class="ttdef"><b>Definition:</b> exp_layer.cpp:49</div></div>
<div class="ttc" id="classcaffe_1_1NeuronLayer_html"><div class="ttname"><a href="classcaffe_1_1NeuronLayer.html">caffe::NeuronLayer</a></div><div class="ttdoc">An interface for layers that take one blob as input ( ) and produce one equally-sized blob as output ...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:25</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a6684b2c6c2b2047d58c9d2809b86c39c"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a6684b2c6c2b2047d58c9d2809b86c39c">caffe::PowerLayer::scale_</a></div><div class="ttdeci">Dtype scale_</div><div class="ttdoc"> from layer_param_.power_param() </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:402</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a867367c03a4ddada547c6f5d663cdc73"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a867367c03a4ddada547c6f5d663cdc73">caffe::DropoutLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:52</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a9dfa072afd31d0261763074be0a797ec"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a9dfa072afd31d0261763074be0a797ec">caffe::AbsValLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html">caffe::PReLULayer</a></div><div class="ttdoc">Parameterized Rectified Linear Unit non-linearity . The differences from ReLULayer are 1) negative sl...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:731</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_a16ab90570492b7e74faae68a0ee986bb"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#a16ab90570492b7e74faae68a0ee986bb">caffe::PReLULayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_ab008c03c36436e1a0dac0fe1faa53c6d"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#ab008c03c36436e1a0dac0fe1faa53c6d">caffe::PowerLayer::PowerLayer</a></div><div class="ttdeci">PowerLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:351</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_addcdd688e5f137181dc9f28c01252d75"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#addcdd688e5f137181dc9f28c01252d75">caffe::ReLULayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html_aa6f92a0b12140d70a44a2bcb71bab552"><div class="ttname"><a href="classcaffe_1_1LogLayer.html#aa6f92a0b12140d70a44a2bcb71bab552">caffe::LogLayer::LogLayer</a></div><div class="ttdeci">LogLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:286</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_ade10fe5dc516efca618ecfd0d9562679"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#ade10fe5dc516efca618ecfd0d9562679">caffe::ReLULayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_ab21bef6df27bee7d7579d02c18d8dfb0"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#ab21bef6df27bee7d7579d02c18d8dfb0">caffe::BNLLLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_acfb0677a17e9d3b4920ff62d3b0d800a"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#acfb0677a17e9d3b4920ff62d3b0d800a">caffe::AbsValLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> absval_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_a76736a76d69ef537f252d36adeadf476"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#a76736a76d69ef537f252d36adeadf476">caffe::ThresholdLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:692</div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html_a9fce31193341c4f70a65a8670121ab51"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html#a9fce31193341c4f70a65a8670121ab51">caffe::ExpLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:227</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_a67128902b4ef419ccfb23db2d49b9ace"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#a67128902b4ef419ccfb23db2d49b9ace">caffe::PReLULayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> prelu_layer.cpp:66</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a6f9bc11e2459c982b44482305390dfc7"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a6f9bc11e2459c982b44482305390dfc7">caffe::AbsValLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Computes . </div><div class="ttdef"><b>Definition:</b> absval_layer.cpp:18</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_ae85a771b875a4acf2c8b72e51f2da1eb"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#ae85a771b875a4acf2c8b72e51f2da1eb">caffe::BNLLLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1PowerLayer_html_a35131891dc10f9092ec6dcd115fdb71b"><div class="ttname"><a href="classcaffe_1_1PowerLayer.html#a35131891dc10f9092ec6dcd115fdb71b">caffe::PowerLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> power_layer.cpp:22</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_a9d164a537a2f77b4143d2491f4809732"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#a9d164a537a2f77b4143d2491f4809732">caffe::PReLULayer::PReLULayer</a></div><div class="ttdeci">PReLULayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:741</div></div>
<div class="ttc" id="classcaffe_1_1ReLULayer_html_aab91a81886843afbe167881b16432947"><div class="ttname"><a href="classcaffe_1_1ReLULayer.html#aab91a81886843afbe167881b16432947">caffe::ReLULayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> relu_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_a469b993d4f5a45f888d16b27f091eb02"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#a469b993d4f5a45f888d16b27f091eb02">caffe::TanHLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html_a928ac703824992b46eb33210e049fdb6"><div class="ttname"><a href="classcaffe_1_1LogLayer.html#a928ac703824992b46eb33210e049fdb6">caffe::LogLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdef"><b>Definition:</b> log_layer.cpp:36</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a3d5bce578b44ba2a89c1d4f7205ed842"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a3d5bce578b44ba2a89c1d4f7205ed842">caffe::DropoutLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> dropout_layer.cpp:25</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_a6a3458c972d30459aaa46bae3d331ceb"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#a6a3458c972d30459aaa46bae3d331ceb">caffe::BNLLLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Computes  if ;  otherwise. </div><div class="ttdef"><b>Definition:</b> bnll_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1PReLULayer_html_af0807c358c94f9947dc42876eca413ce"><div class="ttname"><a href="classcaffe_1_1PReLULayer.html#af0807c358c94f9947dc42876eca413ce">caffe::PReLULayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a35f8a7f7ae11e115f5bd5dac67abf555"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a35f8a7f7ae11e115f5bd5dac67abf555">caffe::AbsValLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:54</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_a0e797616508e76aa9c2ce19a1b08dff0"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#a0e797616508e76aa9c2ce19a1b08dff0">caffe::AbsValLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:55</div></div>
<div class="ttc" id="classcaffe_1_1AbsValLayer_html_abe4da39f8844524e745a92d9766adccc"><div class="ttname"><a href="classcaffe_1_1AbsValLayer.html#abe4da39f8844524e745a92d9766adccc">caffe::AbsValLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html_a87a0fae261ad3d2c8947f463686a6de0"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html#a87a0fae261ad3d2c8947f463686a6de0">caffe::ExpLayer::ExpLayer</a></div><div class="ttdeci">ExpLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:222</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html">caffe::DropoutLayer</a></div><div class="ttdoc">During training only, sets a random portion of  to 0, adjusting the rest of the vector magnitude acco...</div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:154</div></div>
<div class="ttc" id="classcaffe_1_1ThresholdLayer_html_a9568049d6c53efcd64829742e4847bc9"><div class="ttname"><a href="classcaffe_1_1ThresholdLayer.html#a9568049d6c53efcd64829742e4847bc9">caffe::ThresholdLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> threshold_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1DropoutLayer_html_a8e9d88e6128a97101c27ce8a11158ca6"><div class="ttname"><a href="classcaffe_1_1DropoutLayer.html#a8e9d88e6128a97101c27ce8a11158ca6">caffe::DropoutLayer::threshold_</a></div><div class="ttdeci">Dtype threshold_</div><div class="ttdoc">the probability  of dropping any input </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:200</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html_a74cf935710a47152e3596b54e68e6e68"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html#a74cf935710a47152e3596b54e68e6e68">caffe::TanHLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the sigmoid inputs. </div><div class="ttdef"><b>Definition:</b> tanh_layer.cpp:24</div></div>
<div class="ttc" id="classcaffe_1_1ExpLayer_html_a5f88102bf4922032eeab431154a76710"><div class="ttname"><a href="classcaffe_1_1ExpLayer.html#a5f88102bf4922032eeab431154a76710">caffe::ExpLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> exp_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1LogLayer_html_adde7e59f9b065e518e6f254c408eb3ef"><div class="ttname"><a href="classcaffe_1_1LogLayer.html#adde7e59f9b065e518e6f254c408eb3ef">caffe::LogLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Computes the error gradient w.r.t. the exp inputs. </div><div class="ttdef"><b>Definition:</b> log_layer.cpp:59</div></div>
<div class="ttc" id="classcaffe_1_1BNLLLayer_html_a1847167dcb7582eea70e9a5e0d99754a"><div class="ttname"><a href="classcaffe_1_1BNLLLayer.html#a1847167dcb7582eea70e9a5e0d99754a">caffe::BNLLLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:111</div></div>
<div class="ttc" id="classcaffe_1_1TanHLayer_html"><div class="ttname"><a href="classcaffe_1_1TanHLayer.html">caffe::TanHLayer</a></div><div class="ttdoc">TanH hyperbolic tangent non-linearity , popular in auto-encoders. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:598</div></div>
<div class="ttc" id="classcaffe_1_1Blob_html"><div class="ttname"><a href="classcaffe_1_1Blob.html">caffe::Blob</a></div><div class="ttdoc">A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...</div><div class="ttdef"><b>Definition:</b> blob.hpp:25</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Jul 6 2015 00:57:02 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.9.1
</small></address>
</body>
</html>
