<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>Caffe: include/caffe/loss_layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_4b7f3da7c7b4301d805dae0326fb91b7.html">caffe</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">loss_layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef CAFFE_LOSS_LAYERS_HPP_</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define CAFFE_LOSS_LAYERS_HPP_</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;caffe/blob.hpp&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;caffe/common.hpp&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;caffe/layer.hpp&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;caffe/neuron_layers.hpp&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;caffe/proto/caffe.pb.h&quot;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecaffe.html">caffe</a> {</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="keyword">const</span> <span class="keywordtype">float</span> kLOG_THRESHOLD = 1e-20;</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00023"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html">   23</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1AccuracyLayer.html">AccuracyLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00033"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#a362ab61d1961c1b408f84a956f6e598d">   33</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#a362ab61d1961c1b408f84a956f6e598d">AccuracyLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#ab1717073a94fb1de4d88e753ad92a383">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#afff9d4e6b889df03bed7d6102c619c57">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div>
<div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#a50cf5809b51c35bf2c4b03a3b2d55813">   40</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1AccuracyLayer.html#a50cf5809b51c35bf2c4b03a3b2d55813">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_ACCURACY;</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;  }</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div>
<div class="line"><a name="l00044"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#afcde815835ab4cdf76fbbef610491a91">   44</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#afcde815835ab4cdf76fbbef610491a91">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00045"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#a4090d979fa142c19cf90b8f9e37f5ab4">   45</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#a4090d979fa142c19cf90b8f9e37f5ab4">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#a3e78dbd448320c940e734e9c3da9b021">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;</div>
<div class="line"><a name="l00077"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#ab4b0106d443e9d4b6e7b919aebd12a99">   77</a></span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#ab4b0106d443e9d4b6e7b919aebd12a99">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom) {</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; propagate_down.size(); ++i) {</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;      <span class="keywordflow">if</span> (propagate_down[i]) { NOT_IMPLEMENTED; }</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    }</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;  }</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;  <span class="keywordtype">int</span> top_k_;</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;};</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00096"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html">   96</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;     : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LossLayer.html#a00f614a20793dcd2a70d93ac0c0a053a">LayerSetUp</a>(</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LossLayer.html#aafb637144a77ca7bfe5c3194bbe0d484">Reshape</a>(</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;</div>
<div class="line"><a name="l00105"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">  105</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;</div>
<div class="line"><a name="l00113"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">  113</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">AutoTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="keyword">true</span>; }</div>
<div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">  114</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00119"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">  119</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">AllowForceBackward</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> bottom_index)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;    <span class="keywordflow">return</span> bottom_index != 1;</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;  }</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;};</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00149"></a><span class="lineno"><a class="line" href="classcaffe_1_1ContrastiveLossLayer.html">  149</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ContrastiveLossLayer.html">ContrastiveLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html">ContrastiveLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param), diff_() {}</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#a19f373ec54074bff38760323fa0e78a9">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;</div>
<div class="line"><a name="l00156"></a><span class="lineno"><a class="line" href="classcaffe_1_1ContrastiveLossLayer.html#af1b8bcaf8ddacd3e98e26c558c7f49a0">  156</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#af1b8bcaf8ddacd3e98e26c558c7f49a0">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 3; }</div>
<div class="line"><a name="l00157"></a><span class="lineno"><a class="line" href="classcaffe_1_1ContrastiveLossLayer.html#a089cc98a883126fe9c7713a0a150021f">  157</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#a089cc98a883126fe9c7713a0a150021f">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_CONTRASTIVE_LOSS;</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;  }</div>
<div class="line"><a name="l00164"></a><span class="lineno"><a class="line" href="classcaffe_1_1ContrastiveLossLayer.html#afbfe9d1707c9e76e31fe381af3d708ef">  164</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#afbfe9d1707c9e76e31fe381af3d708ef">AllowForceBackward</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> bottom_index)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;    <span class="keywordflow">return</span> bottom_index != 2;</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;  }</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#a1311db1b1898e73a51bb2019d8027531">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#aabfe0dfd4bb71366c779e170de27014d">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#ac33f7498ac81aca77245d0aeae6259dc">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ContrastiveLossLayer.html#a3d5ccaa365bd6d9bb09a7ade7cbd775e">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> diff_;  <span class="comment">// cached for backward pass</span></div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> dist_sq_;  <span class="comment">// cached for backward pass</span></div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> diff_sq_;  <span class="comment">// tmp storage for gpu forward pass</span></div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> summer_vec_;  <span class="comment">// tmp storage for gpu forward pass</span></div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;};</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00238"></a><span class="lineno"><a class="line" href="classcaffe_1_1EuclideanLossLayer.html">  238</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1EuclideanLossLayer.html">EuclideanLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html">EuclideanLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param), diff_() {}</div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a294463f3d2a77c84d95a0c27d9a829bb">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;</div>
<div class="line"><a name="l00245"></a><span class="lineno"><a class="line" href="classcaffe_1_1EuclideanLossLayer.html#ac2ef07f6aa25f31c1e955f66b60b4e84">  245</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#ac2ef07f6aa25f31c1e955f66b60b4e84">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_EUCLIDEAN_LOSS;</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;  }</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;</div>
<div class="line"><a name="l00253"></a><span class="lineno"><a class="line" href="classcaffe_1_1EuclideanLossLayer.html#a3c954fd7c15596fd2f59e0f79601905c">  253</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a3c954fd7c15596fd2f59e0f79601905c">AllowForceBackward</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> bottom_index)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;  }</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a864b0ebb8cc013347d7fa7ca69822e64">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#af6dcbdf17106aa4f574823424811179d">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#aad0ba82244d43962ce5f0727021c3942">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a09e462e9f748a8a68eab86f46d8ec962">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;</div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> diff_;</div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;};</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00349"></a><span class="lineno"><a class="line" href="classcaffe_1_1HingeLossLayer.html">  349</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1HingeLossLayer.html">HingeLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1HingeLossLayer.html">HingeLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;</div>
<div class="line"><a name="l00354"></a><span class="lineno"><a class="line" href="classcaffe_1_1HingeLossLayer.html#a529b2c2921f5c81dfc735cc7e992ce07">  354</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1HingeLossLayer.html#a529b2c2921f5c81dfc735cc7e992ce07">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_HINGE_LOSS;</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;  }</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1HingeLossLayer.html#a4ec1934463a9a0f4e7b2cc02a5dd6c72">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1HingeLossLayer.html#a56bc906580c7f52c2e2ab18bed48efc4">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;};</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;</div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00427"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html">  427</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1InfogainLossLayer.html">InfogainLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html">InfogainLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param), infogain_() {}</div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a2c809eec60183f518928918aec8644b6">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#ab621b7c66a853dd2fe54559d50641139">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;  <span class="comment">// InfogainLossLayer takes 2-3 bottom Blobs; if there are 3 the third should</span></div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;  <span class="comment">// be the infogain matrix.  (Otherwise the infogain matrix is loaded from a</span></div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;  <span class="comment">// file specified by LayerParameter.)</span></div>
<div class="line"><a name="l00439"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#aef9aa9200a3129d7bddf56f717017cbb">  439</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#aef9aa9200a3129d7bddf56f717017cbb">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00440"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#a71105feb6b206d7f807c86d7dc303c64">  440</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a71105feb6b206d7f807c86d7dc303c64">MinBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00441"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#ae6cf4ae009630b28583b161c33b582cb">  441</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#ae6cf4ae009630b28583b161c33b582cb">MaxBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 3; }</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;</div>
<div class="line"><a name="l00443"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#a4a125ca3f9f5b75f5d31342da457b058">  443</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a4a125ca3f9f5b75f5d31342da457b058">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_INFOGAIN_LOSS;</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;  }</div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;</div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a743bece4f019364b533d789e2874ec76">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#aca058466597f414390272461ccb6e710">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> infogain_;</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;};</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00520"></a><span class="lineno"><a class="line" href="classcaffe_1_1MultinomialLogisticLossLayer.html">  520</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html">MultinomialLogisticLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html">MultinomialLogisticLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#a8c466dc4a388dbf2d2e8de9c1556f56a">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;</div>
<div class="line"><a name="l00527"></a><span class="lineno"><a class="line" href="classcaffe_1_1MultinomialLogisticLossLayer.html#a34db3140c6b1d6ef91f8a41b786958ba">  527</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#a34db3140c6b1d6ef91f8a41b786958ba">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_MULTINOMIAL_LOGISTIC_LOSS;</div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;  }</div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;</div>
<div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#a42eec0c83ce3545301f3372bc2e015e3">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#af1a48a9c02871e234ea297bbbc86a5c9">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;};</div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;</div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00598"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">  598</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">SigmoidCrossEntropyLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">SigmoidCrossEntropyLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param),</div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;          <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">sigmoid_layer_</a>(<span class="keyword">new</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html">SigmoidLayer&lt;Dtype&gt;</a>(param)),</div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;          <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">sigmoid_output_</a>(<span class="keyword">new</span> <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>()) {}</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a995f9869f2167df152cdec773b53bd90">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a94a74943ac5712c8dc7313eb635d5d50">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;</div>
<div class="line"><a name="l00609"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a79f3344dc486d27da32d017bf35fe458">  609</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a79f3344dc486d27da32d017bf35fe458">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_SIGMOID_CROSS_ENTROPY_LOSS;</div>
<div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;  }</div>
<div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;</div>
<div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#aaf5a9f893661766ca7987ed748027e41">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ac62d50044f3fdcc9915a03dffb2eca40">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;</div>
<div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af43a48c97cfcc6c3339f99e802797c8d">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ab9de1575463555e4339082b5ad7306b4">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;</div>
<div class="line"><a name="l00656"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">  656</a></span>&#160;  shared_ptr&lt;SigmoidLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">sigmoid_layer_</a>;</div>
<div class="line"><a name="l00658"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">  658</a></span>&#160;  shared_ptr&lt;Blob&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">sigmoid_output_</a>;</div>
<div class="line"><a name="l00660"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a52c3183799d44aa9e581992aee502409">  660</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a52c3183799d44aa9e581992aee502409">sigmoid_bottom_vec_</a>;</div>
<div class="line"><a name="l00662"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af6719c9685fcf910129db20cceb47be5">  662</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af6719c9685fcf910129db20cceb47be5">sigmoid_top_vec_</a>;</div>
<div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;};</div>
<div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;</div>
<div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;<span class="comment">// Forward declare SoftmaxLayer for use in SoftmaxWithLossLayer.</span></div>
<div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt; <span class="keyword">class </span><a class="code" href="classcaffe_1_1SoftmaxLayer.html">SoftmaxLayer</a>;</div>
<div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;</div>
<div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00697"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html">  697</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html">SoftmaxWithLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html">SoftmaxWithLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param),</div>
<div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;        <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">softmax_layer_</a>(<span class="keyword">new</span> <a class="code" href="classcaffe_1_1SoftmaxLayer.html">SoftmaxLayer&lt;Dtype&gt;</a>(param)) {}</div>
<div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a4e18748879369f229a5b1a211d1fef4a">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a424c3ad2e521c4a7010b6634256ed5b6">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;</div>
<div class="line"><a name="l00707"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#af4de9059f785ab91302e040b7c8bd737">  707</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#af4de9059f785ab91302e040b7c8bd737">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_SOFTMAX_LOSS;</div>
<div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;  }</div>
<div class="line"><a name="l00710"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a4752aed6057b5747e0e72003878da060">  710</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a4752aed6057b5747e0e72003878da060">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00711"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#acf52e9421c1eff42e787321754bdbe4c">  711</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#acf52e9421c1eff42e787321754bdbe4c">MinBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00712"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a922fdce0bace61b8b3996a3427566a9f">  712</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a922fdce0bace61b8b3996a3427566a9f">MaxBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 3; }</div>
<div class="line"><a name="l00713"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8222589f986db56372bf00935bae6180">  713</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8222589f986db56372bf00935bae6180">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00714"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8994c9ed80aa3dac79a81aefe8f5ee64">  714</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8994c9ed80aa3dac79a81aefe8f5ee64">MinTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00715"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac1f31629bf294a9281c5600f7e890232">  715</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac1f31629bf294a9281c5600f7e890232">MaxTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;</div>
<div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac659dd3d867feab6c36aef18b01383ba">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8f12a0634f5de6f3f41fcfb9d9ee2434">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;</div>
<div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a64fcc6d246ef17f1f4b4679d8bb540e0">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac21525b2ff259f50ae82dd7844387c82">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;</div>
<div class="line"><a name="l00757"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">  757</a></span>&#160;  shared_ptr&lt;SoftmaxLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">softmax_layer_</a>;</div>
<div class="line"><a name="l00759"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a02669f20097006452d877ea05e98b775">  759</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a02669f20097006452d877ea05e98b775">prob_</a>;</div>
<div class="line"><a name="l00761"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#aa39f89b673da5e6f86c6b1f79ced1270">  761</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#aa39f89b673da5e6f86c6b1f79ced1270">softmax_bottom_vec_</a>;</div>
<div class="line"><a name="l00763"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a0fd219e185b46acce8fd74cb71dabf44">  763</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a0fd219e185b46acce8fd74cb71dabf44">softmax_top_vec_</a>;</div>
<div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;};</div>
<div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;</div>
<div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;}  <span class="comment">// namespace caffe</span></div>
<div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;</div>
<div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;<span class="preprocessor">#endif  // CAFFE_LOSS_LAYERS_HPP_</span></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_ad272e6792a781ce4f66a65057cc829d1"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">caffe::LossLayer::AutoTopBlobs</a></div><div class="ttdeci">virtual bool AutoTopBlobs() const </div><div class="ttdoc">For convenience and backwards compatibility, instruct the Net to automatically allocate a single top ...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:113</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a52c3183799d44aa9e581992aee502409"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a52c3183799d44aa9e581992aee502409">caffe::SigmoidCrossEntropyLossLayer::sigmoid_bottom_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; sigmoid_bottom_vec_</div><div class="ttdoc">bottom vector holder to call the underlying SigmoidLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:660</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a864b0ebb8cc013347d7fa7ca69822e64"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a864b0ebb8cc013347d7fa7ca69822e64">caffe::EuclideanLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the Euclidean (L2) loss  for real-valued regression tasks. </div><div class="ttdef"><b>Definition:</b> euclidean_loss_layer.cpp:22</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_af4de9059f785ab91302e040b7c8bd737"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#af4de9059f785ab91302e040b7c8bd737">caffe::SoftmaxWithLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:707</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_af1a48a9c02871e234ea297bbbc86a5c9"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#af1a48a9c02871e234ea297bbbc86a5c9">caffe::MultinomialLogisticLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the multinomial logistic loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> multinomial_logistic_loss_layer.cpp:40</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_afbfe9d1707c9e76e31fe381af3d708ef"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#afbfe9d1707c9e76e31fe381af3d708ef">caffe::ContrastiveLossLayer::AllowForceBackward</a></div><div class="ttdeci">virtual bool AllowForceBackward(const int bottom_index) const </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:164</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a8f12a0634f5de6f3f41fcfb9d9ee2434"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a8f12a0634f5de6f3f41fcfb9d9ee2434">caffe::SoftmaxWithLossLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a79f3344dc486d27da32d017bf35fe458"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a79f3344dc486d27da32d017bf35fe458">caffe::SigmoidCrossEntropyLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:609</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a64fcc6d246ef17f1f4b4679d8bb540e0"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a64fcc6d246ef17f1f4b4679d8bb540e0">caffe::SoftmaxWithLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the softmax loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> softmax_loss_layer.cpp:58</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html"><div class="ttname"><a href="classcaffe_1_1Layer.html">caffe::Layer</a></div><div class="ttdoc">An interface for the units of computation which can be composed into a Net. </div><div class="ttdef"><b>Definition:</b> layer.hpp:26</div></div>
<div class="ttc" id="namespacecaffe_html"><div class="ttname"><a href="namespacecaffe.html">caffe</a></div><div class="ttdef"><b>Definition:</b> blob.hpp:9</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a94a74943ac5712c8dc7313eb635d5d50"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a94a74943ac5712c8dc7313eb635d5d50">caffe::SigmoidCrossEntropyLossLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> sigmoid_cross_entropy_loss_layer.cpp:23</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html">caffe::SigmoidLayer</a></div><div class="ttdoc">Sigmoid function non-linearity , a classic choice in neural networks. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:397</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a1eb4c2e90dd4807dbfb0806a411a7bea"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">caffe::SigmoidCrossEntropyLossLayer::sigmoid_output_</a></div><div class="ttdeci">shared_ptr&lt; Blob&lt; Dtype &gt; &gt; sigmoid_output_</div><div class="ttdoc">sigmoid_output stores the output of the SigmoidLayer. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:658</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_af6719c9685fcf910129db20cceb47be5"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af6719c9685fcf910129db20cceb47be5">caffe::SigmoidCrossEntropyLossLayer::sigmoid_top_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; sigmoid_top_vec_</div><div class="ttdoc">top vector holder to call the underlying SigmoidLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:662</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_a19f373ec54074bff38760323fa0e78a9"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#a19f373ec54074bff38760323fa0e78a9">caffe::ContrastiveLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> contrastive_loss_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a995f9869f2167df152cdec773b53bd90"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a995f9869f2167df152cdec773b53bd90">caffe::SigmoidCrossEntropyLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> sigmoid_cross_entropy_loss_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_a8a2e16d4691640c34e589aac4ec42e28"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">caffe::LossLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:105</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html">caffe::HingeLossLayer</a></div><div class="ttdoc">Computes the hinge loss for a one-of-many classification task. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:349</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_aabfe0dfd4bb71366c779e170de27014d"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#aabfe0dfd4bb71366c779e170de27014d">caffe::ContrastiveLossLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html">caffe::InfogainLossLayer</a></div><div class="ttdoc">A generalization of MultinomialLogisticLossLayer that takes an "information gain" (infogain) matrix s...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:427</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a4a125ca3f9f5b75f5d31342da457b058"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a4a125ca3f9f5b75f5d31342da457b058">caffe::InfogainLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:443</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_a00f614a20793dcd2a70d93ac0c0a053a"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#a00f614a20793dcd2a70d93ac0c0a053a">caffe::LossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_aafb637144a77ca7bfe5c3194bbe0d484"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#aafb637144a77ca7bfe5c3194bbe0d484">caffe::LossLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> loss_layer.cpp:23</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a8222589f986db56372bf00935bae6180"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a8222589f986db56372bf00935bae6180">caffe::SoftmaxWithLossLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:713</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a8994c9ed80aa3dac79a81aefe8f5ee64"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a8994c9ed80aa3dac79a81aefe8f5ee64">caffe::SoftmaxWithLossLayer::MinTopBlobs</a></div><div class="ttdeci">virtual int MinTopBlobs() const </div><div class="ttdoc">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:714</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_ad02fe695b06451ac8e6f21db0cba1dad"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">caffe::LossLayer::AllowForceBackward</a></div><div class="ttdeci">virtual bool AllowForceBackward(const int bottom_index) const </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:119</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a424c3ad2e521c4a7010b6634256ed5b6"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a424c3ad2e521c4a7010b6634256ed5b6">caffe::SoftmaxWithLossLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> softmax_loss_layer.cpp:23</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_aca058466597f414390272461ccb6e710"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#aca058466597f414390272461ccb6e710">caffe::InfogainLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the infogain loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> infogain_loss_layer.cpp:74</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a0fd219e185b46acce8fd74cb71dabf44"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a0fd219e185b46acce8fd74cb71dabf44">caffe::SoftmaxWithLossLayer::softmax_top_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; softmax_top_vec_</div><div class="ttdoc">top vector holder used in call to the underlying SoftmaxLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:763</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_af6dcbdf17106aa4f574823424811179d"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#af6dcbdf17106aa4f574823424811179d">caffe::EuclideanLossLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a69e0c8d2106b4b06c7c896e3069f531c"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">caffe::SigmoidCrossEntropyLossLayer::sigmoid_layer_</a></div><div class="ttdeci">shared_ptr&lt; SigmoidLayer&lt; Dtype &gt; &gt; sigmoid_layer_</div><div class="ttdoc">The internal SigmoidLayer used to map predictions to probabilities. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:656</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_a3d5ccaa365bd6d9bb09a7ade7cbd775e"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#a3d5ccaa365bd6d9bb09a7ade7cbd775e">caffe::ContrastiveLossLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxLayer_html"><div class="ttname"><a href="classcaffe_1_1SoftmaxLayer.html">caffe::SoftmaxLayer</a></div><div class="ttdoc">Computes the softmax function. </div><div class="ttdef"><b>Definition:</b> common_layers.hpp:358</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_af43a48c97cfcc6c3339f99e802797c8d"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af43a48c97cfcc6c3339f99e802797c8d">caffe::SigmoidCrossEntropyLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the sigmoid cross-entropy loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> sigmoid_cross_entropy_loss_layer.cpp:52</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ac1f31629bf294a9281c5600f7e890232"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ac1f31629bf294a9281c5600f7e890232">caffe::SoftmaxWithLossLayer::MaxTopBlobs</a></div><div class="ttdeci">virtual int MaxTopBlobs() const </div><div class="ttdoc">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:715</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html">caffe::AccuracyLayer</a></div><div class="ttdoc">Computes the classification accuracy for a one-of-many classification task. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:23</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a3e78dbd448320c940e734e9c3da9b021"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a3e78dbd448320c940e734e9c3da9b021">caffe::AccuracyLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> accuracy_layer.cpp:33</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a71105feb6b206d7f807c86d7dc303c64"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a71105feb6b206d7f807c86d7dc303c64">caffe::InfogainLossLayer::MinBottomBlobs</a></div><div class="ttdeci">virtual int MinBottomBlobs() const </div><div class="ttdoc">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:440</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ac659dd3d867feab6c36aef18b01383ba"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ac659dd3d867feab6c36aef18b01383ba">caffe::SoftmaxWithLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued pre...</div><div class="ttdef"><b>Definition:</b> softmax_loss_layer.cpp:34</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_ab4b0106d443e9d4b6e7b919aebd12a99"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#ab4b0106d443e9d4b6e7b919aebd12a99">caffe::AccuracyLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Not implemented  AccuracyLayer cannot be used as a loss. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:77</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a4e18748879369f229a5b1a211d1fef4a"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a4e18748879369f229a5b1a211d1fef4a">caffe::SoftmaxWithLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> softmax_loss_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_ac33f7498ac81aca77245d0aeae6259dc"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#ac33f7498ac81aca77245d0aeae6259dc">caffe::ContrastiveLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the Contrastive error gradient w.r.t. the inputs. </div><div class="ttdef"><b>Definition:</b> contrastive_loss_layer.cpp:59</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a743bece4f019364b533d789e2874ec76"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a743bece4f019364b533d789e2874ec76">caffe::InfogainLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">A generalization of MultinomialLogisticLossLayer that takes an "information gain" (infogain) matrix s...</div><div class="ttdef"><b>Definition:</b> infogain_loss_layer.cpp:50</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_ac2ef07f6aa25f31c1e955f66b60b4e84"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#ac2ef07f6aa25f31c1e955f66b60b4e84">caffe::EuclideanLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:245</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a3c954fd7c15596fd2f59e0f79601905c"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a3c954fd7c15596fd2f59e0f79601905c">caffe::EuclideanLossLayer::AllowForceBackward</a></div><div class="ttdeci">virtual bool AllowForceBackward(const int bottom_index) const </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:253</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_acf52e9421c1eff42e787321754bdbe4c"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#acf52e9421c1eff42e787321754bdbe4c">caffe::SoftmaxWithLossLayer::MinBottomBlobs</a></div><div class="ttdeci">virtual int MinBottomBlobs() const </div><div class="ttdoc">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:711</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_afff9d4e6b889df03bed7d6102c619c57"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#afff9d4e6b889df03bed7d6102c619c57">caffe::AccuracyLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> accuracy_layer.cpp:20</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a09e462e9f748a8a68eab86f46d8ec962"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a09e462e9f748a8a68eab86f46d8ec962">caffe::EuclideanLossLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html">caffe::MultinomialLogisticLossLayer</a></div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, directly taking a predi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:520</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a362ab61d1961c1b408f84a956f6e598d"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a362ab61d1961c1b408f84a956f6e598d">caffe::AccuracyLayer::AccuracyLayer</a></div><div class="ttdeci">AccuracyLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:33</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">caffe::SigmoidCrossEntropyLossLayer</a></div><div class="ttdoc">Computes the cross-entropy (logistic) loss , often used for predicting targets interpreted as probabi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:598</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html">caffe::SoftmaxWithLossLayer</a></div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued pre...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:697</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_aa39f89b673da5e6f86c6b1f79ced1270"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#aa39f89b673da5e6f86c6b1f79ced1270">caffe::SoftmaxWithLossLayer::softmax_bottom_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; softmax_bottom_vec_</div><div class="ttdoc">bottom vector holder used in call to the underlying SoftmaxLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:761</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_af1b8bcaf8ddacd3e98e26c558c7f49a0"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#af1b8bcaf8ddacd3e98e26c558c7f49a0">caffe::ContrastiveLossLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:156</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ac21525b2ff259f50ae82dd7844387c82"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ac21525b2ff259f50ae82dd7844387c82">caffe::SoftmaxWithLossLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_ab1717073a94fb1de4d88e753ad92a383"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#ab1717073a94fb1de4d88e753ad92a383">caffe::AccuracyLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> accuracy_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html_a529b2c2921f5c81dfc735cc7e992ce07"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html#a529b2c2921f5c81dfc735cc7e992ce07">caffe::HingeLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:354</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_a42eec0c83ce3545301f3372bc2e015e3"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#a42eec0c83ce3545301f3372bc2e015e3">caffe::MultinomialLogisticLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, directly taking a predi...</div><div class="ttdef"><b>Definition:</b> multinomial_logistic_loss_layer.cpp:23</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a50cf5809b51c35bf2c4b03a3b2d55813"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a50cf5809b51c35bf2c4b03a3b2d55813">caffe::AccuracyLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:40</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html_a4ec1934463a9a0f4e7b2cc02a5dd6c72"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html#a4ec1934463a9a0f4e7b2cc02a5dd6c72">caffe::HingeLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the hinge loss for a one-of-many classification task. </div><div class="ttdef"><b>Definition:</b> hinge_loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_ab621b7c66a853dd2fe54559d50641139"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#ab621b7c66a853dd2fe54559d50641139">caffe::InfogainLossLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> infogain_loss_layer.cpp:28</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_a8c466dc4a388dbf2d2e8de9c1556f56a"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#a8c466dc4a388dbf2d2e8de9c1556f56a">caffe::MultinomialLogisticLossLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> multinomial_logistic_loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_ae6cf4ae009630b28583b161c33b582cb"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#ae6cf4ae009630b28583b161c33b582cb">caffe::InfogainLossLayer::MaxBottomBlobs</a></div><div class="ttdeci">virtual int MaxBottomBlobs() const </div><div class="ttdoc">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:441</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a4090d979fa142c19cf90b8f9e37f5ab4"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a4090d979fa142c19cf90b8f9e37f5ab4">caffe::AccuracyLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:45</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html"><div class="ttname"><a href="classcaffe_1_1LossLayer.html">caffe::LossLayer</a></div><div class="ttdoc">An interface for Layers that take two Blobs as input  usually (1) predictions and (2) ground-truth ...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:96</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a922fdce0bace61b8b3996a3427566a9f"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a922fdce0bace61b8b3996a3427566a9f">caffe::SoftmaxWithLossLayer::MaxBottomBlobs</a></div><div class="ttdeci">virtual int MaxBottomBlobs() const </div><div class="ttdoc">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:712</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_aaf5a9f893661766ca7987ed748027e41"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#aaf5a9f893661766ca7987ed748027e41">caffe::SigmoidCrossEntropyLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the cross-entropy (logistic) loss , often used for predicting targets interpreted as probabi...</div><div class="ttdef"><b>Definition:</b> sigmoid_cross_entropy_loss_layer.cpp:32</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_af8dca16967e8e979ebead4e80664dc10"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">caffe::LossLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:114</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html">caffe::ContrastiveLossLayer</a></div><div class="ttdoc">Computes the contrastive loss  where . This can be used to train siamese networks. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:149</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_aad0ba82244d43962ce5f0727021c3942"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#aad0ba82244d43962ce5f0727021c3942">caffe::EuclideanLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the Euclidean error gradient w.r.t. the inputs. </div><div class="ttdef"><b>Definition:</b> euclidean_loss_layer.cpp:36</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html_a56bc906580c7f52c2e2ab18bed48efc4"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html#a56bc906580c7f52c2e2ab18bed48efc4">caffe::HingeLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the hinge loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> hinge_loss_layer.cpp:47</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_afcde815835ab4cdf76fbbef610491a91"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#afcde815835ab4cdf76fbbef610491a91">caffe::AccuracyLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:44</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a4752aed6057b5747e0e72003878da060"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a4752aed6057b5747e0e72003878da060">caffe::SoftmaxWithLossLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:710</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_ab9de1575463555e4339082b5ad7306b4"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ab9de1575463555e4339082b5ad7306b4">caffe::SigmoidCrossEntropyLossLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_a34db3140c6b1d6ef91f8a41b786958ba"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#a34db3140c6b1d6ef91f8a41b786958ba">caffe::MultinomialLogisticLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:527</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_a089cc98a883126fe9c7713a0a150021f"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#a089cc98a883126fe9c7713a0a150021f">caffe::ContrastiveLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:157</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_aef9aa9200a3129d7bddf56f717017cbb"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#aef9aa9200a3129d7bddf56f717017cbb">caffe::InfogainLossLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:439</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a2c809eec60183f518928918aec8644b6"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a2c809eec60183f518928918aec8644b6">caffe::InfogainLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> infogain_loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html">caffe::EuclideanLossLayer</a></div><div class="ttdoc">Computes the Euclidean (L2) loss  for real-valued regression tasks. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:238</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a02669f20097006452d877ea05e98b775"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a02669f20097006452d877ea05e98b775">caffe::SoftmaxWithLossLayer::prob_</a></div><div class="ttdeci">Blob&lt; Dtype &gt; prob_</div><div class="ttdoc">prob stores the output probability predictions from the SoftmaxLayer. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:759</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_ac62d50044f3fdcc9915a03dffb2eca40"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ac62d50044f3fdcc9915a03dffb2eca40">caffe::SigmoidCrossEntropyLossLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a294463f3d2a77c84d95a0c27d9a829bb"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a294463f3d2a77c84d95a0c27d9a829bb">caffe::EuclideanLossLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> euclidean_loss_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ad5d63b5be7be681045f4e901de667035"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">caffe::SoftmaxWithLossLayer::softmax_layer_</a></div><div class="ttdeci">shared_ptr&lt; SoftmaxLayer&lt; Dtype &gt; &gt; softmax_layer_</div><div class="ttdoc">The internal SoftmaxLayer used to map predictions to a distribution. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:757</div></div>
<div class="ttc" id="classcaffe_1_1ContrastiveLossLayer_html_a1311db1b1898e73a51bb2019d8027531"><div class="ttname"><a href="classcaffe_1_1ContrastiveLossLayer.html#a1311db1b1898e73a51bb2019d8027531">caffe::ContrastiveLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the contrastive loss  where . This can be used to train siamese networks. </div><div class="ttdef"><b>Definition:</b> contrastive_loss_layer.cpp:33</div></div>
<div class="ttc" id="classcaffe_1_1Blob_html"><div class="ttname"><a href="classcaffe_1_1Blob.html">caffe::Blob</a></div><div class="ttdoc">A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...</div><div class="ttdef"><b>Definition:</b> blob.hpp:19</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Oct 17 2014 12:00:35 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.8
</small></address>
</body>
</html>
