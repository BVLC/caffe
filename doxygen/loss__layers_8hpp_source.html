<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>Caffe: include/caffe/loss_layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_4b7f3da7c7b4301d805dae0326fb91b7.html">caffe</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">loss_layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef CAFFE_LOSS_LAYERS_HPP_</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define CAFFE_LOSS_LAYERS_HPP_</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;caffe/blob.hpp&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;caffe/common.hpp&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;caffe/layer.hpp&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;caffe/neuron_layers.hpp&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;caffe/proto/caffe.pb.h&quot;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecaffe.html">caffe</a> {</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="keyword">const</span> <span class="keywordtype">float</span> kLOG_THRESHOLD = 1e-20;</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00023"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html">   23</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1AccuracyLayer.html">AccuracyLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00033"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#a362ab61d1961c1b408f84a956f6e598d">   33</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#a362ab61d1961c1b408f84a956f6e598d">AccuracyLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#ab1717073a94fb1de4d88e753ad92a383">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div>
<div class="line"><a name="l00038"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#a50cf5809b51c35bf2c4b03a3b2d55813">   38</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1AccuracyLayer.html#a50cf5809b51c35bf2c4b03a3b2d55813">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_ACCURACY;</div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;  }</div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div>
<div class="line"><a name="l00042"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#afcde815835ab4cdf76fbbef610491a91">   42</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#afcde815835ab4cdf76fbbef610491a91">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00043"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#a4090d979fa142c19cf90b8f9e37f5ab4">   43</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#a4090d979fa142c19cf90b8f9e37f5ab4">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#a3e78dbd448320c940e734e9c3da9b021">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;</div>
<div class="line"><a name="l00075"></a><span class="lineno"><a class="line" href="classcaffe_1_1AccuracyLayer.html#ab4b0106d443e9d4b6e7b919aebd12a99">   75</a></span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1AccuracyLayer.html#ab4b0106d443e9d4b6e7b919aebd12a99">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom) {</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; propagate_down.size(); ++i) {</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;      <span class="keywordflow">if</span> (propagate_down[i]) { NOT_IMPLEMENTED; }</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    }</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;  }</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;  <span class="keywordtype">int</span> top_k_;</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;};</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00094"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html">   94</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;     : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LossLayer.html#a00f614a20793dcd2a70d93ac0c0a053a">LayerSetUp</a>(</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div>
<div class="line"><a name="l00101"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">  101</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div>
<div class="line"><a name="l00109"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">  109</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">AutoTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="keyword">true</span>; }</div>
<div class="line"><a name="l00110"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">  110</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">  115</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">AllowForceBackward</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> bottom_index)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="keywordflow">return</span> bottom_index != 1;</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;  }</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;};</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00147"></a><span class="lineno"><a class="line" href="classcaffe_1_1EuclideanLossLayer.html">  147</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1EuclideanLossLayer.html">EuclideanLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html">EuclideanLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param), diff_() {}</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a58a4db1e251eeb1e45d2f957a38038e5">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;</div>
<div class="line"><a name="l00154"></a><span class="lineno"><a class="line" href="classcaffe_1_1EuclideanLossLayer.html#ac2ef07f6aa25f31c1e955f66b60b4e84">  154</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#ac2ef07f6aa25f31c1e955f66b60b4e84">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_EUCLIDEAN_LOSS;</div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;  }</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;</div>
<div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="classcaffe_1_1EuclideanLossLayer.html#a3c954fd7c15596fd2f59e0f79601905c">  162</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a3c954fd7c15596fd2f59e0f79601905c">AllowForceBackward</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> bottom_index)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;  }</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a864b0ebb8cc013347d7fa7ca69822e64">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#af6dcbdf17106aa4f574823424811179d">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;</div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#aad0ba82244d43962ce5f0727021c3942">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1EuclideanLossLayer.html#a09e462e9f748a8a68eab86f46d8ec962">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> diff_;</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;};</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00258"></a><span class="lineno"><a class="line" href="classcaffe_1_1HingeLossLayer.html">  258</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1HingeLossLayer.html">HingeLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1HingeLossLayer.html">HingeLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;</div>
<div class="line"><a name="l00263"></a><span class="lineno"><a class="line" href="classcaffe_1_1HingeLossLayer.html#a529b2c2921f5c81dfc735cc7e992ce07">  263</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1HingeLossLayer.html#a529b2c2921f5c81dfc735cc7e992ce07">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_HINGE_LOSS;</div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;  }</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;</div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1HingeLossLayer.html#a4ec1934463a9a0f4e7b2cc02a5dd6c72">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1HingeLossLayer.html#a56bc906580c7f52c2e2ab18bed48efc4">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;};</div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00336"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html">  336</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1InfogainLossLayer.html">InfogainLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html">InfogainLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param), infogain_() {}</div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a2c809eec60183f518928918aec8644b6">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;  <span class="comment">// InfogainLossLayer takes 2-3 bottom Blobs; if there are 3 the third should</span></div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;  <span class="comment">// be the infogain matrix.  (Otherwise the infogain matrix is loaded from a</span></div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;  <span class="comment">// file specified by LayerParameter.)</span></div>
<div class="line"><a name="l00346"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#aef9aa9200a3129d7bddf56f717017cbb">  346</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#aef9aa9200a3129d7bddf56f717017cbb">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00347"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#a71105feb6b206d7f807c86d7dc303c64">  347</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a71105feb6b206d7f807c86d7dc303c64">MinBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00348"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#ae6cf4ae009630b28583b161c33b582cb">  348</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#ae6cf4ae009630b28583b161c33b582cb">MaxBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 3; }</div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;</div>
<div class="line"><a name="l00350"></a><span class="lineno"><a class="line" href="classcaffe_1_1InfogainLossLayer.html#a4a125ca3f9f5b75f5d31342da457b058">  350</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a4a125ca3f9f5b75f5d31342da457b058">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_INFOGAIN_LOSS;</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;  }</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#a743bece4f019364b533d789e2874ec76">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1InfogainLossLayer.html#aca058466597f414390272461ccb6e710">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> infogain_;</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;};</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;</div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00427"></a><span class="lineno"><a class="line" href="classcaffe_1_1MultinomialLogisticLossLayer.html">  427</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html">MultinomialLogisticLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html">MultinomialLogisticLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#ae59fcb10578d883ae9e896159cf9a69e">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;</div>
<div class="line"><a name="l00434"></a><span class="lineno"><a class="line" href="classcaffe_1_1MultinomialLogisticLossLayer.html#a34db3140c6b1d6ef91f8a41b786958ba">  434</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#a34db3140c6b1d6ef91f8a41b786958ba">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_MULTINOMIAL_LOGISTIC_LOSS;</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;  }</div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;</div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#a42eec0c83ce3545301f3372bc2e015e3">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;</div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1MultinomialLogisticLossLayer.html#af1a48a9c02871e234ea297bbbc86a5c9">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;};</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;</div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00505"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">  505</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">SigmoidCrossEntropyLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">SigmoidCrossEntropyLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param),</div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;          <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">sigmoid_layer_</a>(<span class="keyword">new</span> <a class="code" href="classcaffe_1_1SigmoidLayer.html">SigmoidLayer&lt;Dtype&gt;</a>(param)),</div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;          <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">sigmoid_output_</a>(<span class="keyword">new</span> <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>()) {}</div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a995f9869f2167df152cdec773b53bd90">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;</div>
<div class="line"><a name="l00514"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a79f3344dc486d27da32d017bf35fe458">  514</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a79f3344dc486d27da32d017bf35fe458">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_SIGMOID_CROSS_ENTROPY_LOSS;</div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;  }</div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;</div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#aaf5a9f893661766ca7987ed748027e41">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ac62d50044f3fdcc9915a03dffb2eca40">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;</div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af43a48c97cfcc6c3339f99e802797c8d">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ab9de1575463555e4339082b5ad7306b4">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;</div>
<div class="line"><a name="l00561"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">  561</a></span>&#160;  shared_ptr&lt;SigmoidLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">sigmoid_layer_</a>;</div>
<div class="line"><a name="l00563"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">  563</a></span>&#160;  shared_ptr&lt;Blob&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">sigmoid_output_</a>;</div>
<div class="line"><a name="l00565"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a52c3183799d44aa9e581992aee502409">  565</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a52c3183799d44aa9e581992aee502409">sigmoid_bottom_vec_</a>;</div>
<div class="line"><a name="l00567"></a><span class="lineno"><a class="line" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af6719c9685fcf910129db20cceb47be5">  567</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af6719c9685fcf910129db20cceb47be5">sigmoid_top_vec_</a>;</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;};</div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;</div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;<span class="comment">// Forward declare SoftmaxLayer for use in SoftmaxWithLossLayer.</span></div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt; <span class="keyword">class </span><a class="code" href="classcaffe_1_1SoftmaxLayer.html">SoftmaxLayer</a>;</div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00602"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html">  602</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html">SoftmaxWithLossLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html">SoftmaxWithLossLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;      : <a class="code" href="classcaffe_1_1LossLayer.html">LossLayer&lt;Dtype&gt;</a>(param),</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;        <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">softmax_layer_</a>(<span class="keyword">new</span> <a class="code" href="classcaffe_1_1SoftmaxLayer.html">SoftmaxLayer&lt;Dtype&gt;</a>(param)) {}</div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a4e18748879369f229a5b1a211d1fef4a">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;</div>
<div class="line"><a name="l00610"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#af4de9059f785ab91302e040b7c8bd737">  610</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> LayerParameter_LayerType <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#af4de9059f785ab91302e040b7c8bd737">type</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;    <span class="keywordflow">return</span> LayerParameter_LayerType_SOFTMAX_LOSS;</div>
<div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;  }</div>
<div class="line"><a name="l00613"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a4752aed6057b5747e0e72003878da060">  613</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a4752aed6057b5747e0e72003878da060">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00614"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#acf52e9421c1eff42e787321754bdbe4c">  614</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#acf52e9421c1eff42e787321754bdbe4c">MinBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00615"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a922fdce0bace61b8b3996a3427566a9f">  615</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a922fdce0bace61b8b3996a3427566a9f">MaxBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 3; }</div>
<div class="line"><a name="l00616"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8222589f986db56372bf00935bae6180">  616</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8222589f986db56372bf00935bae6180">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00617"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8994c9ed80aa3dac79a81aefe8f5ee64">  617</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8994c9ed80aa3dac79a81aefe8f5ee64">MinTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00618"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac1f31629bf294a9281c5600f7e890232">  618</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac1f31629bf294a9281c5600f7e890232">MaxTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 2; }</div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac659dd3d867feab6c36aef18b01383ba">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a8f12a0634f5de6f3f41fcfb9d9ee2434">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;      vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* top);</div>
<div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;</div>
<div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a64fcc6d246ef17f1f4b4679d8bb540e0">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ac21525b2ff259f50ae82dd7844387c82">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;* bottom);</div>
<div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;</div>
<div class="line"><a name="l00660"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">  660</a></span>&#160;  shared_ptr&lt;SoftmaxLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">softmax_layer_</a>;</div>
<div class="line"><a name="l00662"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a02669f20097006452d877ea05e98b775">  662</a></span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a02669f20097006452d877ea05e98b775">prob_</a>;</div>
<div class="line"><a name="l00664"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#aa39f89b673da5e6f86c6b1f79ced1270">  664</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#aa39f89b673da5e6f86c6b1f79ced1270">softmax_bottom_vec_</a>;</div>
<div class="line"><a name="l00666"></a><span class="lineno"><a class="line" href="classcaffe_1_1SoftmaxWithLossLayer.html#a0fd219e185b46acce8fd74cb71dabf44">  666</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SoftmaxWithLossLayer.html#a0fd219e185b46acce8fd74cb71dabf44">softmax_top_vec_</a>;</div>
<div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;};</div>
<div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;</div>
<div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;}  <span class="comment">// namespace caffe</span></div>
<div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;</div>
<div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;<span class="preprocessor">#endif  // CAFFE_LOSS_LAYERS_HPP_</span></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_ad272e6792a781ce4f66a65057cc829d1"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">caffe::LossLayer::AutoTopBlobs</a></div><div class="ttdeci">virtual bool AutoTopBlobs() const </div><div class="ttdoc">For convenience and backwards compatibility, instruct the Net to automatically allocate a single top ...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:109</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a52c3183799d44aa9e581992aee502409"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a52c3183799d44aa9e581992aee502409">caffe::SigmoidCrossEntropyLossLayer::sigmoid_bottom_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; sigmoid_bottom_vec_</div><div class="ttdoc">bottom vector holder to call the underlying SigmoidLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:565</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a864b0ebb8cc013347d7fa7ca69822e64"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a864b0ebb8cc013347d7fa7ca69822e64">caffe::EuclideanLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the Euclidean (L2) loss  for real-valued regression tasks. </div><div class="ttdef"><b>Definition:</b> euclidean_loss_layer.cpp:22</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_af4de9059f785ab91302e040b7c8bd737"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#af4de9059f785ab91302e040b7c8bd737">caffe::SoftmaxWithLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:610</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_af1a48a9c02871e234ea297bbbc86a5c9"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#af1a48a9c02871e234ea297bbbc86a5c9">caffe::MultinomialLogisticLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the multinomial logistic loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> multinomial_logistic_loss_layer.cpp:40</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a8f12a0634f5de6f3f41fcfb9d9ee2434"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a8f12a0634f5de6f3f41fcfb9d9ee2434">caffe::SoftmaxWithLossLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a79f3344dc486d27da32d017bf35fe458"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a79f3344dc486d27da32d017bf35fe458">caffe::SigmoidCrossEntropyLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:514</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a64fcc6d246ef17f1f4b4679d8bb540e0"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a64fcc6d246ef17f1f4b4679d8bb540e0">caffe::SoftmaxWithLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the softmax loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> softmax_loss_layer.cpp:51</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html"><div class="ttname"><a href="classcaffe_1_1Layer.html">caffe::Layer</a></div><div class="ttdoc">An interface for the units of computation which can be composed into a Net. </div><div class="ttdef"><b>Definition:</b> layer.hpp:26</div></div>
<div class="ttc" id="namespacecaffe_html"><div class="ttname"><a href="namespacecaffe.html">caffe</a></div><div class="ttdef"><b>Definition:</b> blob.hpp:9</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidLayer_html"><div class="ttname"><a href="classcaffe_1_1SigmoidLayer.html">caffe::SigmoidLayer</a></div><div class="ttdoc">Sigmoid function non-linearity , a classic choice in neural networks. </div><div class="ttdef"><b>Definition:</b> neuron_layers.hpp:393</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a1eb4c2e90dd4807dbfb0806a411a7bea"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a1eb4c2e90dd4807dbfb0806a411a7bea">caffe::SigmoidCrossEntropyLossLayer::sigmoid_output_</a></div><div class="ttdeci">shared_ptr&lt; Blob&lt; Dtype &gt; &gt; sigmoid_output_</div><div class="ttdoc">sigmoid_output stores the output of the SigmoidLayer. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:563</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_af6719c9685fcf910129db20cceb47be5"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af6719c9685fcf910129db20cceb47be5">caffe::SigmoidCrossEntropyLossLayer::sigmoid_top_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; sigmoid_top_vec_</div><div class="ttdoc">top vector holder to call the underlying SigmoidLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:567</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_ae59fcb10578d883ae9e896159cf9a69e"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#ae59fcb10578d883ae9e896159cf9a69e">caffe::MultinomialLogisticLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this. </div><div class="ttdef"><b>Definition:</b> multinomial_logistic_loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a995f9869f2167df152cdec773b53bd90"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a995f9869f2167df152cdec773b53bd90">caffe::SigmoidCrossEntropyLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this. </div><div class="ttdef"><b>Definition:</b> sigmoid_cross_entropy_loss_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_a8a2e16d4691640c34e589aac4ec42e28"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">caffe::LossLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:101</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html">caffe::HingeLossLayer</a></div><div class="ttdoc">Computes the hinge loss for a one-of-many classification task. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:258</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html">caffe::InfogainLossLayer</a></div><div class="ttdoc">A generalization of MultinomialLogisticLossLayer that takes an "information gain" (infogain) matrix s...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:336</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a4a125ca3f9f5b75f5d31342da457b058"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a4a125ca3f9f5b75f5d31342da457b058">caffe::InfogainLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:350</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_a00f614a20793dcd2a70d93ac0c0a053a"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#a00f614a20793dcd2a70d93ac0c0a053a">caffe::LossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this. </div><div class="ttdef"><b>Definition:</b> loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a8222589f986db56372bf00935bae6180"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a8222589f986db56372bf00935bae6180">caffe::SoftmaxWithLossLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:616</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a8994c9ed80aa3dac79a81aefe8f5ee64"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a8994c9ed80aa3dac79a81aefe8f5ee64">caffe::SoftmaxWithLossLayer::MinTopBlobs</a></div><div class="ttdeci">virtual int MinTopBlobs() const </div><div class="ttdoc">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:617</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_ad02fe695b06451ac8e6f21db0cba1dad"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">caffe::LossLayer::AllowForceBackward</a></div><div class="ttdeci">virtual bool AllowForceBackward(const int bottom_index) const </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:115</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_aca058466597f414390272461ccb6e710"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#aca058466597f414390272461ccb6e710">caffe::InfogainLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the infogain loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> infogain_loss_layer.cpp:66</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a0fd219e185b46acce8fd74cb71dabf44"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a0fd219e185b46acce8fd74cb71dabf44">caffe::SoftmaxWithLossLayer::softmax_top_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; softmax_top_vec_</div><div class="ttdoc">top vector holder used in call to the underlying SoftmaxLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:666</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_af6dcbdf17106aa4f574823424811179d"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#af6dcbdf17106aa4f574823424811179d">caffe::EuclideanLossLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_a69e0c8d2106b4b06c7c896e3069f531c"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#a69e0c8d2106b4b06c7c896e3069f531c">caffe::SigmoidCrossEntropyLossLayer::sigmoid_layer_</a></div><div class="ttdeci">shared_ptr&lt; SigmoidLayer&lt; Dtype &gt; &gt; sigmoid_layer_</div><div class="ttdoc">The internal SigmoidLayer used to map predictions to probabilities. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:561</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxLayer_html"><div class="ttname"><a href="classcaffe_1_1SoftmaxLayer.html">caffe::SoftmaxLayer</a></div><div class="ttdoc">Computes the softmax function. </div><div class="ttdef"><b>Definition:</b> common_layers.hpp:349</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_af43a48c97cfcc6c3339f99e802797c8d"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#af43a48c97cfcc6c3339f99e802797c8d">caffe::SigmoidCrossEntropyLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the sigmoid cross-entropy loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> sigmoid_cross_entropy_loss_layer.cpp:45</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ac1f31629bf294a9281c5600f7e890232"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ac1f31629bf294a9281c5600f7e890232">caffe::SoftmaxWithLossLayer::MaxTopBlobs</a></div><div class="ttdeci">virtual int MaxTopBlobs() const </div><div class="ttdoc">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:618</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html">caffe::AccuracyLayer</a></div><div class="ttdoc">Computes the classification accuracy for a one-of-many classification task. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:23</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a3e78dbd448320c940e734e9c3da9b021"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a3e78dbd448320c940e734e9c3da9b021">caffe::AccuracyLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdef"><b>Definition:</b> accuracy_layer.cpp:28</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a71105feb6b206d7f807c86d7dc303c64"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a71105feb6b206d7f807c86d7dc303c64">caffe::InfogainLossLayer::MinBottomBlobs</a></div><div class="ttdeci">virtual int MinBottomBlobs() const </div><div class="ttdoc">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:347</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ac659dd3d867feab6c36aef18b01383ba"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ac659dd3d867feab6c36aef18b01383ba">caffe::SoftmaxWithLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued pre...</div><div class="ttdef"><b>Definition:</b> softmax_loss_layer.cpp:27</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_ab4b0106d443e9d4b6e7b919aebd12a99"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#ab4b0106d443e9d4b6e7b919aebd12a99">caffe::AccuracyLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Not implemented  AccuracyLayer cannot be used as a loss. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:75</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a4e18748879369f229a5b1a211d1fef4a"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a4e18748879369f229a5b1a211d1fef4a">caffe::SoftmaxWithLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this. </div><div class="ttdef"><b>Definition:</b> softmax_loss_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a743bece4f019364b533d789e2874ec76"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a743bece4f019364b533d789e2874ec76">caffe::InfogainLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">A generalization of MultinomialLogisticLossLayer that takes an "information gain" (infogain) matrix s...</div><div class="ttdef"><b>Definition:</b> infogain_loss_layer.cpp:42</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_ac2ef07f6aa25f31c1e955f66b60b4e84"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#ac2ef07f6aa25f31c1e955f66b60b4e84">caffe::EuclideanLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:154</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a3c954fd7c15596fd2f59e0f79601905c"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a3c954fd7c15596fd2f59e0f79601905c">caffe::EuclideanLossLayer::AllowForceBackward</a></div><div class="ttdeci">virtual bool AllowForceBackward(const int bottom_index) const </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:162</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_acf52e9421c1eff42e787321754bdbe4c"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#acf52e9421c1eff42e787321754bdbe4c">caffe::SoftmaxWithLossLayer::MinBottomBlobs</a></div><div class="ttdeci">virtual int MinBottomBlobs() const </div><div class="ttdoc">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:614</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a09e462e9f748a8a68eab86f46d8ec962"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a09e462e9f748a8a68eab86f46d8ec962">caffe::EuclideanLossLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html">caffe::MultinomialLogisticLossLayer</a></div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, directly taking a predi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:427</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a362ab61d1961c1b408f84a956f6e598d"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a362ab61d1961c1b408f84a956f6e598d">caffe::AccuracyLayer::AccuracyLayer</a></div><div class="ttdeci">AccuracyLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:33</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html">caffe::SigmoidCrossEntropyLossLayer</a></div><div class="ttdoc">Computes the cross-entropy (logistic) loss , often used for predicting targets interpreted as probabi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:505</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html">caffe::SoftmaxWithLossLayer</a></div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued pre...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:602</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_aa39f89b673da5e6f86c6b1f79ced1270"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#aa39f89b673da5e6f86c6b1f79ced1270">caffe::SoftmaxWithLossLayer::softmax_bottom_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; softmax_bottom_vec_</div><div class="ttdoc">bottom vector holder used in call to the underlying SoftmaxLayer::Forward </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:664</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ac21525b2ff259f50ae82dd7844387c82"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ac21525b2ff259f50ae82dd7844387c82">caffe::SoftmaxWithLossLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_ab1717073a94fb1de4d88e753ad92a383"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#ab1717073a94fb1de4d88e753ad92a383">caffe::AccuracyLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this. </div><div class="ttdef"><b>Definition:</b> accuracy_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html_a529b2c2921f5c81dfc735cc7e992ce07"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html#a529b2c2921f5c81dfc735cc7e992ce07">caffe::HingeLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:263</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_a42eec0c83ce3545301f3372bc2e015e3"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#a42eec0c83ce3545301f3372bc2e015e3">caffe::MultinomialLogisticLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the multinomial logistic loss for a one-of-many classification task, directly taking a predi...</div><div class="ttdef"><b>Definition:</b> multinomial_logistic_loss_layer.cpp:23</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a50cf5809b51c35bf2c4b03a3b2d55813"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a50cf5809b51c35bf2c4b03a3b2d55813">caffe::AccuracyLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:38</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html_a4ec1934463a9a0f4e7b2cc02a5dd6c72"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html#a4ec1934463a9a0f4e7b2cc02a5dd6c72">caffe::HingeLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the hinge loss for a one-of-many classification task. </div><div class="ttdef"><b>Definition:</b> hinge_loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_ae6cf4ae009630b28583b161c33b582cb"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#ae6cf4ae009630b28583b161c33b582cb">caffe::InfogainLossLayer::MaxBottomBlobs</a></div><div class="ttdeci">virtual int MaxBottomBlobs() const </div><div class="ttdoc">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:348</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_a4090d979fa142c19cf90b8f9e37f5ab4"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#a4090d979fa142c19cf90b8f9e37f5ab4">caffe::AccuracyLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:43</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html"><div class="ttname"><a href="classcaffe_1_1LossLayer.html">caffe::LossLayer</a></div><div class="ttdoc">An interface for Layers that take two Blobs as input  usually (1) predictions and (2) ground-truth ...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:94</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a922fdce0bace61b8b3996a3427566a9f"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a922fdce0bace61b8b3996a3427566a9f">caffe::SoftmaxWithLossLayer::MaxBottomBlobs</a></div><div class="ttdeci">virtual int MaxBottomBlobs() const </div><div class="ttdoc">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is requi...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:615</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_aaf5a9f893661766ca7987ed748027e41"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#aaf5a9f893661766ca7987ed748027e41">caffe::SigmoidCrossEntropyLossLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Computes the cross-entropy (logistic) loss , often used for predicting targets interpreted as probabi...</div><div class="ttdef"><b>Definition:</b> sigmoid_cross_entropy_loss_layer.cpp:25</div></div>
<div class="ttc" id="classcaffe_1_1LossLayer_html_af8dca16967e8e979ebead4e80664dc10"><div class="ttname"><a href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">caffe::LossLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:110</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_aad0ba82244d43962ce5f0727021c3942"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#aad0ba82244d43962ce5f0727021c3942">caffe::EuclideanLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the Euclidean error gradient w.r.t. the inputs. </div><div class="ttdef"><b>Definition:</b> euclidean_loss_layer.cpp:36</div></div>
<div class="ttc" id="classcaffe_1_1HingeLossLayer_html_a56bc906580c7f52c2e2ab18bed48efc4"><div class="ttname"><a href="classcaffe_1_1HingeLossLayer.html#a56bc906580c7f52c2e2ab18bed48efc4">caffe::HingeLossLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Computes the hinge loss error gradient w.r.t. the predictions. </div><div class="ttdef"><b>Definition:</b> hinge_loss_layer.cpp:47</div></div>
<div class="ttc" id="classcaffe_1_1AccuracyLayer_html_afcde815835ab4cdf76fbbef610491a91"><div class="ttname"><a href="classcaffe_1_1AccuracyLayer.html#afcde815835ab4cdf76fbbef610491a91">caffe::AccuracyLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:42</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a4752aed6057b5747e0e72003878da060"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a4752aed6057b5747e0e72003878da060">caffe::SoftmaxWithLossLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:613</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_ab9de1575463555e4339082b5ad7306b4"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ab9de1575463555e4339082b5ad7306b4">caffe::SigmoidCrossEntropyLossLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, vector&lt; Blob&lt; Dtype &gt; * &gt; *bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1MultinomialLogisticLossLayer_html_a34db3140c6b1d6ef91f8a41b786958ba"><div class="ttname"><a href="classcaffe_1_1MultinomialLogisticLossLayer.html#a34db3140c6b1d6ef91f8a41b786958ba">caffe::MultinomialLogisticLossLayer::type</a></div><div class="ttdeci">virtual LayerParameter_LayerType type() const </div><div class="ttdoc">Returns the layer type as an enum value. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:434</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_aef9aa9200a3129d7bddf56f717017cbb"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#aef9aa9200a3129d7bddf56f717017cbb">caffe::InfogainLossLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:346</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html_a58a4db1e251eeb1e45d2f957a38038e5"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html#a58a4db1e251eeb1e45d2f957a38038e5">caffe::EuclideanLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this. </div><div class="ttdef"><b>Definition:</b> euclidean_loss_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1InfogainLossLayer_html_a2c809eec60183f518928918aec8644b6"><div class="ttname"><a href="classcaffe_1_1InfogainLossLayer.html#a2c809eec60183f518928918aec8644b6">caffe::InfogainLossLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this. </div><div class="ttdef"><b>Definition:</b> infogain_loss_layer.cpp:14</div></div>
<div class="ttc" id="classcaffe_1_1EuclideanLossLayer_html"><div class="ttname"><a href="classcaffe_1_1EuclideanLossLayer.html">caffe::EuclideanLossLayer</a></div><div class="ttdoc">Computes the Euclidean (L2) loss  for real-valued regression tasks. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:147</div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_a02669f20097006452d877ea05e98b775"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#a02669f20097006452d877ea05e98b775">caffe::SoftmaxWithLossLayer::prob_</a></div><div class="ttdeci">Blob&lt; Dtype &gt; prob_</div><div class="ttdoc">prob stores the output probability predictions from the SoftmaxLayer. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:662</div></div>
<div class="ttc" id="classcaffe_1_1SigmoidCrossEntropyLossLayer_html_ac62d50044f3fdcc9915a03dffb2eca40"><div class="ttname"><a href="classcaffe_1_1SigmoidCrossEntropyLossLayer.html#ac62d50044f3fdcc9915a03dffb2eca40">caffe::SigmoidCrossEntropyLossLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, vector&lt; Blob&lt; Dtype &gt; * &gt; *top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1SoftmaxWithLossLayer_html_ad5d63b5be7be681045f4e901de667035"><div class="ttname"><a href="classcaffe_1_1SoftmaxWithLossLayer.html#ad5d63b5be7be681045f4e901de667035">caffe::SoftmaxWithLossLayer::softmax_layer_</a></div><div class="ttdeci">shared_ptr&lt; SoftmaxLayer&lt; Dtype &gt; &gt; softmax_layer_</div><div class="ttdoc">The internal SoftmaxLayer used to map predictions to a distribution. </div><div class="ttdef"><b>Definition:</b> loss_layers.hpp:660</div></div>
<div class="ttc" id="classcaffe_1_1Blob_html"><div class="ttname"><a href="classcaffe_1_1Blob.html">caffe::Blob</a></div><div class="ttdoc">A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...</div><div class="ttdef"><b>Definition:</b> blob.hpp:19</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Sep 8 2014 12:10:58 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.8
</small></address>
</body>
</html>
