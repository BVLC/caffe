<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9.1"/>
<title>Caffe: caffe::HingeLossLayer&lt; Dtype &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecaffe.html">caffe</a></li><li class="navelem"><a class="el" href="classcaffe_1_1HingeLossLayer.html">HingeLossLayer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classcaffe_1_1HingeLossLayer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">caffe::HingeLossLayer&lt; Dtype &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Computes the hinge loss for a one-of-many classification task.  
 <a href="classcaffe_1_1HingeLossLayer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="loss__layers_8hpp_source.html">loss_layers.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for caffe::HingeLossLayer&lt; Dtype &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classcaffe_1_1HingeLossLayer.png" usemap="#caffe::HingeLossLayer&lt; Dtype &gt;_map" alt=""/>
  <map id="caffe::HingeLossLayer&lt; Dtype &gt;_map" name="caffe::HingeLossLayer&lt; Dtype &gt;_map">
<area href="classcaffe_1_1LossLayer.html" title="An interface for Layers that take two Blobs as input â€“ usually (1) predictions and (2) ground-truth ..." alt="caffe::LossLayer&lt; Dtype &gt;" shape="rect" coords="0,56,196,80"/>
<area href="classcaffe_1_1Layer.html" title="An interface for the units of computation which can be composed into a Net. " alt="caffe::Layer&lt; Dtype &gt;" shape="rect" coords="0,0,196,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a358a5bd2625bb7fed61052dd8e1cb588"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a358a5bd2625bb7fed61052dd8e1cb588"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>HingeLossLayer</b> (const LayerParameter &amp;param)</td></tr>
<tr class="separator:a358a5bd2625bb7fed61052dd8e1cb588"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae804bb931e8cf835ac77a0529f89463f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae804bb931e8cf835ac77a0529f89463f"></a>
virtual const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1HingeLossLayer.html#ae804bb931e8cf835ac77a0529f89463f">type</a> () const </td></tr>
<tr class="memdesc:ae804bb931e8cf835ac77a0529f89463f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer type. <br /></td></tr>
<tr class="separator:ae804bb931e8cf835ac77a0529f89463f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcaffe_1_1LossLayer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcaffe_1_1LossLayer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcaffe_1_1LossLayer.html">caffe::LossLayer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:a16e133050e2d97c6f024ea74e3ba4ead inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a16e133050e2d97c6f024ea74e3ba4ead"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>LossLayer</b> (const LayerParameter &amp;param)</td></tr>
<tr class="separator:a16e133050e2d97c6f024ea74e3ba4ead inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98084e06f7ca0e44c11aee5544379609 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#a98084e06f7ca0e44c11aee5544379609">LayerSetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="memdesc:a98084e06f7ca0e44c11aee5544379609 inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Does layer-specific setup: your layer should implement this function as well as Reshape.  <a href="#a98084e06f7ca0e44c11aee5544379609">More...</a><br /></td></tr>
<tr class="separator:a98084e06f7ca0e44c11aee5544379609 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab15b7120ebc172274481f3732db78c9e inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#ab15b7120ebc172274481f3732db78c9e">Reshape</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="memdesc:ab15b7120ebc172274481f3732db78c9e inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs.  <a href="#ab15b7120ebc172274481f3732db78c9e">More...</a><br /></td></tr>
<tr class="separator:ab15b7120ebc172274481f3732db78c9e inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a2e16d4691640c34e589aac4ec42e28 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#a8a2e16d4691640c34e589aac4ec42e28">ExactNumBottomBlobs</a> () const </td></tr>
<tr class="memdesc:a8a2e16d4691640c34e589aac4ec42e28 inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required.  <a href="#a8a2e16d4691640c34e589aac4ec42e28">More...</a><br /></td></tr>
<tr class="separator:a8a2e16d4691640c34e589aac4ec42e28 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad272e6792a781ce4f66a65057cc829d1 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad272e6792a781ce4f66a65057cc829d1"></a>
virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#ad272e6792a781ce4f66a65057cc829d1">AutoTopBlobs</a> () const </td></tr>
<tr class="memdesc:ad272e6792a781ce4f66a65057cc829d1 inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">For convenience and backwards compatibility, instruct the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> to automatically allocate a single top <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> for LossLayers, into which they output their singleton loss, (even if the user didn't specify one in the prototxt, etc.). <br /></td></tr>
<tr class="separator:ad272e6792a781ce4f66a65057cc829d1 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8dca16967e8e979ebead4e80664dc10 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#af8dca16967e8e979ebead4e80664dc10">ExactNumTopBlobs</a> () const </td></tr>
<tr class="memdesc:af8dca16967e8e979ebead4e80664dc10 inherit pub_methods_classcaffe_1_1LossLayer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required.  <a href="#af8dca16967e8e979ebead4e80664dc10">More...</a><br /></td></tr>
<tr class="separator:af8dca16967e8e979ebead4e80664dc10 inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad02fe695b06451ac8e6f21db0cba1dad inherit pub_methods_classcaffe_1_1LossLayer"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1LossLayer.html#ad02fe695b06451ac8e6f21db0cba1dad">AllowForceBackward</a> (const int bottom_index) const </td></tr>
<tr class="separator:ad02fe695b06451ac8e6f21db0cba1dad inherit pub_methods_classcaffe_1_1LossLayer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcaffe_1_1Layer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcaffe_1_1Layer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcaffe_1_1Layer.html">caffe::Layer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:a7b4e4ccea08c7b8b15acc6829d5735f6 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">Layer</a> (const LayerParameter &amp;param)</td></tr>
<tr class="separator:a7b4e4ccea08c7b8b15acc6829d5735f6 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac427a267f4c5ba93caac53b7ba64841d inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#ac427a267f4c5ba93caac53b7ba64841d">SetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="memdesc:ac427a267f4c5ba93caac53b7ba64841d inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements common layer setup functionality.  <a href="#ac427a267f4c5ba93caac53b7ba64841d">More...</a><br /></td></tr>
<tr class="separator:ac427a267f4c5ba93caac53b7ba64841d inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5fc9ddb31b58958653372bdaaccde94 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#aa5fc9ddb31b58958653372bdaaccde94">Forward</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="memdesc:aa5fc9ddb31b58958653372bdaaccde94 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the bottom blobs, compute the top blobs and the loss.  <a href="#aa5fc9ddb31b58958653372bdaaccde94">More...</a><br /></td></tr>
<tr class="separator:aa5fc9ddb31b58958653372bdaaccde94 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53df1e081767e07bfb4c81657f4acd0a inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a53df1e081767e07bfb4c81657f4acd0a">Backward</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom)</td></tr>
<tr class="memdesc:a53df1e081767e07bfb4c81657f4acd0a inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the top blob error gradients, compute the bottom blob error gradients.  <a href="#a53df1e081767e07bfb4c81657f4acd0a">More...</a><br /></td></tr>
<tr class="separator:a53df1e081767e07bfb4c81657f4acd0a inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf4524ce8641a30a8a4784aee1b2b4c8 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aaf4524ce8641a30a8a4784aee1b2b4c8"></a>
vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#aaf4524ce8641a30a8a4784aee1b2b4c8">blobs</a> ()</td></tr>
<tr class="memdesc:aaf4524ce8641a30a8a4784aee1b2b4c8 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the vector of learnable parameter blobs. <br /></td></tr>
<tr class="separator:aaf4524ce8641a30a8a4784aee1b2b4c8 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af475062fe280614b18f642c4ccf50b40 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="af475062fe280614b18f642c4ccf50b40"></a>
const LayerParameter &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#af475062fe280614b18f642c4ccf50b40">layer_param</a> () const </td></tr>
<tr class="memdesc:af475062fe280614b18f642c4ccf50b40 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer parameter. <br /></td></tr>
<tr class="separator:af475062fe280614b18f642c4ccf50b40 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a1754828dda22cc8daa2f63377f3579 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a4a1754828dda22cc8daa2f63377f3579"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a4a1754828dda22cc8daa2f63377f3579">ToProto</a> (LayerParameter *param, bool write_diff=false)</td></tr>
<tr class="memdesc:a4a1754828dda22cc8daa2f63377f3579 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Writes the layer parameter to a protocol buffer. <br /></td></tr>
<tr class="separator:a4a1754828dda22cc8daa2f63377f3579 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a964ccba33b9a4b69391a72508f764eaf inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a964ccba33b9a4b69391a72508f764eaf"></a>
Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a964ccba33b9a4b69391a72508f764eaf">loss</a> (const int top_index) const </td></tr>
<tr class="memdesc:a964ccba33b9a4b69391a72508f764eaf inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the scalar loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a964ccba33b9a4b69391a72508f764eaf inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899b09f4b91ada8545b3a43ee91e0d69 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a899b09f4b91ada8545b3a43ee91e0d69"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a899b09f4b91ada8545b3a43ee91e0d69">set_loss</a> (const int top_index, const Dtype value)</td></tr>
<tr class="memdesc:a899b09f4b91ada8545b3a43ee91e0d69 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a899b09f4b91ada8545b3a43ee91e0d69 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade3eee97cc743c4e68fff7eba6484916 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#ade3eee97cc743c4e68fff7eba6484916">MinBottomBlobs</a> () const </td></tr>
<tr class="memdesc:ade3eee97cc743c4e68fff7eba6484916 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is required.  <a href="#ade3eee97cc743c4e68fff7eba6484916">More...</a><br /></td></tr>
<tr class="separator:ade3eee97cc743c4e68fff7eba6484916 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6408ef3939f1abed1abcec46ff219289 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a6408ef3939f1abed1abcec46ff219289">MaxBottomBlobs</a> () const </td></tr>
<tr class="memdesc:a6408ef3939f1abed1abcec46ff219289 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is required.  <a href="#a6408ef3939f1abed1abcec46ff219289">More...</a><br /></td></tr>
<tr class="separator:a6408ef3939f1abed1abcec46ff219289 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bb143d58a740345fa2dc3d4204d553b inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a8bb143d58a740345fa2dc3d4204d553b">MinTopBlobs</a> () const </td></tr>
<tr class="memdesc:a8bb143d58a740345fa2dc3d4204d553b inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required.  <a href="#a8bb143d58a740345fa2dc3d4204d553b">More...</a><br /></td></tr>
<tr class="separator:a8bb143d58a740345fa2dc3d4204d553b inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adeff774663c6ec94424901d2746e2f03 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#adeff774663c6ec94424901d2746e2f03">MaxTopBlobs</a> () const </td></tr>
<tr class="memdesc:adeff774663c6ec94424901d2746e2f03 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required.  <a href="#adeff774663c6ec94424901d2746e2f03">More...</a><br /></td></tr>
<tr class="separator:adeff774663c6ec94424901d2746e2f03 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad412187a0483c310bd59fd5f957faf0d inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#ad412187a0483c310bd59fd5f957faf0d">EqualNumBottomTopBlobs</a> () const </td></tr>
<tr class="memdesc:ad412187a0483c310bd59fd5f957faf0d inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns true if the layer requires an equal number of bottom and top blobs.  <a href="#ad412187a0483c310bd59fd5f957faf0d">More...</a><br /></td></tr>
<tr class="separator:ad412187a0483c310bd59fd5f957faf0d inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a3708013b0231e71d725252e10ce6e3 inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a1a3708013b0231e71d725252e10ce6e3">param_propagate_down</a> (const int param_id)</td></tr>
<tr class="memdesc:a1a3708013b0231e71d725252e10ce6e3 inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specifies whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id.  <a href="#a1a3708013b0231e71d725252e10ce6e3">More...</a><br /></td></tr>
<tr class="separator:a1a3708013b0231e71d725252e10ce6e3 inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a6fcb843803ed556f0a69cc2864379b inherit pub_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9a6fcb843803ed556f0a69cc2864379b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a9a6fcb843803ed556f0a69cc2864379b">set_param_propagate_down</a> (const int param_id, const bool value)</td></tr>
<tr class="memdesc:a9a6fcb843803ed556f0a69cc2864379b inherit pub_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id. <br /></td></tr>
<tr class="separator:a9a6fcb843803ed556f0a69cc2864379b inherit pub_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a24a8c6e0dca1b35794a14e5f923d226f"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1HingeLossLayer.html#a24a8c6e0dca1b35794a14e5f923d226f">Forward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="memdesc:a24a8c6e0dca1b35794a14e5f923d226f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hinge loss for a one-of-many classification task.  <a href="#a24a8c6e0dca1b35794a14e5f923d226f">More...</a><br /></td></tr>
<tr class="separator:a24a8c6e0dca1b35794a14e5f923d226f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24e8552d75a557b6082c197fd726412e"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1HingeLossLayer.html#a24e8552d75a557b6082c197fd726412e">Backward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom)</td></tr>
<tr class="memdesc:a24e8552d75a557b6082c197fd726412e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the hinge loss error gradient w.r.t. the predictions.  <a href="#a24e8552d75a557b6082c197fd726412e">More...</a><br /></td></tr>
<tr class="separator:a24e8552d75a557b6082c197fd726412e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classcaffe_1_1Layer"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classcaffe_1_1Layer')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classcaffe_1_1Layer.html">caffe::Layer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:a93b8d8c30c7691a39f634bf7bb2b03fb inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a93b8d8c30c7691a39f634bf7bb2b03fb"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a93b8d8c30c7691a39f634bf7bb2b03fb">Forward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="memdesc:a93b8d8c30c7691a39f634bf7bb2b03fb inherit pro_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the layer output. Fall back to <a class="el" href="classcaffe_1_1Layer.html#add965883f75bbf90c7a06f960cda7a1a" title="Using the CPU device, compute the layer output. ">Forward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:a93b8d8c30c7691a39f634bf7bb2b03fb inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9275e5b8196feac9cf22803973c890f9 inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a9275e5b8196feac9cf22803973c890f9"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a9275e5b8196feac9cf22803973c890f9">Backward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom)</td></tr>
<tr class="memdesc:a9275e5b8196feac9cf22803973c890f9 inherit pro_methods_classcaffe_1_1Layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_down is true. Fall back to <a class="el" href="classcaffe_1_1Layer.html#a64d15855f882af4b82e83fa993c4e7c6" title="Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...">Backward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:a9275e5b8196feac9cf22803973c890f9 inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adaa95e30dff155409a25ffcb5c8c885e inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#adaa95e30dff155409a25ffcb5c8c885e">CheckBlobCounts</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="separator:adaa95e30dff155409a25ffcb5c8c885e inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bd62d1505dd35d6a3a25954ae9e6014 inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a8bd62d1505dd35d6a3a25954ae9e6014">SetLossWeights</a> (const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;top)</td></tr>
<tr class="separator:a8bd62d1505dd35d6a3a25954ae9e6014 inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90730e177e4b3b3516b1b69ba2f6b06a inherit pro_methods_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a90730e177e4b3b3516b1b69ba2f6b06a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>DISABLE_COPY_AND_ASSIGN</b> (<a class="el" href="classcaffe_1_1Layer.html">Layer</a>)</td></tr>
<tr class="separator:a90730e177e4b3b3516b1b69ba2f6b06a inherit pro_methods_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_attribs_classcaffe_1_1Layer"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_classcaffe_1_1Layer')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="classcaffe_1_1Layer.html">caffe::Layer&lt; Dtype &gt;</a></td></tr>
<tr class="memitem:a7ed12bb2df25c887e41d7ea9557fc701 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">LayerParameter&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a7ed12bb2df25c887e41d7ea9557fc701">layer_param_</a></td></tr>
<tr class="separator:a7ed12bb2df25c887e41d7ea9557fc701 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d04ad7f595a82a1c811f102d68b8a19 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">Phase&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a1d04ad7f595a82a1c811f102d68b8a19">phase_</a></td></tr>
<tr class="separator:a1d04ad7f595a82a1c811f102d68b8a19 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8073fcf2c139b47eb99ce71b346b1321 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#a8073fcf2c139b47eb99ce71b346b1321">blobs_</a></td></tr>
<tr class="separator:a8073fcf2c139b47eb99ce71b346b1321 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd4a05def9ff3b42ad72404210613ef7 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">vector&lt; bool &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#acd4a05def9ff3b42ad72404210613ef7">param_propagate_down_</a></td></tr>
<tr class="separator:acd4a05def9ff3b42ad72404210613ef7 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6d347229a139500994e7a926c680486 inherit pro_attribs_classcaffe_1_1Layer"><td class="memItemLeft" align="right" valign="top">vector&lt; Dtype &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1Layer.html#af6d347229a139500994e7a926c680486">loss_</a></td></tr>
<tr class="separator:af6d347229a139500994e7a926c680486 inherit pro_attribs_classcaffe_1_1Layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Dtype&gt;<br />
class caffe::HingeLossLayer&lt; Dtype &gt;</h3>

<p>Computes the hinge loss for a one-of-many classification task. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 2)<ol type="1">
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the predictions <img class="formulaInl" alt="$ t $" src="form_37.png"/>, a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with values in <img class="formulaInl" alt="$ [-\infty, +\infty] $" src="form_38.png"/> indicating the predicted score for each of the <img class="formulaInl" alt="$ K = CHW $" src="form_39.png"/> classes. In an SVM, <img class="formulaInl" alt="$ t $" src="form_37.png"/> is the result of taking the inner product <img class="formulaInl" alt="$ X^T W $" src="form_40.png"/> of the D-dimensional features <img class="formulaInl" alt="$ X \in \mathcal{R}^{D \times N} $" src="form_41.png"/> and the learned hyperplane parameters <img class="formulaInl" alt="$ W \in \mathcal{R}^{D \times K} $" src="form_42.png"/>, so a <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> with just an <a class="el" href="classcaffe_1_1InnerProductLayer.html" title="Also known as a &quot;fully-connected&quot; layer, computes an inner product with a set of learned weights...">InnerProductLayer</a> (with num_output = D) providing predictions to a <a class="el" href="classcaffe_1_1HingeLossLayer.html" title="Computes the hinge loss for a one-of-many classification task. ">HingeLossLayer</a> and no other learnable parameters or losses is equivalent to an SVM.</li>
<li><img class="formulaInl" alt="$ (N \times 1 \times 1 \times 1) $" src="form_30.png"/> the labels <img class="formulaInl" alt="$ l $" src="form_43.png"/>, an integer-valued <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with values <img class="formulaInl" alt="$ l_n \in [0, 1, 2, ..., K - 1] $" src="form_44.png"/> indicating the correct class label among the <img class="formulaInl" alt="$ K $" src="form_0.png"/> classes </li>
</ol>
</td></tr>
    <tr><td class="paramname">top</td><td>output <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 1)<ol type="1">
<li><img class="formulaInl" alt="$ (1 \times 1 \times 1 \times 1) $" src="form_32.png"/> the computed hinge loss: <img class="formulaInl" alt="$ E = \frac{1}{N} \sum\limits_{n=1}^N \sum\limits_{k=1}^K [\max(0, 1 - \delta\{l_n = k\} t_{nk})] ^ p $" src="form_45.png"/>, for the <img class="formulaInl" alt="$ L^p $" src="form_46.png"/> norm (defaults to <img class="formulaInl" alt="$ p = 1 $" src="form_47.png"/>, the L1 norm; L2 norm, as in L2-SVM, is also available), and <img class="formulaInl" alt="$ \delta\{\mathrm{condition}\} = \left\{ \begin{array}{lr} 1 &amp; \mbox{if condition} \\ -1 &amp; \mbox{otherwise} \end{array} \right. $" src="form_48.png"/></li>
</ol>
</td></tr>
  </table>
  </dd>
</dl>
<p>In an SVM, <img class="formulaInl" alt="$ t \in \mathcal{R}^{N \times K} $" src="form_49.png"/> is the result of taking the inner product <img class="formulaInl" alt="$ X^T W $" src="form_40.png"/> of the features <img class="formulaInl" alt="$ X \in \mathcal{R}^{D \times N} $" src="form_41.png"/> and the learned hyperplane parameters <img class="formulaInl" alt="$ W \in \mathcal{R}^{D \times K} $" src="form_42.png"/>. So, a <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> with just an <a class="el" href="classcaffe_1_1InnerProductLayer.html" title="Also known as a &quot;fully-connected&quot; layer, computes an inner product with a set of learned weights...">InnerProductLayer</a> (with num_output = <img class="formulaInl" alt="$k$" src="form_50.png"/>) providing predictions to a <a class="el" href="classcaffe_1_1HingeLossLayer.html" title="Computes the hinge loss for a one-of-many classification task. ">HingeLossLayer</a> is equivalent to an SVM (assuming it has no other learned outside the <a class="el" href="classcaffe_1_1InnerProductLayer.html" title="Also known as a &quot;fully-connected&quot; layer, computes an inner product with a set of learned weights...">InnerProductLayer</a> and no other losses outside the <a class="el" href="classcaffe_1_1HingeLossLayer.html" title="Computes the hinge loss for a one-of-many classification task. ">HingeLossLayer</a>). </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a24e8552d75a557b6082c197fd726412e"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1HingeLossLayer.html">caffe::HingeLossLayer</a>&lt; Dtype &gt;::Backward_cpu </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; bool &gt; &amp;&#160;</td>
          <td class="paramname"><em>propagate_down</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the hinge loss error gradient w.r.t. the predictions. </p>
<p>Gradients cannot be computed with respect to the label inputs (bottom[1]), so this method ignores bottom[1] and requires !propagate_down[1], crashing if propagate_down[1] is set.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">top</td><td>output <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 1), providing the error gradient with respect to the outputs<ol type="1">
<li><img class="formulaInl" alt="$ (1 \times 1 \times 1 \times 1) $" src="form_32.png"/> This <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>'s diff will simply contain the loss_weight* <img class="formulaInl" alt="$ \lambda $" src="form_76.png"/>, as <img class="formulaInl" alt="$ \lambda $" src="form_76.png"/> is the coefficient of this layer's output <img class="formulaInl" alt="$\ell_i$" src="form_77.png"/> in the overall <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> loss <img class="formulaInl" alt="$ E = \lambda_i \ell_i + \mbox{other loss terms}$" src="form_78.png"/>; hence <img class="formulaInl" alt="$ \frac{\partial E}{\partial \ell_i} = \lambda_i $" src="form_79.png"/>. (*Assuming that this top <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> is not used as a bottom (input) by any other layer of the <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a>.) </li>
</ol>
</td></tr>
    <tr><td class="paramname">propagate_down</td><td>see <a class="el" href="classcaffe_1_1Layer.html#a53df1e081767e07bfb4c81657f4acd0a" title="Given the top blob error gradients, compute the bottom blob error gradients. ">Layer::Backward</a>. propagate_down[1] must be false as we can't compute gradients with respect to the labels. </td></tr>
    <tr><td class="paramname">bottom</td><td>input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 2)<ol type="1">
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the predictions <img class="formulaInl" alt="$t$" src="form_86.png"/>; Backward computes diff <img class="formulaInl" alt="$ \frac{\partial E}{\partial t} $" src="form_87.png"/></li>
<li><img class="formulaInl" alt="$ (N \times 1 \times 1 \times 1) $" src="form_30.png"/> the labels &ndash; ignored as we can't compute their error gradients </li>
</ol>
</td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classcaffe_1_1Layer.html#a64d15855f882af4b82e83fa993c4e7c6">caffe::Layer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a class="anchor" id="a24a8c6e0dca1b35794a14e5f923d226f"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1HingeLossLayer.html">caffe::HingeLossLayer</a>&lt; Dtype &gt;::Forward_cpu </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1Blob.html">Blob</a>&lt; Dtype &gt; * &gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the hinge loss for a one-of-many classification task. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>input <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 2)<ol type="1">
<li><img class="formulaInl" alt="$ (N \times C \times H \times W) $" src="form_2.png"/> the predictions <img class="formulaInl" alt="$ t $" src="form_37.png"/>, a <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with values in <img class="formulaInl" alt="$ [-\infty, +\infty] $" src="form_38.png"/> indicating the predicted score for each of the <img class="formulaInl" alt="$ K = CHW $" src="form_39.png"/> classes. In an SVM, <img class="formulaInl" alt="$ t $" src="form_37.png"/> is the result of taking the inner product <img class="formulaInl" alt="$ X^T W $" src="form_40.png"/> of the D-dimensional features <img class="formulaInl" alt="$ X \in \mathcal{R}^{D \times N} $" src="form_41.png"/> and the learned hyperplane parameters <img class="formulaInl" alt="$ W \in \mathcal{R}^{D \times K} $" src="form_42.png"/>, so a <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> with just an <a class="el" href="classcaffe_1_1InnerProductLayer.html" title="Also known as a &quot;fully-connected&quot; layer, computes an inner product with a set of learned weights...">InnerProductLayer</a> (with num_output = D) providing predictions to a <a class="el" href="classcaffe_1_1HingeLossLayer.html" title="Computes the hinge loss for a one-of-many classification task. ">HingeLossLayer</a> and no other learnable parameters or losses is equivalent to an SVM.</li>
<li><img class="formulaInl" alt="$ (N \times 1 \times 1 \times 1) $" src="form_30.png"/> the labels <img class="formulaInl" alt="$ l $" src="form_43.png"/>, an integer-valued <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> with values <img class="formulaInl" alt="$ l_n \in [0, 1, 2, ..., K - 1] $" src="form_44.png"/> indicating the correct class label among the <img class="formulaInl" alt="$ K $" src="form_0.png"/> classes </li>
</ol>
</td></tr>
    <tr><td class="paramname">top</td><td>output <a class="el" href="classcaffe_1_1Blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a> vector (length 1)<ol type="1">
<li><img class="formulaInl" alt="$ (1 \times 1 \times 1 \times 1) $" src="form_32.png"/> the computed hinge loss: <img class="formulaInl" alt="$ E = \frac{1}{N} \sum\limits_{n=1}^N \sum\limits_{k=1}^K [\max(0, 1 - \delta\{l_n = k\} t_{nk})] ^ p $" src="form_45.png"/>, for the <img class="formulaInl" alt="$ L^p $" src="form_46.png"/> norm (defaults to <img class="formulaInl" alt="$ p = 1 $" src="form_47.png"/>, the L1 norm; L2 norm, as in L2-SVM, is also available), and <img class="formulaInl" alt="$ \delta\{\mathrm{condition}\} = \left\{ \begin{array}{lr} 1 &amp; \mbox{if condition} \\ -1 &amp; \mbox{otherwise} \end{array} \right. $" src="form_48.png"/></li>
</ol>
</td></tr>
  </table>
  </dd>
</dl>
<p>In an SVM, <img class="formulaInl" alt="$ t \in \mathcal{R}^{N \times K} $" src="form_49.png"/> is the result of taking the inner product <img class="formulaInl" alt="$ X^T W $" src="form_40.png"/> of the features <img class="formulaInl" alt="$ X \in \mathcal{R}^{D \times N} $" src="form_41.png"/> and the learned hyperplane parameters <img class="formulaInl" alt="$ W \in \mathcal{R}^{D \times K} $" src="form_42.png"/>. So, a <a class="el" href="classcaffe_1_1Net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a> with just an <a class="el" href="classcaffe_1_1InnerProductLayer.html" title="Also known as a &quot;fully-connected&quot; layer, computes an inner product with a set of learned weights...">InnerProductLayer</a> (with num_output = <img class="formulaInl" alt="$k$" src="form_50.png"/>) providing predictions to a <a class="el" href="classcaffe_1_1HingeLossLayer.html" title="Computes the hinge loss for a one-of-many classification task. ">HingeLossLayer</a> is equivalent to an SVM (assuming it has no other learned outside the <a class="el" href="classcaffe_1_1InnerProductLayer.html" title="Also known as a &quot;fully-connected&quot; layer, computes an inner product with a set of learned weights...">InnerProductLayer</a> and no other losses outside the <a class="el" href="classcaffe_1_1HingeLossLayer.html" title="Computes the hinge loss for a one-of-many classification task. ">HingeLossLayer</a>). </p>

<p>Implements <a class="el" href="classcaffe_1_1Layer.html#add965883f75bbf90c7a06f960cda7a1a">caffe::Layer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/caffe/<a class="el" href="loss__layers_8hpp_source.html">loss_layers.hpp</a></li>
<li>src/caffe/layers/hinge_loss_layer.cpp</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri May 29 2015 12:07:32 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.9.1
</small></address>
</body>
</html>
