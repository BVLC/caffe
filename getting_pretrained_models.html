<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>
      Caffe 
    </title>

    <link rel="stylesheet" href="/stylesheets/reset.css">
    <link rel="stylesheet" href="/stylesheets/styles.css">
    <link rel="stylesheet" href="/stylesheets/pygment_trac.css">

    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46255508-1', 'daggerfs.com');
    ga('send', 'pageview');
  </script>
    <div class="wrapper">
      <header>
        <h1 class="header"><a href="/">Caffe</a></h1>
        <p class="header">
          Deep learning framework developed by <a class="header name" href="http://daggerfs.com/">Yangqing Jia</a> / <a class="header name" href="http://bvlc.eecs.berkeley.edu/">BVLC</a>
        </p>
        <ul>
          <li>
            <a class="buttons github" href="https://github.com/BVLC/caffe">View On GitHub</a>
          </li>
        </ul>
      </header>
      <section>

      <h1 id="pre-trained-models">Pre-trained models</h1>

<p><a href="http://bvlc.eecs.berkeley.edu">BVLC</a> aims to provide a variety of high quality pre-trained models.
Note that unlike Caffe itself, these models are licensed for <strong>academic research / non-commercial use only</strong>.
If you have any questions, please get in touch with us.</p>

<p><em>UPDATE</em> July 2014: we are actively working on a service for hosting user-uploaded model definition and trained weight files.
Soon, the community will be able to easily contribute different architectures!</p>

<h3 id="imagenet">ImageNet</h3>

<p><strong>Caffe Reference ImageNet Model</strong>: Our reference implementation of an ImageNet model trained on ILSVRC-2012 can be downloaded (232.6MB) by running <code>examples/imagenet/get_caffe_reference_imagenet_model.sh</code> from the Caffe root directory.</p>

<ul>
  <li>The bundled model is the iteration 310,000 snapshot.</li>
  <li>The best validation performance during training was iteration 313,000 with
validation accuracy 57.412% and loss 1.82328.</li>
  <li>This model obtains a top-1 accuracy 57.4% and a top-5 accuracy 80.4% on the validation set, using just the center crop. (Using the average of 10 crops, (4 + 1 center) * 2 mirror, should obtain a bit higher accuracy)</li>
</ul>

<p><strong>AlexNet</strong>: Our training of the Krizhevsky architecture, which differs from the paperâ€™s methodology by (1) not training with the relighting data-augmentation and (2) initializing non-zero biases to 0.1 instead of 1. (2) was found necessary for training, as initialization to 1 gave flat loss. Download the model (243.9MB) by running <code>examples/imagenet/get_caffe_alexnet_model.sh</code> from the Caffe root directory.</p>

<ul>
  <li>The bundled model is the iteration 360,000 snapshot.</li>
  <li>The best validation performance during training was iteration 358,000 with
validation accuracy 57.258% and loss 1.83948.</li>
  <li>This model obtains a top-1 accuracy 57.1% and a top-5 accuracy 80.2% on the validation set, using just the center crop. (Using the average of 10 crops, (4 + 1 center) * 2 mirror, should obtain a bit higher accuracy)</li>
</ul>

<p><strong>R-CNN (ILSVRC13)</strong>: The pure Caffe instantiation of the <a href="https://github.com/rbgirshick/rcnn">R-CNN</a> model for ILSVRC13 detection. Download the model (230.8MB) by running <code>examples/imagenet/get_caffe_rcnn_imagenet_model.sh</code> from the Caffe root directory. This model was made by transplanting the R-CNN SVM classifiers into a <code>fc-rcnn</code> classification layer, provided here as an off-the-shelf Caffe detector. Try the <a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/detection.ipynb">detection example</a> to see it in action. For the full details, refer to the R-CNN site. <em>N.B. For research purposes, make use of the official R-CNN package and not this example.</em></p>

<h3 id="auxiliary-data">Auxiliary Data</h3>

<p>Additionally, you will probably eventually need some auxiliary data (mean image, synset list, etc.): run <code>data/ilsvrc12/get_ilsvrc_aux.sh</code> from the root directory to obtain it.</p>


      </section>
  </div>
  </body>
</html>
