name: "MNISTAutoencoder"
layer {
  name: "data"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> caffe
>>>>>>> pod-caffe-pod.hpp-merge
=======
<<<<<<< HEAD
=======
>>>>>>> caffe
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> caffe
>>>>>>> pod/caffe-merge
=======
>>>>>>> caffe
>>>>>>> pod/caffe-merge
=======
=======
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> caffe
>>>>>>> pod-caffe-pod.hpp-merge
>>>>>>> pod/device/blob.hpp
=======
>>>>>>> device-abstraction
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215684
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    batch_size: 100
    backend: LMDB
  }
}
layer {
=======
<<<<<<< HEAD
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
  type: DATA
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    backend: LMDB
>>>>>>> origin/BVLC/parallel
    batch_size: 100
    backend: LMDB
  }
<<<<<<< HEAD
=======
  transform_param {
    scale: 0.0039215684
  }
  include: { phase: TRAIN }
>>>>>>> origin/BVLC/parallel
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
    stage: "test-on-train"
  }
  transform_param {
    scale: 0.0039215684
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
<<<<<<< HEAD
    batch_size: 100
    backend: LMDB
  }
}
layer {
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    stage: "test-on-train"
=======
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
    stage: "test-on-test"
=======
    backend: LMDB
    batch_size: 100
>>>>>>> origin/BVLC/parallel
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
  }
  transform_param {
    scale: 0.0039215684
  }
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
=======
<<<<<<< HEAD
=======
>>>>>>> pod/caffe-merge
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
=======
  include: {
    phase: TEST
    stage: 'test-on-train'
  }
=======
    batch_size: 100
    backend: LMDB
  }
>>>>>>> caffe
<<<<<<< HEAD
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
<<<<<<< HEAD
<<<<<<< HEAD
    stage: "test-on-test"
=======
    stage: "test-on-train"
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
=======
    stage: "test-on-train"
>>>>>>> pod/caffe-merge
  }
  transform_param {
    scale: 0.0039215684
  }
<<<<<<< HEAD
<<<<<<< HEAD
  data_param {
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
=======
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    backend: LMDB
>>>>>>> origin/BVLC/parallel
    batch_size: 100
    backend: LMDB
  }
<<<<<<< HEAD
=======
  transform_param {
    scale: 0.0039215684
  }
  include: {
    phase: TEST
    stage: 'test-on-test'
  }
>>>>>>> origin/BVLC/parallel
=======
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
=======
=======
<<<<<<< HEAD
>>>>>>> pod/caffe-merge
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
=======
  include: {
    phase: TEST
    stage: 'test-on-train'
  }
=======
    batch_size: 100
    backend: LMDB
  }
>>>>>>> caffe
<<<<<<< HEAD
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
}
layer {
=======
    batch_size: 100
    backend: LMDB
  }
}
layer {
>>>>>>> device-abstraction
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
    stage: "test-on-test"
=======
    stage: "test-on-train"
>>>>>>> pod-caffe-pod.hpp-merge
=======
    stage: "test-on-train"
>>>>>>> device-abstraction
  }
  transform_param {
    scale: 0.0039215684
  }
<<<<<<< HEAD
  data_param {
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
>>>>>>> caffe
}
layer {
>>>>>>> pod-caffe-pod.hpp-merge
=======
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    backend: LMDB
>>>>>>> origin/BVLC/parallel
    batch_size: 100
    backend: LMDB
  }
<<<<<<< HEAD
=======
  transform_param {
    scale: 0.0039215684
  }
  include: {
    phase: TEST
    stage: 'test-on-test'
  }
>>>>>>> origin/BVLC/parallel
=======
    source: "examples/mnist/mnist_train_lmdb"
=======
>>>>>>> pod/device/blob.hpp
    batch_size: 100
    backend: LMDB
  }
}
layer {
=======
<<<<<<< HEAD
=======
  type: DATA
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    backend: LMDB
>>>>>>> origin/BVLC/parallel
    batch_size: 100
    backend: LMDB
  }
<<<<<<< HEAD
=======
  transform_param {
    scale: 0.0039215684
  }
  include: { phase: TRAIN }
>>>>>>> origin/BVLC/parallel
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
    stage: "test-on-test"
=======
    stage: "test-on-train"
>>>>>>> pod/caffe-merge
  }
  transform_param {
    scale: 0.0039215684
  }
  data_param {
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
>>>>>>> caffe
}
layer {
>>>>>>> pod-caffe-pod.hpp-merge
=======
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    backend: LMDB
>>>>>>> origin/BVLC/parallel
    batch_size: 100
    backend: LMDB
  }
<<<<<<< HEAD
=======
  transform_param {
    scale: 0.0039215684
  }
  include: {
    phase: TEST
    stage: 'test-on-test'
  }
>>>>>>> origin/BVLC/parallel
=======
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
=======
  data_param {
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    backend: LMDB
>>>>>>> origin/BVLC/parallel
    batch_size: 100
    backend: LMDB
  }
<<<<<<< HEAD
=======
  transform_param {
    scale: 0.0039215684
  }
  include: {
    phase: TEST
    stage: 'test-on-test'
  }
>>>>>>> origin/BVLC/parallel
=======
    source: "examples/mnist/mnist_train_lmdb"
<<<<<<< HEAD
    batch_size: 100
    backend: LMDB
  }
}
layer {
<<<<<<< HEAD
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
>>>>>>> pod/device/blob.hpp
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
<<<<<<< HEAD
    stage: "test-on-train"
=======
    stage: "test-on-test"
=======
    backend: LMDB
    batch_size: 100
>>>>>>> origin/BVLC/parallel
>>>>>>> pod-caffe-pod.hpp-merge
  }
  transform_param {
    scale: 0.0039215684
  }
<<<<<<< HEAD
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
=======
<<<<<<< HEAD
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
=======
  include: {
    phase: TEST
    stage: 'test-on-train'
  }
=======
    batch_size: 100
    backend: LMDB
  }
>>>>>>> caffe
<<<<<<< HEAD
}
layer {
<<<<<<< HEAD
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
>>>>>>> device-abstraction
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
<<<<<<< HEAD
<<<<<<< HEAD
    stage: "test-on-test"
=======
    stage: "test-on-train"
>>>>>>> pod-caffe-pod.hpp-merge
=======
    stage: "test-on-test"
>>>>>>> device-abstraction
  }
  transform_param {
    scale: 0.0039215684
  }
  data_param {
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> device-abstraction
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
<<<<<<< HEAD
=======
<<<<<<< HEAD
    source: "examples/mnist/mnist_test_lmdb"
    backend: LMDB
>>>>>>> origin/BVLC/parallel
    batch_size: 100
    backend: LMDB
  }
<<<<<<< HEAD
=======
  transform_param {
    scale: 0.0039215684
  }
  include: {
    phase: TEST
    stage: 'test-on-test'
  }
>>>>>>> origin/BVLC/parallel
=======
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
    stage: "test-on-test"
  }
  transform_param {
    scale: 0.0039215684
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
>>>>>>> caffe
}
layer {
>>>>>>> pod-caffe-pod.hpp-merge
>>>>>>> pod/device/blob.hpp
=======
>>>>>>> device-abstraction
  name: "flatdata"
  type: "Flatten"
  bottom: "data"
  top: "flatdata"
}
layer {
  name: "encode1"
  type: "InnerProduct"
  bottom: "data"
  top: "encode1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "encode1neuron"
  type: "Sigmoid"
  bottom: "encode1"
  top: "encode1neuron"
}
layer {
  name: "encode2"
  type: "InnerProduct"
  bottom: "encode1neuron"
  top: "encode2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "encode2neuron"
  type: "Sigmoid"
  bottom: "encode2"
  top: "encode2neuron"
}
layer {
  name: "encode3"
  type: "InnerProduct"
  bottom: "encode2neuron"
  top: "encode3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "encode3neuron"
  type: "Sigmoid"
  bottom: "encode3"
  top: "encode3neuron"
}
layer {
  name: "encode4"
  type: "InnerProduct"
  bottom: "encode3neuron"
  top: "encode4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 30
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "decode4"
  type: "InnerProduct"
  bottom: "encode4"
  top: "decode4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "decode4neuron"
  type: "Sigmoid"
  bottom: "decode4"
  top: "decode4neuron"
}
layer {
  name: "decode3"
  type: "InnerProduct"
  bottom: "decode4neuron"
  top: "decode3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "decode3neuron"
  type: "Sigmoid"
  bottom: "decode3"
  top: "decode3neuron"
}
layer {
  name: "decode2"
  type: "InnerProduct"
  bottom: "decode3neuron"
  top: "decode2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "decode2neuron"
  type: "Sigmoid"
  bottom: "decode2"
  top: "decode2neuron"
}
layer {
  name: "decode1"
  type: "InnerProduct"
  bottom: "decode2neuron"
  top: "decode1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 784
    weight_filler {
      type: "gaussian"
      std: 1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "decode1"
  bottom: "flatdata"
  top: "cross_entropy_loss"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> pod-caffe-pod.hpp-merge
<<<<<<< HEAD
=======
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
=======
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> pod/device/blob.hpp
  name: "loss"
  type: SIGMOID_CROSS_ENTROPY_LOSS
>>>>>>> origin/BVLC/parallel
=======
>>>>>>> caffe
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
>>>>>>> pod/device/blob.hpp
=======
>>>>>>> device-abstraction
  loss_weight: 1
}
layer {
  name: "decode1neuron"
  type: "Sigmoid"
  bottom: "decode1"
  top: "decode1neuron"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> pod-caffe-pod.hpp-merge
<<<<<<< HEAD
=======
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
=======
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> pod/device/blob.hpp
  name: "decode1neuron"
  type: SIGMOID
>>>>>>> origin/BVLC/parallel
=======
>>>>>>> caffe
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
>>>>>>> pod/device/blob.hpp
=======
>>>>>>> device-abstraction
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "decode1neuron"
  bottom: "flatdata"
  top: "l2_error"
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> pod-caffe-pod.hpp-merge
<<<<<<< HEAD
=======
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
=======
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> pod/device/blob.hpp
  name: "loss"
  type: EUCLIDEAN_LOSS
>>>>>>> origin/BVLC/parallel
=======
>>>>>>> caffe
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod/caffe-merge
=======
>>>>>>> pod-caffe-pod.hpp-merge
>>>>>>> pod/device/blob.hpp
=======
>>>>>>> device-abstraction
  loss_weight: 0
}
