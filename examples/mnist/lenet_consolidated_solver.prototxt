# lenet_consolidated_solver.prototxt consolidates the lenet_solver, lenet_train,
# and lenet_test prototxts into a single file.  It also adds an additional test
# net which runs on the training set, e.g., for the purpose of comparing
# train/test accuracy (accuracy is computed only on the test set in the included
# LeNet example.  This is mainly included as an example of using these features
# (specify NetParameters directly in the solver, specify multiple test nets)
# if desired.
# 
# Carry out testing every 500 training iterations.
test_interval: 500
# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.01
momentum: 0.9
weight_decay: 0.0005
# The learning rate policy
lr_policy: "inv"
gamma: 0.0001
power: 0.75
# Display every 100 iterations
display: 100
# The maximum number of iterations
max_iter: 10000
# snapshot intermediate results
snapshot: 5000
snapshot_prefix: "lenet"
# Set a random_seed for repeatable results.
# (For results that vary due to random initialization, comment out the below
# line, or set to a negative integer -- e.g. "random_seed: -1")
random_seed: 1701
# solver mode: CPU or GPU
solver_mode: GPU

# The training protocol buffer definition
train_net_param {
  name: "LeNet"
  layers {
    name: "mnist"
    type: DATA
    top: "data"
    top: "label"
    data_param {
      source: "mnist-train-leveldb"
      scale: 0.00390625
      batch_size: 64
    }
  }
  layers {
    name: "conv1"
    type: CONVOLUTION
    bottom: "data"
    top: "conv1"
    blobs_lr: 1
    blobs_lr: 2
    convolution_param {
      num_output: 20
      kernel_size: 5
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "pool1"
    type: POOLING
    bottom: "conv1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layers {
    name: "conv2"
    type: CONVOLUTION
    bottom: "pool1"
    top: "conv2"
    blobs_lr: 1
    blobs_lr: 2
    convolution_param {
      num_output: 50
      kernel_size: 5
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "pool2"
    type: POOLING
    bottom: "conv2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layers {
    name: "ip1"
    type: INNER_PRODUCT
    bottom: "pool2"
    top: "ip1"
    blobs_lr: 1
    blobs_lr: 2
    inner_product_param {
      num_output: 500
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "relu1"
    type: RELU
    bottom: "ip1"
    top: "ip1"
  }
  layers {
    name: "ip2"
    type: INNER_PRODUCT
    bottom: "ip1"
    top: "ip2"
    blobs_lr: 1
    blobs_lr: 2
    inner_product_param {
      num_output: 10
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "loss"
    type: SOFTMAX_LOSS
    bottom: "ip2"
    bottom: "label"
  }
}

# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 100
# The testing protocol buffer definition
test_net_param {
  name: "LeNet-test"
  layers {
    name: "mnist"
    type: DATA
    top: "data"
    top: "label"
    data_param {
      source: "mnist-test-leveldb"
      scale: 0.00390625
      batch_size: 100
    }
  }
  layers {
    name: "conv1"
    type: CONVOLUTION
    bottom: "data"
    top: "conv1"
    convolution_param {
      num_output: 20
      kernel_size: 5
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "pool1"
    type: POOLING
    bottom: "conv1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layers {
    name: "conv2"
    type: CONVOLUTION
    bottom: "pool1"
    top: "conv2"
    convolution_param {
      num_output: 50
      kernel_size: 5
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "pool2"
    type: POOLING
    bottom: "conv2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layers {
    name: "ip1"
    type: INNER_PRODUCT
    bottom: "pool2"
    top: "ip1"
    inner_product_param {
      num_output: 500
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "relu1"
    type: RELU
    bottom: "ip1"
    top: "ip1"
  }
  layers {
    name: "ip2"
    type: INNER_PRODUCT
    bottom: "ip1"
    top: "ip2"
    inner_product_param {
      num_output: 10
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "prob"
    type: SOFTMAX
    bottom: "ip2"
    top: "prob"
  }
  layers {
    name: "accuracy"
    type: ACCURACY
    bottom: "prob"
    bottom: "label"
    top: "accuracy"
  }
}

# The train set has 60K images, so we run 600 test iters (600 * 100 = 60K).
test_iter: 600
# The protocol buffer definition to test on the train set
test_net_param {
  name: "LeNet-test-on-train"
  layers {
    name: "mnist"
    type: DATA
    top: "data"
    top: "label"
    data_param {
      source: "mnist-train-leveldb"
      scale: 0.00390625
      batch_size: 100
    }
  }
  layers {
    name: "conv1"
    type: CONVOLUTION
    bottom: "data"
    top: "conv1"
    convolution_param {
      num_output: 20
      kernel_size: 5
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "pool1"
    type: POOLING
    bottom: "conv1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layers {
    name: "conv2"
    type: CONVOLUTION
    bottom: "pool1"
    top: "conv2"
    convolution_param {
      num_output: 50
      kernel_size: 5
      stride: 1
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "pool2"
    type: POOLING
    bottom: "conv2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 2
      stride: 2
    }
  }
  layers {
    name: "ip1"
    type: INNER_PRODUCT
    bottom: "pool2"
    top: "ip1"
    inner_product_param {
      num_output: 500
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "relu1"
    type: RELU
    bottom: "ip1"
    top: "ip1"
  }
  layers {
    name: "ip2"
    type: INNER_PRODUCT
    bottom: "ip1"
    top: "ip2"
    inner_product_param {
      num_output: 10
      weight_filler {
        type: "xavier"
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layers {
    name: "prob"
    type: SOFTMAX
    bottom: "ip2"
    top: "prob"
  }
  layers {
    name: "accuracy"
    type: ACCURACY
    bottom: "prob"
    bottom: "label"
    top: "accuracy"
  }
}
