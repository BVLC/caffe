{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel classification on PASCAL using the image data layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is the case with the `pascal-multilabel-with-datalayer.ipynb` example, this tutorial considers multilabel claclassification on the PASCAL VOC 2012 dataset.\n",
    "\n",
    "Multilabel classification is a generalization of multiclass classification, where each instance (image) can belong to many classes. For example, an image may both belong to a \"beach\" category and a \"vacation pictures\" category. In multiclass classification, on the other hand, each image belongs to a single class.\n",
    "\n",
    "Caffe supports multilabel classification through the `SigmoidCrossEntropyLoss` layer. The input to the network is defined by an `ImageDataLayer`, which loads a list of images and corresponding labels from a text file. Data could also be provided through HDF5 or LMDB data layers (or even a Python data layer as in `pascal-multilabel-with-datalayer.ipynb`), but in some respects these layers are not as simple as just providing a list of images. The image data layer also has the advantage that it allows for the shuffling of the input data set after each epoch in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "This examples requires that Caffe and PyCaffe are already built.\n",
    "\n",
    "Download the Pascal VOC2012 data set. A script is provided at `../data/pascal/get_pascal.sh` which downloads the dataset. The example assumes that the dataset has been downloaded and extracted to `../data/pascal/VOC2012`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!../data/pascal/get_pascal.sh\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some modules\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "# Ensure that matplotlib figures are displayed in the notebook and specify their size.\n",
    "% matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (6, 6)\n",
    "\n",
    "caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
    "sys.path.append(caffe_root + 'python')\n",
    "import caffe # If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that the starting model (`bvlc_reference_caffenet`) is available\n",
    "The `download_model_binary.py` script is used to download pre-trained weights for the BVLC reference caffenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure we have the caffenet weight downloaded.\n",
    "if not os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
    "    print(\"Downloading pre-trained CaffeNet model...\")\n",
    "    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the required paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set root directory of the dataset\n",
    "pascal_root = os.path.join(caffe_root, 'data/pascal/VOC2012')\n",
    "# Set the directory where the model definitions and output files will be stored.\n",
    "workdir = \"./pascal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the file lists required by the `ImageDataLayer` used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Generating file lists\\n\")\n",
    "!python ../examples/pascal/create_file_list.py --ignore-background --pascal-root ../data/pascal/VOC2012 --output-path ./pascal\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Caffe (using the GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize caffe for gpu mode\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the network definition\n",
    "The network has been defined in the `pascal/solver_image_layer_notebook.prototxt` file. We load the network definition here and initialise it from the `bvlc_reference_caffenet` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver = caffe.SGDSolver(osp.join(workdir, 'solver_image_layer_notebook.prototxt'))\n",
    "solver.net.copy_from(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')\n",
    "solver.test_nets[0].share_with(solver.net)\n",
    "solver.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the class names as a list. Note The `ImageDataLayer` allows for labels to be ignored, although `__background__` is specified this is ignored for each image (and assigned a value of -1). See the lines of the files `trainval.list.txt` and `val.list.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# String representations of the class labels\n",
    "classes = np.array(('__background__', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'))\n",
    "\n",
    "# The network uses a label value of -1 to indicate that a label should be ignored.\n",
    "ig_label = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the input data\n",
    "We can now view the data loaded by the network (defined by the lines of the files `pascal/trainval.list.txt`). As we are viewing the Caffe Blobs directly, the following function is used to convert a caffe data blob to a image for display purposes. This involves changing the order of the axes as well as the color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deprocess(im):\n",
    "    \"\"\"Make a caffe blob viewable\"\"\"\n",
    "    im = im.transpose(1, 2, 0)\n",
    "    im = im[:, :, ::-1]  # change to RGB\n",
    "    return np.uint8(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first image loaded by the network as well as its corresponding labels. Note that labels to be ignored are not displayed. To confirm this, try setting `ig_label` to something other than -1 and confirm that the ground truth then contains the string `__background__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_index = 0 #Lets look at the first image in the batch.\n",
    "plt.imshow(deprocess(copy(solver.net.blobs['data'].data[image_index, ...])))\n",
    "gtlist = solver.net.blobs['label'].data[image_index, ...].astype(np.int)\n",
    "plt.title('GT: {}'.format(classes[np.where((gtlist) & (gtlist != ig_label))]))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** we are reading the image from the data layer, so the resolution is lower than the original PASCAL image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a network\n",
    "\n",
    "Let's train the net. It would be useful to have a means to measure accuracy. The Hamming distance is commonly used in multilabel problems, and we thus define the corresponding function. Note that labels which are ignored (`ig_label`) do not contribute to the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hamming_distance(gt, est):\n",
    "    return sum([1 for (g, e) in zip(gt, est) if g == e and g != ig_label]) / float(len(gt[np.where(gt != ig_label)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We also need a simple test loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy(net, num_batches, batch_size = 128):\n",
    "    acc = 0.0\n",
    "    for t in range(num_batches):\n",
    "        net.forward()\n",
    "        gts = net.blobs['label'].data\n",
    "        ests = net.blobs['score'].data > 0\n",
    "        for gt, est in zip(gts, ests): #for each ground truth and estimated label vector\n",
    "            acc += hamming_distance(gt, est)\n",
    "    return acc / (num_batches * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network for a while and output the computed accuracy at a number of intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for itt in range(6):\n",
    "    solver.step(100)\n",
    "    print 'itt:{:3d}'.format((itt + 1) * 100), 'accuracy:{0:.4f}'.format(check_accuracy(solver.test_nets[0], 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The accuracy is increasing, and it seems to converge rather quickly. It may seem strange that it starts off so high but it is because the ground truth is sparse. There are 20 classes in PASCAL, and usually only one or two are present. So predicting all zeros yields rather high accuracy. Let's check to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_baseline_accuracy(net, num_batches, batch_size = 128):\n",
    "    acc = 0.0\n",
    "    for t in range(num_batches):\n",
    "        net.forward()\n",
    "        gts = net.blobs['label'].data\n",
    "        # Provide zeros as the estimated labels.\n",
    "        ests = np.zeros((batch_size, len(gts)))\n",
    "        for gt, est in zip(gts, ests): #for each ground truth and estimated label vector\n",
    "            acc += hamming_distance(gt, est)\n",
    "    return acc / (num_batches * batch_size)\n",
    "\n",
    "print 'Baseline accuracy:{0:.4f}'.format(check_baseline_accuracy(solver.test_nets[0], 5823/128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some prediction results\n",
    "Since the network has now been trained somewhat, we can look at the predicitions for futher input files. Perform inferrence for a selection of images from the intput set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_net = solver.test_nets[0]\n",
    "for image_index in range(5):\n",
    "    plt.figure()\n",
    "    plt.imshow(deprocess(copy(test_net.blobs['data'].data[image_index, ...])))\n",
    "    gtlist = test_net.blobs['label'].data[image_index, ...].astype(np.int)\n",
    "    estlist = test_net.blobs['score'].data[image_index, ...] > 0\n",
    "    plt.title('GT: {} \\n EST: {}'.format(classes[np.where((gtlist) & (gtlist != ig_label))], classes[np.where(estlist)]))\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
