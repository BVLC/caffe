<!doctype html>
<html>
  <head>
    <!-- MathJax -->
    <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>
      Caffe | Layer Catalogue
    </title>

    <link rel="icon" type="image/png" href="/images/caffeine-icon.png">

    <link rel="stylesheet" href="/stylesheets/reset.css">
    <link rel="stylesheet" href="/stylesheets/styles.css">
    <link rel="stylesheet" href="/stylesheets/pygment_trac.css">

    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46255508-1', 'daggerfs.com');
    ga('send', 'pageview');
  </script>
    <div class="wrapper">
      <header>
        <h1 class="header"><a href="/">Caffe</a></h1>
        <p class="header">
          Deep learning framework by <a class="header name" href="http://bair.berkeley.edu/">BAIR</a>
        </p>
        <p class="header">
          Created by
          <br>
          <a class="header name" href="http://daggerfs.com/">Yangqing Jia</a>
          <br>
          Lead Developer
          <br>
          <a class="header name" href="http://imaginarynumber.net/">Evan Shelhamer</a>
        <ul>
          <li>
            <a class="buttons github" href="https://github.com/BVLC/caffe">View On GitHub</a>
          </li>
        </ul>
      </header>
      <section>

      <h1 id="layers">Layers</h1>

<p>To create a Caffe model you need to define the model architecture in a protocol buffer definition file (prototxt).</p>

<p>Caffe layers and their parameters are defined in the protocol buffer definitions for the project in <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto">caffe.proto</a>.</p>

<h2 id="data-layers">Data Layers</h2>

<p>Data enters Caffe through data layers: they lie at the bottom of nets. Data can come from efficient databases (LevelDB or LMDB), directly from memory, or, when efficiency is not critical, from files on disk in HDF5 or common image formats.</p>

<p>Common input preprocessing (mean subtraction, scaling, random cropping, and mirroring) is available by specifying <code class="highlighter-rouge">TransformationParameter</code>s by some of the layers.
The <a href="layers/bias.html">bias</a>, <a href="layers/scale.html">scale</a>, and <a href="layers/crop.html">crop</a> layers can be helpful with transforming the inputs, when <code class="highlighter-rouge">TransformationParameter</code> isn’t available.</p>

<p>Layers:</p>

<ul>
  <li><a href="layers/imagedata.html">Image Data</a> - read raw images.</li>
  <li><a href="layers/data.html">Database</a> - read data from LEVELDB or LMDB.</li>
  <li><a href="layers/hdf5data.html">HDF5 Input</a> - read HDF5 data, allows data of arbitrary dimensions.</li>
  <li><a href="layers/hdf5output.html">HDF5 Output</a> - write data as HDF5.</li>
  <li><a href="layers/input.html">Input</a> - typically used for networks that are being deployed.</li>
  <li><a href="layers/windowdata.html">Window Data</a> - read window data file.</li>
  <li><a href="layers/memorydata.html">Memory Data</a> - read data directly from memory.</li>
  <li><a href="layers/dummydata.html">Dummy Data</a> - for static data and debugging.</li>
</ul>

<p>Note that the <a href="layers/python.html">Python</a> Layer can be useful for create custom data layers.</p>

<h2 id="vision-layers">Vision Layers</h2>

<p>Vision layers usually take <em>images</em> as input and produce other <em>images</em> as output, although they can take data of other types and dimensions.
A typical “image” in the real-world may have one color channel (<script type="math/tex">c = 1</script>), as in a grayscale image, or three color channels (<script type="math/tex">c = 3</script>) as in an RGB (red, green, blue) image.
But in this context, the distinguishing characteristic of an image is its spatial structure: usually an image has some non-trivial height <script type="math/tex">h > 1</script> and width <script type="math/tex">w > 1</script>.
This 2D geometry naturally lends itself to certain decisions about how to process the input.
In particular, most of the vision layers work by applying a particular operation to some region of the input to produce a corresponding region of the output.
In contrast, other layers (with few exceptions) ignore the spatial structure of the input, effectively treating it as “one big vector” with dimension <script type="math/tex">chw</script>.</p>

<p>Layers:</p>

<ul>
  <li><a href="layers/convolution.html">Convolution Layer</a> - convolves the input image with a set of learnable filters, each producing one feature map in the output image.</li>
  <li><a href="layers/pooling.html">Pooling Layer</a> - max, average, or stochastic pooling.</li>
  <li><a href="layers/spp.html">Spatial Pyramid Pooling (SPP)</a></li>
  <li><a href="layers/crop.html">Crop</a> - perform cropping transformation.</li>
  <li>
    <p><a href="layers/deconvolution.html">Deconvolution Layer</a> - transposed convolution.</p>
  </li>
  <li><a href="layers/im2col.html">Im2Col</a> - relic helper layer that is not used much anymore.</li>
</ul>

<h2 id="recurrent-layers">Recurrent Layers</h2>

<p>Layers:</p>

<ul>
  <li><a href="layers/recurrent.html">Recurrent</a></li>
  <li><a href="layers/rnn.html">RNN</a></li>
  <li><a href="layers/lstm.html">Long-Short Term Memory (LSTM)</a></li>
</ul>

<h2 id="common-layers">Common Layers</h2>

<p>Layers:</p>

<ul>
  <li><a href="layers/innerproduct.html">Inner Product</a> - fully connected layer.</li>
  <li><a href="layers/dropout.html">Dropout</a></li>
  <li><a href="layers/embed.html">Embed</a> - for learning embeddings of one-hot encoded vector (takes index as input).</li>
</ul>

<h2 id="normalization-layers">Normalization Layers</h2>

<ul>
  <li><a href="layers/lrn.html">Local Response Normalization (LRN)</a> - performs a kind of “lateral inhibition” by normalizing over local input regions.</li>
  <li><a href="layers/mvn.html">Mean Variance Normalization (MVN)</a> - performs contrast normalization / instance normalization.</li>
  <li><a href="layers/batchnorm.html">Batch Normalization</a> - performs normalization over mini-batches.</li>
</ul>

<p>The <a href="layers/bias.html">bias</a> and <a href="layers/scale.html">scale</a> layers can be helpful in combination with normalization.</p>

<h2 id="activation--neuron-layers">Activation / Neuron Layers</h2>

<p>In general, activation / Neuron layers are element-wise operators, taking one bottom blob and producing one top blob of the same size. In the layers below, we will ignore the input and out sizes as they are identical:</p>

<ul>
  <li>Input
    <ul>
      <li>n * c * h * w</li>
    </ul>
  </li>
  <li>Output
    <ul>
      <li>n * c * h * w</li>
    </ul>
  </li>
</ul>

<p>Layers:</p>

<ul>
  <li><a href="layers/relu.html">ReLU / Rectified-Linear and Leaky-ReLU</a> - ReLU and Leaky-ReLU rectification.</li>
  <li><a href="layers/prelu.html">PReLU</a> - parametric ReLU.</li>
  <li><a href="layers/elu.html">ELU</a> - exponential linear rectification.</li>
  <li><a href="layers/sigmoid.html">Sigmoid</a></li>
  <li><a href="layers/tanh.html">TanH</a></li>
  <li><a href="layers/abs.html">Absolute Value</a></li>
  <li><a href="layers/power.html">Power</a> - f(x) = (shift + scale * x) ^ power.</li>
  <li><a href="layers/exp.html">Exp</a> - f(x) = base ^ (shift + scale * x).</li>
  <li><a href="layers/log.html">Log</a> - f(x) = log(x).</li>
  <li><a href="layers/bnll.html">BNLL</a> - f(x) = log(1 + exp(x)).</li>
  <li><a href="layers/threshold.html">Threshold</a> - performs step function at user defined threshold.</li>
  <li><a href="layers/bias.html">Bias</a> - adds a bias to a blob that can either be learned or fixed.</li>
  <li><a href="layers/scale.html">Scale</a> - scales a blob by an amount that can either be learned or fixed.</li>
</ul>

<h2 id="utility-layers">Utility Layers</h2>

<p>Layers:</p>

<ul>
  <li><a href="layers/flatten.html">Flatten</a></li>
  <li><a href="layers/reshape.html">Reshape</a></li>
  <li>
    <p><a href="layers/batchreindex.html">Batch Reindex</a></p>
  </li>
  <li><a href="layers/split.html">Split</a></li>
  <li><a href="layers/concat.html">Concat</a></li>
  <li><a href="layers/slice.html">Slicing</a></li>
  <li><a href="layers/eltwise.html">Eltwise</a> - element-wise operations such as product or sum between two blobs.</li>
  <li><a href="layers/filter.html">Filter / Mask</a> - mask or select output using last blob.</li>
  <li><a href="layers/parameter.html">Parameter</a> - enable parameters to be shared between layers.</li>
  <li><a href="layers/reduction.html">Reduction</a> - reduce input blob to scalar blob using operations such as sum or mean.</li>
  <li>
    <p><a href="layers/silence.html">Silence</a> - prevent top-level blobs from being printed during training.</p>
  </li>
  <li><a href="layers/argmax.html">ArgMax</a></li>
  <li>
    <p><a href="layers/softmax.html">Softmax</a></p>
  </li>
  <li><a href="layers/python.html">Python</a> - allows custom Python layers.</li>
</ul>

<h2 id="loss-layers">Loss Layers</h2>

<p>Loss drives learning by comparing an output to a target and assigning cost to minimize. The loss itself is computed by the forward pass and the gradient w.r.t. to the loss is computed by the backward pass.</p>

<p>Layers:</p>

<ul>
  <li><a href="layers/multinomiallogisticloss.html">Multinomial Logistic Loss</a></li>
  <li><a href="layers/infogainloss.html">Infogain Loss</a> - a generalization of MultinomialLogisticLossLayer.</li>
  <li><a href="layers/softmaxwithloss.html">Softmax with Loss</a> - computes the multinomial logistic loss of the softmax of its inputs. It’s conceptually identical to a softmax layer followed by a multinomial logistic loss layer, but provides a more numerically stable gradient.</li>
  <li><a href="layers/euclideanloss.html">Sum-of-Squares / Euclidean</a> - computes the sum of squares of differences of its two inputs, <script type="math/tex">\frac 1 {2N} \sum_{i=1}^N \| x^1_i - x^2_i \|_2^2</script>.</li>
  <li><a href="layers/hingeloss.html">Hinge / Margin</a> - The hinge loss layer computes a one-vs-all hinge (L1) or squared hinge loss (L2).</li>
  <li><a href="layers/sigmoidcrossentropyloss.html">Sigmoid Cross-Entropy Loss</a> - computes the cross-entropy (logistic) loss, often used for predicting targets interpreted as probabilities.</li>
  <li><a href="layers/accuracy.html">Accuracy / Top-k layer</a> - scores the output as an accuracy with respect to target – it is not actually a loss and has no backward step.</li>
  <li><a href="layers/contrastiveloss.html">Contrastive Loss</a></li>
</ul>



      </section>
  </div>
  </body>
</html>
