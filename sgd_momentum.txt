I0216 21:36:15.305614 15389 caffe.cpp:99] Use GPU with device ID 0
I0216 21:36:15.636533 15389 caffe.cpp:107] Starting Optimization
I0216 21:36:15.636705 15389 solver.cpp:32] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/models/lenet"
solver_mode: GPU
net: "examples/mnist/lenet_train_test.prototxt"
I0216 21:36:15.636760 15389 solver.cpp:70] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I0216 21:36:15.637282 15389 net.cpp:260] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0216 21:36:15.637306 15389 net.cpp:260] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0216 21:36:15.637418 15389 net.cpp:39] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0216 21:36:15.637496 15389 layer_factory.hpp:74] Creating layer mnist
I0216 21:36:15.637526 15389 net.cpp:69] Creating Layer mnist
I0216 21:36:15.637537 15389 net.cpp:341] mnist -> data
I0216 21:36:15.637565 15389 net.cpp:341] mnist -> label
I0216 21:36:15.637581 15389 net.cpp:98] Setting up mnist
I0216 21:36:15.637694 15389 db.cpp:34] Opened lmdb examples/mnist/mnist_train_lmdb
I0216 21:36:15.637758 15389 data_layer.cpp:65] output data size: 64,1,28,28
I0216 21:36:15.637948 15389 net.cpp:105] Top shape: 64 1 28 28 (50176)
I0216 21:36:15.637964 15389 net.cpp:105] Top shape: 64 1 1 1 (64)
I0216 21:36:15.637974 15389 layer_factory.hpp:74] Creating layer conv1
I0216 21:36:15.637989 15389 net.cpp:69] Creating Layer conv1
I0216 21:36:15.638073 15389 net.cpp:379] conv1 <- data
I0216 21:36:15.638155 15389 net.cpp:341] conv1 -> conv1
I0216 21:36:15.638180 15389 net.cpp:98] Setting up conv1
I0216 21:36:15.638823 15389 net.cpp:105] Top shape: 64 20 24 24 (737280)
I0216 21:36:15.638913 15389 layer_factory.hpp:74] Creating layer pool1
I0216 21:36:15.638947 15389 net.cpp:69] Creating Layer pool1
I0216 21:36:15.638963 15389 net.cpp:379] pool1 <- conv1
I0216 21:36:15.638988 15389 net.cpp:341] pool1 -> pool1
I0216 21:36:15.639011 15389 net.cpp:98] Setting up pool1
I0216 21:36:15.639107 15389 net.cpp:105] Top shape: 64 20 12 12 (184320)
I0216 21:36:15.639185 15389 layer_factory.hpp:74] Creating layer conv2
I0216 21:36:15.639224 15389 net.cpp:69] Creating Layer conv2
I0216 21:36:15.639240 15389 net.cpp:379] conv2 <- pool1
I0216 21:36:15.639264 15389 net.cpp:341] conv2 -> conv2
I0216 21:36:15.639304 15389 net.cpp:98] Setting up conv2
I0216 21:36:15.640028 15389 net.cpp:105] Top shape: 64 50 8 8 (204800)
I0216 21:36:15.640076 15389 layer_factory.hpp:74] Creating layer pool2
I0216 21:36:15.640103 15389 net.cpp:69] Creating Layer pool2
I0216 21:36:15.640118 15389 net.cpp:379] pool2 <- conv2
I0216 21:36:15.640146 15389 net.cpp:341] pool2 -> pool2
I0216 21:36:15.640169 15389 net.cpp:98] Setting up pool2
I0216 21:36:15.640188 15389 net.cpp:105] Top shape: 64 50 4 4 (51200)
I0216 21:36:15.640203 15389 layer_factory.hpp:74] Creating layer ip1
I0216 21:36:15.640236 15389 net.cpp:69] Creating Layer ip1
I0216 21:36:15.640269 15389 net.cpp:379] ip1 <- pool2
I0216 21:36:15.640296 15389 net.cpp:341] ip1 -> ip1
I0216 21:36:15.640321 15389 net.cpp:98] Setting up ip1
I0216 21:36:15.647832 15389 net.cpp:105] Top shape: 64 500 1 1 (32000)
I0216 21:36:15.647863 15389 layer_factory.hpp:74] Creating layer relu1
I0216 21:36:15.647877 15389 net.cpp:69] Creating Layer relu1
I0216 21:36:15.647884 15389 net.cpp:379] relu1 <- ip1
I0216 21:36:15.647893 15389 net.cpp:330] relu1 -> ip1 (in-place)
I0216 21:36:15.647903 15389 net.cpp:98] Setting up relu1
I0216 21:36:15.647914 15389 net.cpp:105] Top shape: 64 500 1 1 (32000)
I0216 21:36:15.647922 15389 layer_factory.hpp:74] Creating layer ip2
I0216 21:36:15.647933 15389 net.cpp:69] Creating Layer ip2
I0216 21:36:15.647940 15389 net.cpp:379] ip2 <- ip1
I0216 21:36:15.647953 15389 net.cpp:341] ip2 -> ip2
I0216 21:36:15.647964 15389 net.cpp:98] Setting up ip2
I0216 21:36:15.648028 15389 net.cpp:105] Top shape: 64 10 1 1 (640)
I0216 21:36:15.648043 15389 layer_factory.hpp:74] Creating layer loss
I0216 21:36:15.648061 15389 net.cpp:69] Creating Layer loss
I0216 21:36:15.648068 15389 net.cpp:379] loss <- ip2
I0216 21:36:15.648077 15389 net.cpp:379] loss <- label
I0216 21:36:15.648085 15389 net.cpp:341] loss -> loss
I0216 21:36:15.648098 15389 net.cpp:98] Setting up loss
I0216 21:36:15.648110 15389 layer_factory.hpp:74] Creating layer loss
I0216 21:36:15.648131 15389 net.cpp:105] Top shape: 1 1 1 1 (1)
I0216 21:36:15.648141 15389 net.cpp:111]     with loss weight 1
I0216 21:36:15.648176 15389 net.cpp:156] loss needs backward computation.
I0216 21:36:15.648185 15389 net.cpp:156] ip2 needs backward computation.
I0216 21:36:15.648192 15389 net.cpp:156] relu1 needs backward computation.
I0216 21:36:15.648198 15389 net.cpp:156] ip1 needs backward computation.
I0216 21:36:15.648206 15389 net.cpp:156] pool2 needs backward computation.
I0216 21:36:15.648212 15389 net.cpp:156] conv2 needs backward computation.
I0216 21:36:15.648221 15389 net.cpp:156] pool1 needs backward computation.
I0216 21:36:15.648226 15389 net.cpp:156] conv1 needs backward computation.
I0216 21:36:15.648233 15389 net.cpp:158] mnist does not need backward computation.
I0216 21:36:15.648242 15389 net.cpp:194] This network produces output loss
I0216 21:36:15.648258 15389 net.cpp:453] Collecting Learning Rate and Weight Decay.
I0216 21:36:15.648273 15389 net.cpp:206] Network initialization done.
I0216 21:36:15.648279 15389 net.cpp:207] Memory required for data: 5169924
I0216 21:36:15.648784 15389 solver.cpp:154] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I0216 21:36:15.648824 15389 net.cpp:260] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0216 21:36:15.648970 15389 net.cpp:39] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0216 21:36:15.649085 15389 layer_factory.hpp:74] Creating layer mnist
I0216 21:36:15.649102 15389 net.cpp:69] Creating Layer mnist
I0216 21:36:15.649112 15389 net.cpp:341] mnist -> data
I0216 21:36:15.649126 15389 net.cpp:341] mnist -> label
I0216 21:36:15.649137 15389 net.cpp:98] Setting up mnist
I0216 21:36:15.649224 15389 db.cpp:34] Opened lmdb examples/mnist/mnist_test_lmdb
I0216 21:36:15.649271 15389 data_layer.cpp:65] output data size: 100,1,28,28
I0216 21:36:15.649543 15389 net.cpp:105] Top shape: 100 1 28 28 (78400)
I0216 21:36:15.649559 15389 net.cpp:105] Top shape: 100 1 1 1 (100)
I0216 21:36:15.649567 15389 layer_factory.hpp:74] Creating layer label_mnist_1_split
I0216 21:36:15.649577 15389 net.cpp:69] Creating Layer label_mnist_1_split
I0216 21:36:15.649585 15389 net.cpp:379] label_mnist_1_split <- label
I0216 21:36:15.649667 15389 net.cpp:341] label_mnist_1_split -> label_mnist_1_split_0
I0216 21:36:15.649765 15389 net.cpp:341] label_mnist_1_split -> label_mnist_1_split_1
I0216 21:36:15.649796 15389 net.cpp:98] Setting up label_mnist_1_split
I0216 21:36:15.649842 15389 net.cpp:105] Top shape: 100 1 1 1 (100)
I0216 21:36:15.649854 15389 net.cpp:105] Top shape: 100 1 1 1 (100)
I0216 21:36:15.649881 15389 layer_factory.hpp:74] Creating layer conv1
I0216 21:36:15.649910 15389 net.cpp:69] Creating Layer conv1
I0216 21:36:15.649935 15389 net.cpp:379] conv1 <- data
I0216 21:36:15.649960 15389 net.cpp:341] conv1 -> conv1
I0216 21:36:15.649988 15389 net.cpp:98] Setting up conv1
I0216 21:36:15.650063 15389 net.cpp:105] Top shape: 100 20 24 24 (1152000)
I0216 21:36:15.650109 15389 layer_factory.hpp:74] Creating layer pool1
I0216 21:36:15.650135 15389 net.cpp:69] Creating Layer pool1
I0216 21:36:15.650151 15389 net.cpp:379] pool1 <- conv1
I0216 21:36:15.650171 15389 net.cpp:341] pool1 -> pool1
I0216 21:36:15.650192 15389 net.cpp:98] Setting up pool1
I0216 21:36:15.650219 15389 net.cpp:105] Top shape: 100 20 12 12 (288000)
I0216 21:36:15.650236 15389 layer_factory.hpp:74] Creating layer conv2
I0216 21:36:15.650261 15389 net.cpp:69] Creating Layer conv2
I0216 21:36:15.650276 15389 net.cpp:379] conv2 <- pool1
I0216 21:36:15.650302 15389 net.cpp:341] conv2 -> conv2
I0216 21:36:15.650327 15389 net.cpp:98] Setting up conv2
I0216 21:36:15.651023 15389 net.cpp:105] Top shape: 100 50 8 8 (320000)
I0216 21:36:15.651098 15389 layer_factory.hpp:74] Creating layer pool2
I0216 21:36:15.651154 15389 net.cpp:69] Creating Layer pool2
I0216 21:36:15.651170 15389 net.cpp:379] pool2 <- conv2
I0216 21:36:15.651199 15389 net.cpp:341] pool2 -> pool2
I0216 21:36:15.651223 15389 net.cpp:98] Setting up pool2
I0216 21:36:15.651242 15389 net.cpp:105] Top shape: 100 50 4 4 (80000)
I0216 21:36:15.651258 15389 layer_factory.hpp:74] Creating layer ip1
I0216 21:36:15.651281 15389 net.cpp:69] Creating Layer ip1
I0216 21:36:15.651296 15389 net.cpp:379] ip1 <- pool2
I0216 21:36:15.651322 15389 net.cpp:341] ip1 -> ip1
I0216 21:36:15.651350 15389 net.cpp:98] Setting up ip1
I0216 21:36:15.658943 15389 net.cpp:105] Top shape: 100 500 1 1 (50000)
I0216 21:36:15.658995 15389 layer_factory.hpp:74] Creating layer relu1
I0216 21:36:15.659009 15389 net.cpp:69] Creating Layer relu1
I0216 21:36:15.659018 15389 net.cpp:379] relu1 <- ip1
I0216 21:36:15.659029 15389 net.cpp:330] relu1 -> ip1 (in-place)
I0216 21:36:15.659039 15389 net.cpp:98] Setting up relu1
I0216 21:36:15.659047 15389 net.cpp:105] Top shape: 100 500 1 1 (50000)
I0216 21:36:15.659054 15389 layer_factory.hpp:74] Creating layer ip2
I0216 21:36:15.659071 15389 net.cpp:69] Creating Layer ip2
I0216 21:36:15.659090 15389 net.cpp:379] ip2 <- ip1
I0216 21:36:15.659101 15389 net.cpp:341] ip2 -> ip2
I0216 21:36:15.659113 15389 net.cpp:98] Setting up ip2
I0216 21:36:15.659183 15389 net.cpp:105] Top shape: 100 10 1 1 (1000)
I0216 21:36:15.659198 15389 layer_factory.hpp:74] Creating layer ip2_ip2_0_split
I0216 21:36:15.659209 15389 net.cpp:69] Creating Layer ip2_ip2_0_split
I0216 21:36:15.659216 15389 net.cpp:379] ip2_ip2_0_split <- ip2
I0216 21:36:15.659225 15389 net.cpp:341] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0216 21:36:15.659237 15389 net.cpp:341] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0216 21:36:15.659247 15389 net.cpp:98] Setting up ip2_ip2_0_split
I0216 21:36:15.659256 15389 net.cpp:105] Top shape: 100 10 1 1 (1000)
I0216 21:36:15.659265 15389 net.cpp:105] Top shape: 100 10 1 1 (1000)
I0216 21:36:15.659271 15389 layer_factory.hpp:74] Creating layer accuracy
I0216 21:36:15.659286 15389 net.cpp:69] Creating Layer accuracy
I0216 21:36:15.659302 15389 net.cpp:379] accuracy <- ip2_ip2_0_split_0
I0216 21:36:15.659312 15389 net.cpp:379] accuracy <- label_mnist_1_split_0
I0216 21:36:15.659320 15389 net.cpp:341] accuracy -> accuracy
I0216 21:36:15.659330 15389 net.cpp:98] Setting up accuracy
I0216 21:36:15.659339 15389 net.cpp:105] Top shape: 1 1 1 1 (1)
I0216 21:36:15.659348 15389 layer_factory.hpp:74] Creating layer loss
I0216 21:36:15.659358 15389 net.cpp:69] Creating Layer loss
I0216 21:36:15.659365 15389 net.cpp:379] loss <- ip2_ip2_0_split_1
I0216 21:36:15.659373 15389 net.cpp:379] loss <- label_mnist_1_split_1
I0216 21:36:15.659385 15389 net.cpp:341] loss -> loss
I0216 21:36:15.659395 15389 net.cpp:98] Setting up loss
I0216 21:36:15.659405 15389 layer_factory.hpp:74] Creating layer loss
I0216 21:36:15.659426 15389 net.cpp:105] Top shape: 1 1 1 1 (1)
I0216 21:36:15.659440 15389 net.cpp:111]     with loss weight 1
I0216 21:36:15.659456 15389 net.cpp:156] loss needs backward computation.
I0216 21:36:15.659464 15389 net.cpp:158] accuracy does not need backward computation.
I0216 21:36:15.659471 15389 net.cpp:156] ip2_ip2_0_split needs backward computation.
I0216 21:36:15.659477 15389 net.cpp:156] ip2 needs backward computation.
I0216 21:36:15.659484 15389 net.cpp:156] relu1 needs backward computation.
I0216 21:36:15.659490 15389 net.cpp:156] ip1 needs backward computation.
I0216 21:36:15.659498 15389 net.cpp:156] pool2 needs backward computation.
I0216 21:36:15.659504 15389 net.cpp:156] conv2 needs backward computation.
I0216 21:36:15.659512 15389 net.cpp:156] pool1 needs backward computation.
I0216 21:36:15.659518 15389 net.cpp:156] conv1 needs backward computation.
I0216 21:36:15.659525 15389 net.cpp:158] label_mnist_1_split does not need backward computation.
I0216 21:36:15.659533 15389 net.cpp:158] mnist does not need backward computation.
I0216 21:36:15.659538 15389 net.cpp:194] This network produces output accuracy
I0216 21:36:15.659561 15389 net.cpp:194] This network produces output loss
I0216 21:36:15.659590 15389 net.cpp:453] Collecting Learning Rate and Weight Decay.
I0216 21:36:15.659601 15389 net.cpp:206] Network initialization done.
I0216 21:36:15.659608 15389 net.cpp:207] Memory required for data: 8086808
I0216 21:36:15.659677 15389 solver.cpp:42] Solver scaffolding done.
I0216 21:36:15.659709 15389 solver.cpp:223] Solving LeNet
I0216 21:36:15.659718 15389 solver.cpp:224] Learning Rate Policy: inv
I0216 21:36:15.659725 15389 solver.cpp:267] Iteration 0, Testing net (#0)
I0216 21:36:17.435143 15389 solver.cpp:318]     Test net output #0: accuracy = 0.1097
I0216 21:36:17.435231 15389 solver.cpp:318]     Test net output #1: loss = 2.30274 (* 1 = 2.30274 loss)
I0216 21:36:17.452062 15389 solver.cpp:189] Iteration 0, loss = 2.3033
I0216 21:36:17.452147 15389 solver.cpp:204]     Train net output #0: loss = 2.3033 (* 1 = 2.3033 loss)
I0216 21:36:17.452185 15389 solver.cpp:474] Iteration 0, lr = 0.01
I0216 21:36:19.883262 15389 solver.cpp:189] Iteration 100, loss = 0.309779
I0216 21:36:19.883373 15389 solver.cpp:204]     Train net output #0: loss = 0.309779 (* 1 = 0.309779 loss)
I0216 21:36:19.883396 15389 solver.cpp:474] Iteration 100, lr = 0.00992565
I0216 21:36:22.313297 15389 solver.cpp:189] Iteration 200, loss = 0.147992
I0216 21:36:22.313376 15389 solver.cpp:204]     Train net output #0: loss = 0.147992 (* 1 = 0.147992 loss)
I0216 21:36:22.313392 15389 solver.cpp:474] Iteration 200, lr = 0.00985258
I0216 21:36:24.744140 15389 solver.cpp:189] Iteration 300, loss = 0.216221
I0216 21:36:24.744246 15389 solver.cpp:204]     Train net output #0: loss = 0.216221 (* 1 = 0.216221 loss)
I0216 21:36:24.744261 15389 solver.cpp:474] Iteration 300, lr = 0.00978075
I0216 21:36:27.171924 15389 solver.cpp:189] Iteration 400, loss = 0.111584
I0216 21:36:27.172010 15389 solver.cpp:204]     Train net output #0: loss = 0.111584 (* 1 = 0.111584 loss)
I0216 21:36:27.172026 15389 solver.cpp:474] Iteration 400, lr = 0.00971013
I0216 21:36:29.576151 15389 solver.cpp:267] Iteration 500, Testing net (#0)
I0216 21:36:31.361176 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9686
I0216 21:36:31.361254 15389 solver.cpp:318]     Test net output #1: loss = 0.0998101 (* 1 = 0.0998101 loss)
I0216 21:36:31.374886 15389 solver.cpp:189] Iteration 500, loss = 0.106511
I0216 21:36:31.374922 15389 solver.cpp:204]     Train net output #0: loss = 0.106512 (* 1 = 0.106512 loss)
I0216 21:36:31.374939 15389 solver.cpp:474] Iteration 500, lr = 0.00964069
I0216 21:36:33.806931 15389 solver.cpp:189] Iteration 600, loss = 0.0905579
I0216 21:36:33.807049 15389 solver.cpp:204]     Train net output #0: loss = 0.090558 (* 1 = 0.090558 loss)
I0216 21:36:33.807081 15389 solver.cpp:474] Iteration 600, lr = 0.0095724
I0216 21:36:36.234321 15389 solver.cpp:189] Iteration 700, loss = 0.142604
I0216 21:36:36.234400 15389 solver.cpp:204]     Train net output #0: loss = 0.142604 (* 1 = 0.142604 loss)
I0216 21:36:36.234413 15389 solver.cpp:474] Iteration 700, lr = 0.00950522
I0216 21:36:38.658712 15389 solver.cpp:189] Iteration 800, loss = 0.204161
I0216 21:36:38.658790 15389 solver.cpp:204]     Train net output #0: loss = 0.204161 (* 1 = 0.204161 loss)
I0216 21:36:38.658807 15389 solver.cpp:474] Iteration 800, lr = 0.00943913
I0216 21:36:41.090229 15389 solver.cpp:189] Iteration 900, loss = 0.18766
I0216 21:36:41.090337 15389 solver.cpp:204]     Train net output #0: loss = 0.18766 (* 1 = 0.18766 loss)
I0216 21:36:41.090517 15389 solver.cpp:474] Iteration 900, lr = 0.00937411
I0216 21:36:43.495344 15389 solver.cpp:267] Iteration 1000, Testing net (#0)
I0216 21:36:45.284545 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9787
I0216 21:36:45.284718 15389 solver.cpp:318]     Test net output #1: loss = 0.0634921 (* 1 = 0.0634921 loss)
I0216 21:36:45.298938 15389 solver.cpp:189] Iteration 1000, loss = 0.101848
I0216 21:36:45.298974 15389 solver.cpp:204]     Train net output #0: loss = 0.101848 (* 1 = 0.101848 loss)
I0216 21:36:45.298990 15389 solver.cpp:474] Iteration 1000, lr = 0.00931012
I0216 21:36:47.728292 15389 solver.cpp:189] Iteration 1100, loss = 0.0113227
I0216 21:36:47.728602 15389 solver.cpp:204]     Train net output #0: loss = 0.0113228 (* 1 = 0.0113228 loss)
I0216 21:36:47.728618 15389 solver.cpp:474] Iteration 1100, lr = 0.00924715
I0216 21:36:50.154970 15389 solver.cpp:189] Iteration 1200, loss = 0.0267541
I0216 21:36:50.155078 15389 solver.cpp:204]     Train net output #0: loss = 0.0267542 (* 1 = 0.0267542 loss)
I0216 21:36:50.155100 15389 solver.cpp:474] Iteration 1200, lr = 0.00918515
I0216 21:36:52.585556 15389 solver.cpp:189] Iteration 1300, loss = 0.0196898
I0216 21:36:52.585628 15389 solver.cpp:204]     Train net output #0: loss = 0.0196899 (* 1 = 0.0196899 loss)
I0216 21:36:52.585643 15389 solver.cpp:474] Iteration 1300, lr = 0.00912412
I0216 21:36:55.015163 15389 solver.cpp:189] Iteration 1400, loss = 0.0101951
I0216 21:36:55.015239 15389 solver.cpp:204]     Train net output #0: loss = 0.0101952 (* 1 = 0.0101952 loss)
I0216 21:36:55.015259 15389 solver.cpp:474] Iteration 1400, lr = 0.00906403
I0216 21:36:57.420881 15389 solver.cpp:267] Iteration 1500, Testing net (#0)
I0216 21:36:59.203425 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9829
I0216 21:36:59.203493 15389 solver.cpp:318]     Test net output #1: loss = 0.0527458 (* 1 = 0.0527458 loss)
I0216 21:36:59.219075 15389 solver.cpp:189] Iteration 1500, loss = 0.112493
I0216 21:36:59.219174 15389 solver.cpp:204]     Train net output #0: loss = 0.112493 (* 1 = 0.112493 loss)
I0216 21:36:59.219195 15389 solver.cpp:474] Iteration 1500, lr = 0.00900485
I0216 21:37:01.648466 15389 solver.cpp:189] Iteration 1600, loss = 0.116406
I0216 21:37:01.648571 15389 solver.cpp:204]     Train net output #0: loss = 0.116406 (* 1 = 0.116406 loss)
I0216 21:37:01.648592 15389 solver.cpp:474] Iteration 1600, lr = 0.00894657
I0216 21:37:04.078645 15389 solver.cpp:189] Iteration 1700, loss = 0.0397328
I0216 21:37:04.078714 15389 solver.cpp:204]     Train net output #0: loss = 0.039733 (* 1 = 0.039733 loss)
I0216 21:37:04.078742 15389 solver.cpp:474] Iteration 1700, lr = 0.00888916
I0216 21:37:06.510691 15389 solver.cpp:189] Iteration 1800, loss = 0.0151779
I0216 21:37:06.510823 15389 solver.cpp:204]     Train net output #0: loss = 0.015178 (* 1 = 0.015178 loss)
I0216 21:37:06.510853 15389 solver.cpp:474] Iteration 1800, lr = 0.0088326
I0216 21:37:08.942709 15389 solver.cpp:189] Iteration 1900, loss = 0.121916
I0216 21:37:08.942795 15389 solver.cpp:204]     Train net output #0: loss = 0.121916 (* 1 = 0.121916 loss)
I0216 21:37:08.942811 15389 solver.cpp:474] Iteration 1900, lr = 0.00877687
I0216 21:37:11.345190 15389 solver.cpp:267] Iteration 2000, Testing net (#0)
I0216 21:37:13.128901 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9856
I0216 21:37:13.128975 15389 solver.cpp:318]     Test net output #1: loss = 0.0443779 (* 1 = 0.0443779 loss)
I0216 21:37:13.142559 15389 solver.cpp:189] Iteration 2000, loss = 0.0214247
I0216 21:37:13.142593 15389 solver.cpp:204]     Train net output #0: loss = 0.0214248 (* 1 = 0.0214248 loss)
I0216 21:37:13.142608 15389 solver.cpp:474] Iteration 2000, lr = 0.00872196
I0216 21:37:15.570545 15389 solver.cpp:189] Iteration 2100, loss = 0.0348056
I0216 21:37:15.570633 15389 solver.cpp:204]     Train net output #0: loss = 0.0348057 (* 1 = 0.0348057 loss)
I0216 21:37:15.570652 15389 solver.cpp:474] Iteration 2100, lr = 0.00866784
I0216 21:37:18.000334 15389 solver.cpp:189] Iteration 2200, loss = 0.0175856
I0216 21:37:18.000640 15389 solver.cpp:204]     Train net output #0: loss = 0.0175857 (* 1 = 0.0175857 loss)
I0216 21:37:18.000665 15389 solver.cpp:474] Iteration 2200, lr = 0.0086145
I0216 21:37:20.426383 15389 solver.cpp:189] Iteration 2300, loss = 0.123369
I0216 21:37:20.426476 15389 solver.cpp:204]     Train net output #0: loss = 0.123369 (* 1 = 0.123369 loss)
I0216 21:37:20.426496 15389 solver.cpp:474] Iteration 2300, lr = 0.00856192
I0216 21:37:22.850008 15389 solver.cpp:189] Iteration 2400, loss = 0.0161017
I0216 21:37:22.850080 15389 solver.cpp:204]     Train net output #0: loss = 0.0161018 (* 1 = 0.0161018 loss)
I0216 21:37:22.850103 15389 solver.cpp:474] Iteration 2400, lr = 0.00851008
I0216 21:37:25.253376 15389 solver.cpp:267] Iteration 2500, Testing net (#0)
I0216 21:37:27.036161 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9827
I0216 21:37:27.036234 15389 solver.cpp:318]     Test net output #1: loss = 0.0515665 (* 1 = 0.0515665 loss)
I0216 21:37:27.050317 15389 solver.cpp:189] Iteration 2500, loss = 0.0576663
I0216 21:37:27.050355 15389 solver.cpp:204]     Train net output #0: loss = 0.0576664 (* 1 = 0.0576664 loss)
I0216 21:37:27.050372 15389 solver.cpp:474] Iteration 2500, lr = 0.00845897
I0216 21:37:29.478698 15389 solver.cpp:189] Iteration 2600, loss = 0.0535214
I0216 21:37:29.478838 15389 solver.cpp:204]     Train net output #0: loss = 0.0535215 (* 1 = 0.0535215 loss)
I0216 21:37:29.478868 15389 solver.cpp:474] Iteration 2600, lr = 0.00840857
I0216 21:37:31.906812 15389 solver.cpp:189] Iteration 2700, loss = 0.110953
I0216 21:37:31.906891 15389 solver.cpp:204]     Train net output #0: loss = 0.110953 (* 1 = 0.110953 loss)
I0216 21:37:31.906914 15389 solver.cpp:474] Iteration 2700, lr = 0.00835886
I0216 21:37:34.333236 15389 solver.cpp:189] Iteration 2800, loss = 0.00257416
I0216 21:37:34.333304 15389 solver.cpp:204]     Train net output #0: loss = 0.00257431 (* 1 = 0.00257431 loss)
I0216 21:37:34.333318 15389 solver.cpp:474] Iteration 2800, lr = 0.00830984
I0216 21:37:36.762246 15389 solver.cpp:189] Iteration 2900, loss = 0.0308583
I0216 21:37:36.762320 15389 solver.cpp:204]     Train net output #0: loss = 0.0308585 (* 1 = 0.0308585 loss)
I0216 21:37:36.762339 15389 solver.cpp:474] Iteration 2900, lr = 0.00826148
I0216 21:37:39.171542 15389 solver.cpp:267] Iteration 3000, Testing net (#0)
I0216 21:37:40.951135 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9838
I0216 21:37:40.951257 15389 solver.cpp:318]     Test net output #1: loss = 0.0506631 (* 1 = 0.0506631 loss)
I0216 21:37:40.964802 15389 solver.cpp:189] Iteration 3000, loss = 0.0170858
I0216 21:37:40.964836 15389 solver.cpp:204]     Train net output #0: loss = 0.0170859 (* 1 = 0.0170859 loss)
I0216 21:37:40.964854 15389 solver.cpp:474] Iteration 3000, lr = 0.00821377
I0216 21:37:43.395946 15389 solver.cpp:189] Iteration 3100, loss = 0.0283565
I0216 21:37:43.396020 15389 solver.cpp:204]     Train net output #0: loss = 0.0283566 (* 1 = 0.0283566 loss)
I0216 21:37:43.396035 15389 solver.cpp:474] Iteration 3100, lr = 0.0081667
I0216 21:37:45.828208 15389 solver.cpp:189] Iteration 3200, loss = 0.00988833
I0216 21:37:45.828331 15389 solver.cpp:204]     Train net output #0: loss = 0.00988846 (* 1 = 0.00988846 loss)
I0216 21:37:45.828352 15389 solver.cpp:474] Iteration 3200, lr = 0.00812025
I0216 21:37:48.258302 15389 solver.cpp:189] Iteration 3300, loss = 0.0304196
I0216 21:37:48.258653 15389 solver.cpp:204]     Train net output #0: loss = 0.0304197 (* 1 = 0.0304197 loss)
I0216 21:37:48.258677 15389 solver.cpp:474] Iteration 3300, lr = 0.00807442
I0216 21:37:50.687238 15389 solver.cpp:189] Iteration 3400, loss = 0.00721089
I0216 21:37:50.687314 15389 solver.cpp:204]     Train net output #0: loss = 0.00721102 (* 1 = 0.00721102 loss)
I0216 21:37:50.687329 15389 solver.cpp:474] Iteration 3400, lr = 0.00802918
I0216 21:37:53.088918 15389 solver.cpp:267] Iteration 3500, Testing net (#0)
I0216 21:37:54.870659 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9852
I0216 21:37:54.870729 15389 solver.cpp:318]     Test net output #1: loss = 0.0434479 (* 1 = 0.0434479 loss)
I0216 21:37:54.884356 15389 solver.cpp:189] Iteration 3500, loss = 0.00625101
I0216 21:37:54.884389 15389 solver.cpp:204]     Train net output #0: loss = 0.00625117 (* 1 = 0.00625117 loss)
I0216 21:37:54.884404 15389 solver.cpp:474] Iteration 3500, lr = 0.00798454
I0216 21:37:57.316051 15389 solver.cpp:189] Iteration 3600, loss = 0.0430624
I0216 21:37:57.316189 15389 solver.cpp:204]     Train net output #0: loss = 0.0430626 (* 1 = 0.0430626 loss)
I0216 21:37:57.316210 15389 solver.cpp:474] Iteration 3600, lr = 0.00794046
I0216 21:37:59.743156 15389 solver.cpp:189] Iteration 3700, loss = 0.0159517
I0216 21:37:59.743265 15389 solver.cpp:204]     Train net output #0: loss = 0.0159519 (* 1 = 0.0159519 loss)
I0216 21:37:59.743286 15389 solver.cpp:474] Iteration 3700, lr = 0.00789695
I0216 21:38:02.171790 15389 solver.cpp:189] Iteration 3800, loss = 0.0101139
I0216 21:38:02.171895 15389 solver.cpp:204]     Train net output #0: loss = 0.010114 (* 1 = 0.010114 loss)
I0216 21:38:02.171924 15389 solver.cpp:474] Iteration 3800, lr = 0.007854
I0216 21:38:04.598461 15389 solver.cpp:189] Iteration 3900, loss = 0.0380785
I0216 21:38:04.598547 15389 solver.cpp:204]     Train net output #0: loss = 0.0380787 (* 1 = 0.0380787 loss)
I0216 21:38:04.598564 15389 solver.cpp:474] Iteration 3900, lr = 0.00781158
I0216 21:38:07.003391 15389 solver.cpp:267] Iteration 4000, Testing net (#0)
I0216 21:38:08.784338 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9892
I0216 21:38:08.784433 15389 solver.cpp:318]     Test net output #1: loss = 0.0328148 (* 1 = 0.0328148 loss)
I0216 21:38:08.798144 15389 solver.cpp:189] Iteration 4000, loss = 0.0333217
I0216 21:38:08.798221 15389 solver.cpp:204]     Train net output #0: loss = 0.0333218 (* 1 = 0.0333218 loss)
I0216 21:38:08.798239 15389 solver.cpp:474] Iteration 4000, lr = 0.0077697
I0216 21:38:11.221077 15389 solver.cpp:189] Iteration 4100, loss = 0.0388545
I0216 21:38:11.221155 15389 solver.cpp:204]     Train net output #0: loss = 0.0388547 (* 1 = 0.0388547 loss)
I0216 21:38:11.221169 15389 solver.cpp:474] Iteration 4100, lr = 0.00772833
I0216 21:38:13.650549 15389 solver.cpp:189] Iteration 4200, loss = 0.0193518
I0216 21:38:13.650619 15389 solver.cpp:204]     Train net output #0: loss = 0.019352 (* 1 = 0.019352 loss)
I0216 21:38:13.650632 15389 solver.cpp:474] Iteration 4200, lr = 0.00768748
I0216 21:38:16.075718 15389 solver.cpp:189] Iteration 4300, loss = 0.0359647
I0216 21:38:16.075788 15389 solver.cpp:204]     Train net output #0: loss = 0.0359649 (* 1 = 0.0359649 loss)
I0216 21:38:16.075803 15389 solver.cpp:474] Iteration 4300, lr = 0.00764712
I0216 21:38:18.498342 15389 solver.cpp:189] Iteration 4400, loss = 0.0316227
I0216 21:38:18.498703 15389 solver.cpp:204]     Train net output #0: loss = 0.0316229 (* 1 = 0.0316229 loss)
I0216 21:38:18.498726 15389 solver.cpp:474] Iteration 4400, lr = 0.00760726
I0216 21:38:20.903771 15389 solver.cpp:267] Iteration 4500, Testing net (#0)
I0216 21:38:22.683352 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9876
I0216 21:38:22.683434 15389 solver.cpp:318]     Test net output #1: loss = 0.0383892 (* 1 = 0.0383892 loss)
I0216 21:38:22.698554 15389 solver.cpp:189] Iteration 4500, loss = 0.00866789
I0216 21:38:22.698688 15389 solver.cpp:204]     Train net output #0: loss = 0.00866812 (* 1 = 0.00866812 loss)
I0216 21:38:22.698720 15389 solver.cpp:474] Iteration 4500, lr = 0.00756788
I0216 21:38:25.128399 15389 solver.cpp:189] Iteration 4600, loss = 0.00424172
I0216 21:38:25.128479 15389 solver.cpp:204]     Train net output #0: loss = 0.00424195 (* 1 = 0.00424195 loss)
I0216 21:38:25.128494 15389 solver.cpp:474] Iteration 4600, lr = 0.00752897
I0216 21:38:27.554416 15389 solver.cpp:189] Iteration 4700, loss = 0.0060886
I0216 21:38:27.554487 15389 solver.cpp:204]     Train net output #0: loss = 0.00608881 (* 1 = 0.00608881 loss)
I0216 21:38:27.554502 15389 solver.cpp:474] Iteration 4700, lr = 0.00749052
I0216 21:38:29.979236 15389 solver.cpp:189] Iteration 4800, loss = 0.0238081
I0216 21:38:29.979310 15389 solver.cpp:204]     Train net output #0: loss = 0.0238083 (* 1 = 0.0238083 loss)
I0216 21:38:29.979326 15389 solver.cpp:474] Iteration 4800, lr = 0.00745253
I0216 21:38:32.406647 15389 solver.cpp:189] Iteration 4900, loss = 0.00624751
I0216 21:38:32.406720 15389 solver.cpp:204]     Train net output #0: loss = 0.00624773 (* 1 = 0.00624773 loss)
I0216 21:38:32.406734 15389 solver.cpp:474] Iteration 4900, lr = 0.00741498
I0216 21:38:34.827126 15389 solver.cpp:338] Snapshotting to examples/mnist/models/lenet_iter_5000.caffemodel
I0216 21:38:34.835191 15389 solver.cpp:346] Snapshotting solver state to examples/mnist/models/lenet_iter_5000.solverstate
I0216 21:38:34.839231 15389 solver.cpp:267] Iteration 5000, Testing net (#0)
I0216 21:38:36.610383 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9897
I0216 21:38:36.610453 15389 solver.cpp:318]     Test net output #1: loss = 0.032429 (* 1 = 0.032429 loss)
I0216 21:38:36.624491 15389 solver.cpp:189] Iteration 5000, loss = 0.0831122
I0216 21:38:36.624583 15389 solver.cpp:204]     Train net output #0: loss = 0.0831124 (* 1 = 0.0831124 loss)
I0216 21:38:36.624601 15389 solver.cpp:474] Iteration 5000, lr = 0.00737788
I0216 21:38:39.055398 15389 solver.cpp:189] Iteration 5100, loss = 0.0230653
I0216 21:38:39.055474 15389 solver.cpp:204]     Train net output #0: loss = 0.0230655 (* 1 = 0.0230655 loss)
I0216 21:38:39.055493 15389 solver.cpp:474] Iteration 5100, lr = 0.0073412
I0216 21:38:41.482415 15389 solver.cpp:189] Iteration 5200, loss = 0.0112701
I0216 21:38:41.482605 15389 solver.cpp:204]     Train net output #0: loss = 0.0112702 (* 1 = 0.0112702 loss)
I0216 21:38:41.482628 15389 solver.cpp:474] Iteration 5200, lr = 0.00730495
I0216 21:38:43.909631 15389 solver.cpp:189] Iteration 5300, loss = 0.00381251
I0216 21:38:43.909699 15389 solver.cpp:204]     Train net output #0: loss = 0.00381267 (* 1 = 0.00381267 loss)
I0216 21:38:43.909714 15389 solver.cpp:474] Iteration 5300, lr = 0.00726911
I0216 21:38:46.335988 15389 solver.cpp:189] Iteration 5400, loss = 0.0113761
I0216 21:38:46.336055 15389 solver.cpp:204]     Train net output #0: loss = 0.0113763 (* 1 = 0.0113763 loss)
I0216 21:38:46.336073 15389 solver.cpp:474] Iteration 5400, lr = 0.00723368
I0216 21:38:48.740185 15389 solver.cpp:267] Iteration 5500, Testing net (#0)
I0216 21:38:50.523767 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9881
I0216 21:38:50.523839 15389 solver.cpp:318]     Test net output #1: loss = 0.0347086 (* 1 = 0.0347086 loss)
I0216 21:38:50.537472 15389 solver.cpp:189] Iteration 5500, loss = 0.0120183
I0216 21:38:50.537554 15389 solver.cpp:204]     Train net output #0: loss = 0.0120185 (* 1 = 0.0120185 loss)
I0216 21:38:50.537574 15389 solver.cpp:474] Iteration 5500, lr = 0.00719865
I0216 21:38:52.961196 15389 solver.cpp:189] Iteration 5600, loss = 0.00186147
I0216 21:38:52.961266 15389 solver.cpp:204]     Train net output #0: loss = 0.00186166 (* 1 = 0.00186166 loss)
I0216 21:38:52.961282 15389 solver.cpp:474] Iteration 5600, lr = 0.00716402
I0216 21:38:55.393957 15389 solver.cpp:189] Iteration 5700, loss = 0.00361772
I0216 21:38:55.394027 15389 solver.cpp:204]     Train net output #0: loss = 0.00361788 (* 1 = 0.00361788 loss)
I0216 21:38:55.394042 15389 solver.cpp:474] Iteration 5700, lr = 0.00712977
I0216 21:38:57.823128 15389 solver.cpp:189] Iteration 5800, loss = 0.0843802
I0216 21:38:57.823220 15389 solver.cpp:204]     Train net output #0: loss = 0.0843804 (* 1 = 0.0843804 loss)
I0216 21:38:57.823241 15389 solver.cpp:474] Iteration 5800, lr = 0.0070959
I0216 21:39:00.252070 15389 solver.cpp:189] Iteration 5900, loss = 0.005637
I0216 21:39:00.252138 15389 solver.cpp:204]     Train net output #0: loss = 0.00563716 (* 1 = 0.00563716 loss)
I0216 21:39:00.252161 15389 solver.cpp:474] Iteration 5900, lr = 0.0070624
I0216 21:39:02.655671 15389 solver.cpp:267] Iteration 6000, Testing net (#0)
I0216 21:39:04.438397 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9908
I0216 21:39:04.438500 15389 solver.cpp:318]     Test net output #1: loss = 0.028732 (* 1 = 0.028732 loss)
I0216 21:39:04.452522 15389 solver.cpp:189] Iteration 6000, loss = 0.00613505
I0216 21:39:04.452589 15389 solver.cpp:204]     Train net output #0: loss = 0.0061352 (* 1 = 0.0061352 loss)
I0216 21:39:04.452605 15389 solver.cpp:474] Iteration 6000, lr = 0.00702927
I0216 21:39:06.880383 15389 solver.cpp:189] Iteration 6100, loss = 0.00333249
I0216 21:39:06.880472 15389 solver.cpp:204]     Train net output #0: loss = 0.00333263 (* 1 = 0.00333263 loss)
I0216 21:39:06.880487 15389 solver.cpp:474] Iteration 6100, lr = 0.0069965
I0216 21:39:09.312798 15389 solver.cpp:189] Iteration 6200, loss = 0.012008
I0216 21:39:09.312893 15389 solver.cpp:204]     Train net output #0: loss = 0.0120081 (* 1 = 0.0120081 loss)
I0216 21:39:09.312907 15389 solver.cpp:474] Iteration 6200, lr = 0.00696408
I0216 21:39:11.737381 15389 solver.cpp:189] Iteration 6300, loss = 0.00967817
I0216 21:39:11.737460 15389 solver.cpp:204]     Train net output #0: loss = 0.0096783 (* 1 = 0.0096783 loss)
I0216 21:39:11.737474 15389 solver.cpp:474] Iteration 6300, lr = 0.00693201
I0216 21:39:14.163097 15389 solver.cpp:189] Iteration 6400, loss = 0.0138956
I0216 21:39:14.163213 15389 solver.cpp:204]     Train net output #0: loss = 0.0138958 (* 1 = 0.0138958 loss)
I0216 21:39:14.163233 15389 solver.cpp:474] Iteration 6400, lr = 0.00690029
I0216 21:39:16.563657 15389 solver.cpp:267] Iteration 6500, Testing net (#0)
I0216 21:39:18.342617 15389 solver.cpp:318]     Test net output #0: accuracy = 0.99
I0216 21:39:18.342712 15389 solver.cpp:318]     Test net output #1: loss = 0.0306487 (* 1 = 0.0306487 loss)
I0216 21:39:18.358705 15389 solver.cpp:189] Iteration 6500, loss = 0.03442
I0216 21:39:18.358768 15389 solver.cpp:204]     Train net output #0: loss = 0.0344201 (* 1 = 0.0344201 loss)
I0216 21:39:18.358784 15389 solver.cpp:474] Iteration 6500, lr = 0.0068689
I0216 21:39:20.785591 15389 solver.cpp:189] Iteration 6600, loss = 0.019997
I0216 21:39:20.785861 15389 solver.cpp:204]     Train net output #0: loss = 0.0199972 (* 1 = 0.0199972 loss)
I0216 21:39:20.785877 15389 solver.cpp:474] Iteration 6600, lr = 0.00683784
I0216 21:39:23.212584 15389 solver.cpp:189] Iteration 6700, loss = 0.0167597
I0216 21:39:23.212664 15389 solver.cpp:204]     Train net output #0: loss = 0.0167598 (* 1 = 0.0167598 loss)
I0216 21:39:23.212685 15389 solver.cpp:474] Iteration 6700, lr = 0.00680711
I0216 21:39:25.645709 15389 solver.cpp:189] Iteration 6800, loss = 0.00408439
I0216 21:39:25.645875 15389 solver.cpp:204]     Train net output #0: loss = 0.00408454 (* 1 = 0.00408454 loss)
I0216 21:39:25.645912 15389 solver.cpp:474] Iteration 6800, lr = 0.0067767
I0216 21:39:28.073626 15389 solver.cpp:189] Iteration 6900, loss = 0.00299499
I0216 21:39:28.073736 15389 solver.cpp:204]     Train net output #0: loss = 0.00299514 (* 1 = 0.00299514 loss)
I0216 21:39:28.073757 15389 solver.cpp:474] Iteration 6900, lr = 0.0067466
I0216 21:39:30.475163 15389 solver.cpp:267] Iteration 7000, Testing net (#0)
I0216 21:39:32.254586 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9893
I0216 21:39:32.254727 15389 solver.cpp:318]     Test net output #1: loss = 0.032712 (* 1 = 0.032712 loss)
I0216 21:39:32.268815 15389 solver.cpp:189] Iteration 7000, loss = 0.0157903
I0216 21:39:32.268892 15389 solver.cpp:204]     Train net output #0: loss = 0.0157905 (* 1 = 0.0157905 loss)
I0216 21:39:32.268910 15389 solver.cpp:474] Iteration 7000, lr = 0.00671681
I0216 21:39:34.698310 15389 solver.cpp:189] Iteration 7100, loss = 0.0318315
I0216 21:39:34.698406 15389 solver.cpp:204]     Train net output #0: loss = 0.0318317 (* 1 = 0.0318317 loss)
I0216 21:39:34.698426 15389 solver.cpp:474] Iteration 7100, lr = 0.00668733
I0216 21:39:37.132117 15389 solver.cpp:189] Iteration 7200, loss = 0.00328504
I0216 21:39:37.132186 15389 solver.cpp:204]     Train net output #0: loss = 0.00328518 (* 1 = 0.00328518 loss)
I0216 21:39:37.132201 15389 solver.cpp:474] Iteration 7200, lr = 0.00665815
I0216 21:39:39.557251 15389 solver.cpp:189] Iteration 7300, loss = 0.030668
I0216 21:39:39.557325 15389 solver.cpp:204]     Train net output #0: loss = 0.0306681 (* 1 = 0.0306681 loss)
I0216 21:39:39.557339 15389 solver.cpp:474] Iteration 7300, lr = 0.00662927
I0216 21:39:41.980770 15389 solver.cpp:189] Iteration 7400, loss = 0.0122101
I0216 21:39:41.980836 15389 solver.cpp:204]     Train net output #0: loss = 0.0122103 (* 1 = 0.0122103 loss)
I0216 21:39:41.980847 15389 solver.cpp:474] Iteration 7400, lr = 0.00660067
I0216 21:39:44.383465 15389 solver.cpp:267] Iteration 7500, Testing net (#0)
I0216 21:39:46.167832 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9896
I0216 21:39:46.167943 15389 solver.cpp:318]     Test net output #1: loss = 0.0315206 (* 1 = 0.0315206 loss)
I0216 21:39:46.183454 15389 solver.cpp:189] Iteration 7500, loss = 0.00234267
I0216 21:39:46.183560 15389 solver.cpp:204]     Train net output #0: loss = 0.00234281 (* 1 = 0.00234281 loss)
I0216 21:39:46.183588 15389 solver.cpp:474] Iteration 7500, lr = 0.00657236
I0216 21:39:48.610188 15389 solver.cpp:189] Iteration 7600, loss = 0.00871428
I0216 21:39:48.610263 15389 solver.cpp:204]     Train net output #0: loss = 0.00871442 (* 1 = 0.00871442 loss)
I0216 21:39:48.610277 15389 solver.cpp:474] Iteration 7600, lr = 0.00654433
I0216 21:39:51.037312 15389 solver.cpp:189] Iteration 7700, loss = 0.05481
I0216 21:39:51.037638 15389 solver.cpp:204]     Train net output #0: loss = 0.0548102 (* 1 = 0.0548102 loss)
I0216 21:39:51.037657 15389 solver.cpp:474] Iteration 7700, lr = 0.00651658
I0216 21:39:53.462342 15389 solver.cpp:189] Iteration 7800, loss = 0.00629961
I0216 21:39:53.462434 15389 solver.cpp:204]     Train net output #0: loss = 0.00629973 (* 1 = 0.00629973 loss)
I0216 21:39:53.462453 15389 solver.cpp:474] Iteration 7800, lr = 0.00648911
I0216 21:39:55.886958 15389 solver.cpp:189] Iteration 7900, loss = 0.00490402
I0216 21:39:55.887048 15389 solver.cpp:204]     Train net output #0: loss = 0.00490415 (* 1 = 0.00490415 loss)
I0216 21:39:55.887068 15389 solver.cpp:474] Iteration 7900, lr = 0.0064619
I0216 21:39:58.290122 15389 solver.cpp:267] Iteration 8000, Testing net (#0)
I0216 21:40:00.071985 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9896
I0216 21:40:00.072057 15389 solver.cpp:318]     Test net output #1: loss = 0.0310299 (* 1 = 0.0310299 loss)
I0216 21:40:00.085707 15389 solver.cpp:189] Iteration 8000, loss = 0.0042779
I0216 21:40:00.085783 15389 solver.cpp:204]     Train net output #0: loss = 0.00427802 (* 1 = 0.00427802 loss)
I0216 21:40:00.085800 15389 solver.cpp:474] Iteration 8000, lr = 0.00643496
I0216 21:40:02.514663 15389 solver.cpp:189] Iteration 8100, loss = 0.017279
I0216 21:40:02.514740 15389 solver.cpp:204]     Train net output #0: loss = 0.0172792 (* 1 = 0.0172792 loss)
I0216 21:40:02.514755 15389 solver.cpp:474] Iteration 8100, lr = 0.00640827
I0216 21:40:04.944475 15389 solver.cpp:189] Iteration 8200, loss = 0.0107097
I0216 21:40:04.944545 15389 solver.cpp:204]     Train net output #0: loss = 0.0107098 (* 1 = 0.0107098 loss)
I0216 21:40:04.944560 15389 solver.cpp:474] Iteration 8200, lr = 0.00638185
I0216 21:40:07.370733 15389 solver.cpp:189] Iteration 8300, loss = 0.0320467
I0216 21:40:07.370810 15389 solver.cpp:204]     Train net output #0: loss = 0.0320468 (* 1 = 0.0320468 loss)
I0216 21:40:07.370825 15389 solver.cpp:474] Iteration 8300, lr = 0.00635567
I0216 21:40:09.797240 15389 solver.cpp:189] Iteration 8400, loss = 0.0113178
I0216 21:40:09.797333 15389 solver.cpp:204]     Train net output #0: loss = 0.011318 (* 1 = 0.011318 loss)
I0216 21:40:09.797353 15389 solver.cpp:474] Iteration 8400, lr = 0.00632975
I0216 21:40:12.202407 15389 solver.cpp:267] Iteration 8500, Testing net (#0)
I0216 21:40:13.983263 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9898
I0216 21:40:13.983366 15389 solver.cpp:318]     Test net output #1: loss = 0.0288844 (* 1 = 0.0288844 loss)
I0216 21:40:13.997069 15389 solver.cpp:189] Iteration 8500, loss = 0.00898542
I0216 21:40:13.997133 15389 solver.cpp:204]     Train net output #0: loss = 0.0089856 (* 1 = 0.0089856 loss)
I0216 21:40:13.997149 15389 solver.cpp:474] Iteration 8500, lr = 0.00630407
I0216 21:40:16.428359 15389 solver.cpp:189] Iteration 8600, loss = 0.000625334
I0216 21:40:16.428431 15389 solver.cpp:204]     Train net output #0: loss = 0.000625516 (* 1 = 0.000625516 loss)
I0216 21:40:16.428444 15389 solver.cpp:474] Iteration 8600, lr = 0.00627864
I0216 21:40:18.856616 15389 solver.cpp:189] Iteration 8700, loss = 0.00523266
I0216 21:40:18.856688 15389 solver.cpp:204]     Train net output #0: loss = 0.00523285 (* 1 = 0.00523285 loss)
I0216 21:40:18.856703 15389 solver.cpp:474] Iteration 8700, lr = 0.00625344
I0216 21:40:21.286957 15389 solver.cpp:189] Iteration 8800, loss = 0.00166074
I0216 21:40:21.287336 15389 solver.cpp:204]     Train net output #0: loss = 0.00166092 (* 1 = 0.00166092 loss)
I0216 21:40:21.287353 15389 solver.cpp:474] Iteration 8800, lr = 0.00622847
I0216 21:40:23.715210 15389 solver.cpp:189] Iteration 8900, loss = 0.000716643
I0216 21:40:23.715308 15389 solver.cpp:204]     Train net output #0: loss = 0.000716832 (* 1 = 0.000716832 loss)
I0216 21:40:23.715328 15389 solver.cpp:474] Iteration 8900, lr = 0.00620374
I0216 21:40:26.125236 15389 solver.cpp:267] Iteration 9000, Testing net (#0)
I0216 21:40:27.909272 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9898
I0216 21:40:27.909384 15389 solver.cpp:318]     Test net output #1: loss = 0.0303239 (* 1 = 0.0303239 loss)
I0216 21:40:27.924079 15389 solver.cpp:189] Iteration 9000, loss = 0.0277652
I0216 21:40:27.924167 15389 solver.cpp:204]     Train net output #0: loss = 0.0277654 (* 1 = 0.0277654 loss)
I0216 21:40:27.924186 15389 solver.cpp:474] Iteration 9000, lr = 0.00617924
I0216 21:40:30.356647 15389 solver.cpp:189] Iteration 9100, loss = 0.00719987
I0216 21:40:30.356781 15389 solver.cpp:204]     Train net output #0: loss = 0.00720005 (* 1 = 0.00720005 loss)
I0216 21:40:30.356812 15389 solver.cpp:474] Iteration 9100, lr = 0.00615496
I0216 21:40:32.786350 15389 solver.cpp:189] Iteration 9200, loss = 0.00475769
I0216 21:40:32.786429 15389 solver.cpp:204]     Train net output #0: loss = 0.00475788 (* 1 = 0.00475788 loss)
I0216 21:40:32.786444 15389 solver.cpp:474] Iteration 9200, lr = 0.0061309
I0216 21:40:35.217216 15389 solver.cpp:189] Iteration 9300, loss = 0.00516738
I0216 21:40:35.217291 15389 solver.cpp:204]     Train net output #0: loss = 0.00516757 (* 1 = 0.00516757 loss)
I0216 21:40:35.217305 15389 solver.cpp:474] Iteration 9300, lr = 0.00610706
I0216 21:40:37.641969 15389 solver.cpp:189] Iteration 9400, loss = 0.064992
I0216 21:40:37.642038 15389 solver.cpp:204]     Train net output #0: loss = 0.0649921 (* 1 = 0.0649921 loss)
I0216 21:40:37.642052 15389 solver.cpp:474] Iteration 9400, lr = 0.00608343
I0216 21:40:40.046051 15389 solver.cpp:267] Iteration 9500, Testing net (#0)
I0216 21:40:41.828717 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9884
I0216 21:40:41.828785 15389 solver.cpp:318]     Test net output #1: loss = 0.0354716 (* 1 = 0.0354716 loss)
I0216 21:40:41.843688 15389 solver.cpp:189] Iteration 9500, loss = 0.00441421
I0216 21:40:41.843793 15389 solver.cpp:204]     Train net output #0: loss = 0.0044144 (* 1 = 0.0044144 loss)
I0216 21:40:41.843814 15389 solver.cpp:474] Iteration 9500, lr = 0.00606002
I0216 21:40:44.275017 15389 solver.cpp:189] Iteration 9600, loss = 0.00210507
I0216 21:40:44.275096 15389 solver.cpp:204]     Train net output #0: loss = 0.00210526 (* 1 = 0.00210526 loss)
I0216 21:40:44.275110 15389 solver.cpp:474] Iteration 9600, lr = 0.00603682
I0216 21:40:46.697862 15389 solver.cpp:189] Iteration 9700, loss = 0.00262656
I0216 21:40:46.697932 15389 solver.cpp:204]     Train net output #0: loss = 0.00262675 (* 1 = 0.00262675 loss)
I0216 21:40:46.697947 15389 solver.cpp:474] Iteration 9700, lr = 0.00601382
I0216 21:40:49.121065 15389 solver.cpp:189] Iteration 9800, loss = 0.0166412
I0216 21:40:49.121181 15389 solver.cpp:204]     Train net output #0: loss = 0.0166413 (* 1 = 0.0166413 loss)
I0216 21:40:49.121201 15389 solver.cpp:474] Iteration 9800, lr = 0.00599102
I0216 21:40:51.551939 15389 solver.cpp:189] Iteration 9900, loss = 0.00516509
I0216 21:40:51.552206 15389 solver.cpp:204]     Train net output #0: loss = 0.00516528 (* 1 = 0.00516528 loss)
I0216 21:40:51.552235 15389 solver.cpp:474] Iteration 9900, lr = 0.00596843
I0216 21:40:53.970037 15389 solver.cpp:338] Snapshotting to examples/mnist/models/lenet_iter_10000.caffemodel
I0216 21:40:53.977450 15389 solver.cpp:346] Snapshotting solver state to examples/mnist/models/lenet_iter_10000.solverstate
I0216 21:40:53.993639 15389 solver.cpp:249] Iteration 10000, loss = 0.00530324
I0216 21:40:53.993708 15389 solver.cpp:267] Iteration 10000, Testing net (#0)
I0216 21:40:55.766815 15389 solver.cpp:318]     Test net output #0: accuracy = 0.9908
I0216 21:40:55.766949 15389 solver.cpp:318]     Test net output #1: loss = 0.028901 (* 1 = 0.028901 loss)
I0216 21:40:55.766963 15389 solver.cpp:254] Optimization Done.
I0216 21:40:55.766970 15389 caffe.cpp:121] Optimization Done.
